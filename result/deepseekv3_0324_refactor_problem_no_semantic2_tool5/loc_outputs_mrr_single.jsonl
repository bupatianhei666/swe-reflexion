{"instance_id": "pytest-dev__pytest-6116", "found_files": ["src/_pytest/config/argparsing.py", "src/_pytest/main.py", "src/_pytest/config/__init__.py", "src/_pytest/python.py", "src/_pytest/doctest.py"], "found_modules": ["src/_pytest/config/argparsing.py:Parser", "src/_pytest/main.py:pytest_addoption", "src/_pytest/python.py:PyCollector", "src/_pytest/config/__init__.py:Config", "src/_pytest/python.py:Package", "src/_pytest/doctest.py:DoctestModule"], "found_entities": ["src/_pytest/config/argparsing.py:Parser.addoption", "src/_pytest/main.py:pytest_addoption", "src/_pytest/python.py:PyCollector.collect", "src/_pytest/python.py:Package.collect", "src/_pytest/doctest.py:DoctestModule.collect"], "raw_output_loc": ["```\nsrc/_pytest/main.py\nline: 109\nfunction: pytest_addoption\n\nsrc/_pytest/config/argparsing.py\nline: 64\nfunction: Parser.addoption\n```", "```\nsrc/_pytest/config/argparsing.py\nline: 64\nfunction: Parser.addoption\n\nsrc/_pytest/config/__init__.py\nfunction: Config\n\nsrc/_pytest/python.py\nline: 357\nfunction: PyCollector.collect\n\nsrc/_pytest/python.py\nline: 631\nfunction: Package.collect\n\nsrc/_pytest/doctest.py\nline: 427\nfunction: DoctestModule.collect\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "e670ff76cbad80108bde9bab616b66771b8653cf", "problem_statement": "pytest --collect-only needs a one char shortcut command\nI find myself needing to run `--collect-only` very often and that cli argument is a very long to type one. \r\n\r\nI do think that it would be great to allocate a character for it, not sure which one yet. Please use up/down thumbs to vote if you would find it useful or not and eventually proposing which char should be used. \r\n\r\nClearly this is a change very easy to implement but first I want to see if others would find it useful or not.\npytest --collect-only needs a one char shortcut command\nI find myself needing to run `--collect-only` very often and that cli argument is a very long to type one. \r\n\r\nI do think that it would be great to allocate a character for it, not sure which one yet. Please use up/down thumbs to vote if you would find it useful or not and eventually proposing which char should be used. \r\n\r\nClearly this is a change very easy to implement but first I want to see if others would find it useful or not.\n", "patch": "diff --git a/src/_pytest/main.py b/src/_pytest/main.py\n--- a/src/_pytest/main.py\n+++ b/src/_pytest/main.py\n@@ -109,6 +109,7 @@ def pytest_addoption(parser):\n     group.addoption(\n         \"--collectonly\",\n         \"--collect-only\",\n+        \"--co\",\n         action=\"store_true\",\n         help=\"only collect tests, don't execute them.\",\n     ),\n"}}
{"instance_id": "django__django-13321", "found_files": ["django/contrib/sessions/backends/base.py", "django/core/signing.py"], "found_modules": ["django/contrib/sessions/backends/base.py:SessionBase", "django/core/signing.py:TimestampSigner", "django/core/signing.py:loads"], "found_entities": ["django/contrib/sessions/backends/base.py:SessionBase._legacy_decode", "django/contrib/sessions/backends/base.py:SessionBase.decode", "django/core/signing.py:loads", "django/core/signing.py:TimestampSigner.unsign", "django/contrib/sessions/backends/base.py:SessionBase._get_session"], "raw_output_loc": ["```\ndjango/contrib/sessions/backends/base.py\nline: 135\nclass: SessionBase\nfunction: SessionBase._legacy_decode\n\ndjango/contrib/sessions/backends/base.py\nline: 119\nclass: SessionBase\nfunction: SessionBase.decode\n\ndjango/contrib/sessions/backends/base.py\nline: 217\nclass: SessionBase\nfunction: SessionBase._get_session\n\ndjango/core/signing.py\nline: 135\nfunction: signing.loads\n\ndjango/core/signing.py\nline: 201\nfunction: TimestampSigner.unsign\n```", "```\ndjango/contrib/sessions/backends/base.py\nline: 119\nfunction: SessionBase.decode\n\nline: 133\nfunction: SessionBase._legacy_decode\n\ndjango/core/signing.py\nline: 135\nfunction: loads\n\nline: 196\nfunction: TimestampSigner.unsign\n\nline: 127\nfunction: loads\n```"], "meta_data": {"repo": "django/django", "base_commit": "35b03788b0607c1f8d2b64e4fa9e1669b0907ea4", "problem_statement": "Decoding an invalid session data crashes.\nDescription\n\t \n\t\t(last modified by Matt Hegarty)\n\t \nHi\nI recently upgraded my staging server to 3.1. I think that there was an old session which was still active.\nOn browsing to any URL, I get the crash below. It looks similar to \u200bthis issue.\nI cannot login at all with Chrome - each attempt to access the site results in a crash. Login with Firefox works fine.\nThis is only happening on my Staging site, which is running Gunicorn behind nginx proxy.\nInternal Server Error: /overview/\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 215, in _get_session\nreturn self._session_cache\nAttributeError: 'SessionStore' object has no attribute '_session_cache'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 118, in decode\nreturn signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\nFile \"/usr/local/lib/python3.8/site-packages/django/core/signing.py\", line 135, in loads\nbase64d = TimestampSigner(key, salt=salt).unsign(s, max_age=max_age).encode()\nFile \"/usr/local/lib/python3.8/site-packages/django/core/signing.py\", line 201, in unsign\nresult = super().unsign(value)\nFile \"/usr/local/lib/python3.8/site-packages/django/core/signing.py\", line 184, in unsign\nraise BadSignature('Signature \"%s\" does not match' % sig)\ndjango.core.signing.BadSignature: Signature \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" does not match\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"/usr/local/lib/python3.8/site-packages/django/core/handlers/exception.py\", line 47, in inner\nresponse = get_response(request)\nFile \"/usr/local/lib/python3.8/site-packages/django/core/handlers/base.py\", line 179, in _get_response\nresponse = wrapped_callback(request, *callback_args, **callback_kwargs)\nFile \"/usr/local/lib/python3.8/site-packages/django/views/generic/base.py\", line 73, in view\nreturn self.dispatch(request, *args, **kwargs)\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/auth/mixins.py\", line 50, in dispatch\nif not request.user.is_authenticated:\nFile \"/usr/local/lib/python3.8/site-packages/django/utils/functional.py\", line 240, in inner\nself._setup()\nFile \"/usr/local/lib/python3.8/site-packages/django/utils/functional.py\", line 376, in _setup\nself._wrapped = self._setupfunc()\nFile \"/usr/local/lib/python3.8/site-packages/django_otp/middleware.py\", line 38, in _verify_user\nuser.otp_device = None\nFile \"/usr/local/lib/python3.8/site-packages/django/utils/functional.py\", line 270, in __setattr__\nself._setup()\nFile \"/usr/local/lib/python3.8/site-packages/django/utils/functional.py\", line 376, in _setup\nself._wrapped = self._setupfunc()\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/auth/middleware.py\", line 23, in <lambda>\nrequest.user = SimpleLazyObject(lambda: get_user(request))\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/auth/middleware.py\", line 11, in get_user\nrequest._cached_user = auth.get_user(request)\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/auth/__init__.py\", line 174, in get_user\nuser_id = _get_user_session_key(request)\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/auth/__init__.py\", line 58, in _get_user_session_key\nreturn get_user_model()._meta.pk.to_python(request.session[SESSION_KEY])\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 65, in __getitem__\nreturn self._session[key]\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 220, in _get_session\nself._session_cache = self.load()\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/db.py\", line 44, in load\nreturn self.decode(s.session_data) if s else {}\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 122, in decode\nreturn self._legacy_decode(session_data)\nFile \"/usr/local/lib/python3.8/site-packages/django/contrib/sessions/backends/base.py\", line 126, in _legacy_decode\nencoded_data = base64.b64decode(session_data.encode('ascii'))\nFile \"/usr/local/lib/python3.8/base64.py\", line 87, in b64decode\nreturn binascii.a2b_base64(s)\nbinascii.Error: Incorrect padding\n", "patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -121,6 +121,15 @@ def decode(self, session_data):\n             return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n         # RemovedInDjango40Warning: when the deprecation ends, handle here\n         # exceptions similar to what _legacy_decode() does now.\n+        except signing.BadSignature:\n+            try:\n+                # Return an empty session if data is not in the pre-Django 3.1\n+                # format.\n+                return self._legacy_decode(session_data)\n+            except Exception:\n+                logger = logging.getLogger('django.security.SuspiciousSession')\n+                logger.warning('Session data corrupted')\n+                return {}\n         except Exception:\n             return self._legacy_decode(session_data)\n \n"}}
{"instance_id": "django__django-12113", "found_files": ["django/db/backends/sqlite3/base.py", "django/db/models/base.py", "django/db/utils.py", "django/db/backends/base/base.py"], "found_modules": ["django/db/backends/sqlite3/base.py:DatabaseWrapper", "django/db/models/base.py:Model", "django/db/utils.py:DatabaseErrorWrapper", "django/db/utils.py:ConnectionHandler", "django/db/backends/base/base.py:BaseDatabaseWrapper"], "found_entities": ["django/db/backends/sqlite3/base.py:DatabaseWrapper.get_new_connection", "django/db/models/base.py:Model.save", "django/db/backends/sqlite3/base.py:DatabaseWrapper.get_connection_params", "django/db/models/base.py:Model.save_base", "django/db/utils.py:DatabaseErrorWrapper.__exit__", "django/db/models/base.py:Model._save_table", "django/db/utils.py:ConnectionHandler.__getitem__", "django/db/models/base.py:Model._do_update", "django/db/backends/base/base.py:BaseDatabaseWrapper.connect", "django/db/models/base.py:Model._do_insert", "django/db/backends/base/base.py:BaseDatabaseWrapper.ensure_connection"], "raw_output_loc": ["```\ndjango/db/backends/sqlite3/base.py\nline: 202-252\nclass: DatabaseWrapper\nfunction: DatabaseWrapper.get_new_connection\n\ndjango/db/backends/sqlite3/base.py\nline: 172-200\nclass: DatabaseWrapper\nfunction: DatabaseWrapper.get_connection_params\n\ndjango/db/utils.py\nline: 89-95\nclass: ConnectionHandler\nfunction: ConnectionHandler.__getitem__\n\ndjango/test/testcases.py\nline: 1137-1140\nclass: TestCase\nfunction: TestCase.setUpClass\n\ndjango/db/backends/base/base.py\nline: 200-220\nclass: BaseDatabaseWrapper\nfunction: BaseDatabaseWrapper.ensure_connection\n```", "```\ndjango/db/models/base.py\nline: 741\nfunction: Model.save\n\nline: 779\nfunction: Model.save_base\n\nline: 870\nfunction: Model._save_table\n\nline: 908\nfunction: Model._do_insert\n\nline: 391\nfunction: SQLiteCursorWrapper.execute\n```"], "meta_data": {"repo": "django/django", "base_commit": "62254c5202e80a68f4fe6572a2be46a3d953de1a", "problem_statement": "admin_views.test_multidb fails with persistent test SQLite database.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nI've tried using persistent SQLite databases for the tests (to make use of\n--keepdb), but at least some test fails with:\nsqlite3.OperationalError: database is locked\nThis is not an issue when only using TEST[\"NAME\"] with \"default\" (which is good enough in terms of performance).\ndiff --git i/tests/test_sqlite.py w/tests/test_sqlite.py\nindex f1b65f7d01..9ce4e32e14 100644\n--- i/tests/test_sqlite.py\n+++ w/tests/test_sqlite.py\n@@ -15,9 +15,15 @@\n DATABASES = {\n\t 'default': {\n\t\t 'ENGINE': 'django.db.backends.sqlite3',\n+\t\t'TEST': {\n+\t\t\t'NAME': 'test_default.sqlite3'\n+\t\t},\n\t },\n\t 'other': {\n\t\t 'ENGINE': 'django.db.backends.sqlite3',\n+\t\t'TEST': {\n+\t\t\t'NAME': 'test_other.sqlite3'\n+\t\t},\n\t }\n }\n% tests/runtests.py admin_views.test_multidb -v 3 --keepdb --parallel 1\n\u2026\nOperations to perform:\n Synchronize unmigrated apps: admin_views, auth, contenttypes, messages, sessions, staticfiles\n Apply all migrations: admin, sites\nRunning pre-migrate handlers for application contenttypes\nRunning pre-migrate handlers for application auth\nRunning pre-migrate handlers for application sites\nRunning pre-migrate handlers for application sessions\nRunning pre-migrate handlers for application admin\nRunning pre-migrate handlers for application admin_views\nSynchronizing apps without migrations:\n Creating tables...\n\tRunning deferred SQL...\nRunning migrations:\n No migrations to apply.\nRunning post-migrate handlers for application contenttypes\nRunning post-migrate handlers for application auth\nRunning post-migrate handlers for application sites\nRunning post-migrate handlers for application sessions\nRunning post-migrate handlers for application admin\nRunning post-migrate handlers for application admin_views\nSystem check identified no issues (0 silenced).\nERROR\n======================================================================\nERROR: setUpClass (admin_views.test_multidb.MultiDatabaseTests)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n File \"\u2026/Vcs/django/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\n File \"\u2026/Vcs/django/django/db/backends/sqlite3/base.py\", line 391, in execute\n\treturn Database.Cursor.execute(self, query, params)\nsqlite3.OperationalError: database is locked\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n File \"\u2026/Vcs/django/django/test/testcases.py\", line 1137, in setUpClass\n\tcls.setUpTestData()\n File \"\u2026/Vcs/django/tests/admin_views/test_multidb.py\", line 40, in setUpTestData\n\tusername='admin', password='something', email='test@test.org',\n File \"\u2026/Vcs/django/django/contrib/auth/models.py\", line 158, in create_superuser\n\treturn self._create_user(username, email, password, **extra_fields)\n File \"\u2026/Vcs/django/django/contrib/auth/models.py\", line 141, in _create_user\n\tuser.save(using=self._db)\n File \"\u2026/Vcs/django/django/contrib/auth/base_user.py\", line 66, in save\n\tsuper().save(*args, **kwargs)\n File \"\u2026/Vcs/django/django/db/models/base.py\", line 741, in save\n\tforce_update=force_update, update_fields=update_fields)\n File \"\u2026/Vcs/django/django/db/models/base.py\", line 779, in save_base\n\tforce_update, using, update_fields,\n File \"\u2026/Vcs/django/django/db/models/base.py\", line 870, in _save_table\n\tresult = self._do_insert(cls._base_manager, using, fields, update_pk, raw)\n File \"\u2026/Vcs/django/django/db/models/base.py\", line 908, in _do_insert\n\tusing=using, raw=raw)\n File \"\u2026/Vcs/django/django/db/models/manager.py\", line 82, in manager_method\n\treturn getattr(self.get_queryset(), name)(*args, **kwargs)\n File \"\u2026/Vcs/django/django/db/models/query.py\", line 1175, in _insert\n\treturn query.get_compiler(using=using).execute_sql(return_id)\n File \"\u2026/Vcs/django/django/db/models/sql/compiler.py\", line 1321, in execute_sql\n\tcursor.execute(sql, params)\n File \"\u2026/Vcs/django/django/db/backends/utils.py\", line 67, in execute\n\treturn self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n File \"\u2026/Vcs/django/django/db/backends/utils.py\", line 76, in _execute_with_wrappers\n\treturn executor(sql, params, many, context)\n File \"\u2026/Vcs/django/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\n File \"\u2026/Vcs/django/django/db/utils.py\", line 89, in __exit__\n\traise dj_exc_value.with_traceback(traceback) from exc_value\n File \"\u2026/Vcs/django/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\n File \"\u2026/Vcs/django/django/db/backends/sqlite3/base.py\", line 391, in execute\n\treturn Database.Cursor.execute(self, query, params)\ndjango.db.utils.OperationalError: database is locked\n", "patch": "diff --git a/django/db/backends/sqlite3/creation.py b/django/db/backends/sqlite3/creation.py\n--- a/django/db/backends/sqlite3/creation.py\n+++ b/django/db/backends/sqlite3/creation.py\n@@ -98,4 +98,6 @@ def test_db_signature(self):\n         sig = [self.connection.settings_dict['NAME']]\n         if self.is_in_memory_db(test_database_name):\n             sig.append(self.connection.alias)\n+        else:\n+            sig.append(test_database_name)\n         return tuple(sig)\n"}}
{"instance_id": "pydata__xarray-4493", "found_files": ["xarray/core/dataset.py", "xarray/core/merge.py", "xarray/core/alignment.py"], "found_modules": ["xarray/core/dataset.py:Dataset", "xarray/core/merge.py:dataset_update_method", "xarray/core/merge.py:merge_core", "xarray/core/alignment.py:deep_align", "xarray/core/alignment.py:align", "xarray/core/merge.py:merge_collected"], "found_entities": ["xarray/core/dataset.py:Dataset.update", "xarray/core/merge.py:dataset_update_method", "xarray/core/merge.py:merge_core", "xarray/core/alignment.py:deep_align", "xarray/core/alignment.py:align", "xarray/core/merge.py:merge_collected"], "raw_output_loc": ["```\nxarray/core/dataset.py\nline: 3909\nfunction: Dataset.update\n\nxarray/core/merge.py\nline: 908\nfunction: dataset_update_method\n\nxarray/core/merge.py\nline: 537\nfunction: merge_core\n\nxarray/core/alignment.py\nline: 366\nfunction: deep_align\n\nxarray/core/alignment.py\nline: 74\nfunction: align\n```", "```\nxarray/core/dataset.py:Dataset.update\nline: 3883\nfunction: Dataset.update\n\nxarray/core/merge.py:dataset_update_method\nline: 908\nfunction: dataset_update_method\n\nxarray/core/merge.py:merge_core\nline: 537\nfunction: merge_core\n\nxarray/core/alignment.py:deep_align\nfunction: deep_align\n\nxarray/core/merge.py:merge_collected\nfunction: merge_collected\n```"], "meta_data": {"repo": "pydata/xarray", "base_commit": "a5f53e203c52a7605d5db799864046471115d04f", "problem_statement": "DataSet.update causes chunked dask DataArray to evalute its values eagerly \n**What happened**:\r\nUsed `DataSet.update` to update a chunked dask DataArray, but the DataArray is no longer chunked after the update.\r\n\r\n**What you expected to happen**:\r\nThe chunked DataArray should still be chunked after the update\r\n\r\n**Minimal Complete Verifiable Example**:\r\n\r\n```python\r\nfoo = xr.DataArray(np.random.randn(3, 3), dims=(\"x\", \"y\")).chunk()  # foo is chunked\r\nds = xr.Dataset({\"foo\": foo, \"bar\": (\"x\", [1, 2, 3])})  # foo is still chunked here\r\nds  # you can verify that foo is chunked\r\n```\r\n```python\r\nupdate_dict = {\"foo\": ((\"x\", \"y\"), ds.foo[1:, :]), \"bar\": (\"x\", ds.bar[1:])}\r\nupdate_dict[\"foo\"][1]  # foo is still chunked\r\n```\r\n```python\r\nds.update(update_dict)\r\nds  # now foo is no longer chunked\r\n```\r\n\r\n**Environment**:\r\n\r\n<details><summary>Output of <tt>xr.show_versions()</tt></summary>\r\n\r\n```\r\ncommit: None\r\npython: 3.8.3 (default, Jul  2 2020, 11:26:31) \r\n[Clang 10.0.0 ]\r\npython-bits: 64\r\nOS: Darwin\r\nOS-release: 19.6.0\r\nmachine: x86_64\r\nprocessor: i386\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_US.UTF-8\r\nLOCALE: en_US.UTF-8\r\nlibhdf5: 1.10.6\r\nlibnetcdf: None\r\n\r\nxarray: 0.16.0\r\npandas: 1.0.5\r\nnumpy: 1.18.5\r\nscipy: 1.5.0\r\nnetCDF4: None\r\npydap: None\r\nh5netcdf: None\r\nh5py: 2.10.0\r\nNio: None\r\nzarr: None\r\ncftime: None\r\nnc_time_axis: None\r\nPseudoNetCDF: None\r\nrasterio: None\r\ncfgrib: None\r\niris: None\r\nbottleneck: None\r\ndask: 2.20.0\r\ndistributed: 2.20.0\r\nmatplotlib: 3.2.2\r\ncartopy: None\r\nseaborn: None\r\nnumbagg: None\r\npint: None\r\nsetuptools: 49.2.0.post20200714\r\npip: 20.1.1\r\nconda: None\r\npytest: 5.4.3\r\nIPython: 7.16.1\r\nsphinx: None\r\n```\r\n\r\n</details>\nDataset constructor with DataArray triggers computation\nIs it intentional that creating a Dataset with a DataArray and dimension names for a single variable causes computation of that variable?  In other words, why does ```xr.Dataset(dict(a=('d0', xr.DataArray(da.random.random(10)))))``` cause the dask array to compute?\r\n\r\nA longer example:\r\n\r\n```python\r\nimport dask.array as da\r\nimport xarray as xr\r\nx = da.random.randint(1, 10, size=(100, 25))\r\nds = xr.Dataset(dict(a=xr.DataArray(x, dims=('x', 'y'))))\r\ntype(ds.a.data)\r\ndask.array.core.Array\r\n\r\n# Recreate the dataset with the same array, but also redefine the dimensions\r\nds2 = xr.Dataset(dict(a=(('x', 'y'), ds.a))\r\ntype(ds2.a.data)\r\nnumpy.ndarray\r\n```\r\n\r\n\n", "patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -120,6 +120,16 @@ def as_variable(obj, name=None) -> \"Union[Variable, IndexVariable]\":\n     if isinstance(obj, Variable):\n         obj = obj.copy(deep=False)\n     elif isinstance(obj, tuple):\n+        if isinstance(obj[1], DataArray):\n+            # TODO: change into TypeError\n+            warnings.warn(\n+                (\n+                    \"Using a DataArray object to construct a variable is\"\n+                    \" ambiguous, please extract the data using the .data property.\"\n+                    \" This will raise a TypeError in 0.19.0.\"\n+                ),\n+                DeprecationWarning,\n+            )\n         try:\n             obj = Variable(*obj)\n         except (TypeError, ValueError) as error:\n"}}
{"instance_id": "scikit-learn__scikit-learn-25747", "found_files": ["sklearn/pipeline.py", "sklearn/utils/_set_output.py"], "found_modules": ["sklearn/pipeline.py:FeatureUnion", "sklearn/utils/_set_output.py:_wrap_in_pandas_container", "sklearn/utils/_set_output.py:_wrap_data_with_container"], "found_entities": ["sklearn/pipeline.py:FeatureUnion._hstack", "sklearn/utils/_set_output.py:_wrap_in_pandas_container", "sklearn/utils/_set_output.py:_wrap_data_with_container", "sklearn/pipeline.py:FeatureUnion.transform", "sklearn/pipeline.py:FeatureUnion.fit_transform"], "raw_output_loc": ["```\nsklearn/pipeline.py:FeatureUnion._hstack\nline: 1280\nfunction: FeatureUnion._hstack\n\nsklearn/utils/_set_output.py:_wrap_in_pandas_container\nline: 59\nfunction: _wrap_in_pandas_container\n\nsklearn/utils/_set_output.py:_wrap_data_with_container\nline: 130\nfunction: _wrap_data_with_container\n\nsklearn/pipeline.py:FeatureUnion.transform\nline: 1269\nfunction: FeatureUnion.transform\n\nsklearn/pipeline.py:FeatureUnion.fit_transform\nline: 1219\nfunction: FeatureUnion.fit_transform\n```", "```\nsklearn/pipeline.py:FeatureUnion\nline: 1280\nfunction: FeatureUnion._hstack\n\nsklearn/utils/_set_output.py:_wrap_in_pandas_container\nline: 59\nfunction: _wrap_in_pandas_container\n\nsklearn/utils/_set_output.py:_wrap_data_with_container\nline: 130\nfunction: _wrap_data_with_container\n\nsklearn/pipeline.py:FeatureUnion\nline: 1227\nfunction: FeatureUnion.fit_transform\n\nsklearn/pipeline.py:FeatureUnion\nline: 1254\nfunction: FeatureUnion.transform\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "2c867b8f822eb7a684f0d5c4359e4426e1c9cfe0", "problem_statement": "FeatureUnion not working when aggregating data and pandas transform output selected\n### Describe the bug\n\nI would like to use `pandas` transform output and use a custom transformer in a feature union which aggregates data. When I'm using this combination I got an error. When I use default `numpy` output it works fine.\n\n### Steps/Code to Reproduce\n\n```python\r\nimport pandas as pd\r\nfrom sklearn.base import BaseEstimator, TransformerMixin\r\nfrom sklearn import set_config\r\nfrom sklearn.pipeline import make_union\r\n\r\nindex = pd.date_range(start=\"2020-01-01\", end=\"2020-01-05\", inclusive=\"left\", freq=\"H\")\r\ndata = pd.DataFrame(index=index, data=[10] * len(index), columns=[\"value\"])\r\ndata[\"date\"] = index.date\r\n\r\n\r\nclass MyTransformer(BaseEstimator, TransformerMixin):\r\n    def fit(self, X: pd.DataFrame, y: pd.Series | None = None, **kwargs):\r\n        return self\r\n\r\n    def transform(self, X: pd.DataFrame, y: pd.Series | None = None) -> pd.DataFrame:\r\n        return X[\"value\"].groupby(X[\"date\"]).sum()\r\n\r\n\r\n# This works.\r\nset_config(transform_output=\"default\")\r\nprint(make_union(MyTransformer()).fit_transform(data))\r\n\r\n# This does not work.\r\nset_config(transform_output=\"pandas\")\r\nprint(make_union(MyTransformer()).fit_transform(data))\r\n```\n\n### Expected Results\n\nNo error is thrown when using `pandas` transform output.\n\n### Actual Results\n\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[5], line 25\r\n     23 # This does not work.\r\n     24 set_config(transform_output=\"pandas\")\r\n---> 25 print(make_union(MyTransformer()).fit_transform(data))\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:150, in _wrap_method_output.<locals>.wrapped(self, X, *args, **kwargs)\r\n    143 if isinstance(data_to_wrap, tuple):\r\n    144     # only wrap the first output for cross decomposition\r\n    145     return (\r\n    146         _wrap_data_with_container(method, data_to_wrap[0], X, self),\r\n    147         *data_to_wrap[1:],\r\n    148     )\r\n--> 150 return _wrap_data_with_container(method, data_to_wrap, X, self)\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:130, in _wrap_data_with_container(method, data_to_wrap, original_input, estimator)\r\n    127     return data_to_wrap\r\n    129 # dense_config == \"pandas\"\r\n--> 130 return _wrap_in_pandas_container(\r\n    131     data_to_wrap=data_to_wrap,\r\n    132     index=getattr(original_input, \"index\", None),\r\n    133     columns=estimator.get_feature_names_out,\r\n    134 )\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/utils/_set_output.py:59, in _wrap_in_pandas_container(data_to_wrap, columns, index)\r\n     57         data_to_wrap.columns = columns\r\n     58     if index is not None:\r\n---> 59         data_to_wrap.index = index\r\n     60     return data_to_wrap\r\n     62 return pd.DataFrame(data_to_wrap, index=index, columns=columns)\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/generic.py:5588, in NDFrame.__setattr__(self, name, value)\r\n   5586 try:\r\n   5587     object.__getattribute__(self, name)\r\n-> 5588     return object.__setattr__(self, name, value)\r\n   5589 except AttributeError:\r\n   5590     pass\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/_libs/properties.pyx:70, in pandas._libs.properties.AxisProperty.__set__()\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/generic.py:769, in NDFrame._set_axis(self, axis, labels)\r\n    767 def _set_axis(self, axis: int, labels: Index) -> None:\r\n    768     labels = ensure_index(labels)\r\n--> 769     self._mgr.set_axis(axis, labels)\r\n    770     self._clear_item_cache()\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/internals/managers.py:214, in BaseBlockManager.set_axis(self, axis, new_labels)\r\n    212 def set_axis(self, axis: int, new_labels: Index) -> None:\r\n    213     # Caller is responsible for ensuring we have an Index object.\r\n--> 214     self._validate_set_axis(axis, new_labels)\r\n    215     self.axes[axis] = new_labels\r\n\r\nFile ~/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/pandas/core/internals/base.py:69, in DataManager._validate_set_axis(self, axis, new_labels)\r\n     66     pass\r\n     68 elif new_len != old_len:\r\n---> 69     raise ValueError(\r\n     70         f\"Length mismatch: Expected axis has {old_len} elements, new \"\r\n     71         f\"values have {new_len} elements\"\r\n     72     )\r\n\r\nValueError: Length mismatch: Expected axis has 4 elements, new values have 96 elements\r\n```\n\n### Versions\n\n```shell\nSystem:\r\n    python: 3.10.6 (main, Aug 30 2022, 05:11:14) [Clang 13.0.0 (clang-1300.0.29.30)]\r\nexecutable: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/bin/python\r\n   machine: macOS-11.3-x86_64-i386-64bit\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.1\r\n          pip: 22.3.1\r\n   setuptools: 67.3.2\r\n        numpy: 1.23.5\r\n        scipy: 1.10.1\r\n       Cython: None\r\n       pandas: 1.4.4\r\n   matplotlib: 3.7.0\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/numpy/.dylibs/libopenblas64_.0.dylib\r\n        version: 0.3.20\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 4\r\n\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libomp\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/sklearn/.dylibs/libomp.dylib\r\n        version: None\r\n    num_threads: 8\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /Users/macbookpro/.local/share/virtualenvs/3e_VBrf2/lib/python3.10/site-packages/scipy/.dylibs/libopenblas.0.dylib\r\n        version: 0.3.18\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 4\n```\n\n", "patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -34,7 +34,7 @@ def _wrap_in_pandas_container(\n         `range(n_features)`.\n \n     index : array-like, default=None\n-        Index for data.\n+        Index for data. `index` is ignored if `data_to_wrap` is already a DataFrame.\n \n     Returns\n     -------\n@@ -55,8 +55,6 @@ def _wrap_in_pandas_container(\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n-            data_to_wrap.index = index\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n"}}
{"instance_id": "sympy__sympy-15678", "found_files": ["sympy/geometry/util.py", "sympy/solvers/solvers.py", "sympy/core/function.py"], "found_modules": ["sympy/geometry/util.py:idiff", "sympy/solvers/solvers.py:solve", "sympy/core/function.py:Function"], "found_entities": ["sympy/geometry/util.py:idiff", "sympy/solvers/solvers.py:solve", "sympy/core/function.py:Function.__new__", "sympy/core/function.py:Function._eval_derivative"], "raw_output_loc": ["```\nsympy/geometry/util.py\nline: 568\nline: 574\nline: 582\nfunction: idiff\n\nsympy/solvers/solvers.py\nline: 582\nfunction: solve\n\nsympy/core/function.py\nline: 574\nclass: Function\nfunction: Function.__new__\n```", "```\nsympy/geometry/util.py\nline: 574\nfunction: idiff\n\nsympy/geometry/util.py\nline: 582\nfunction: idiff\n\nsympy/core/function.py\nclass: Function\nfunction: Function.__new__\n\nsympy/solvers/solvers.py\nfunction: solve\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "31c68eef3ffef39e2e792b0ec92cd92b7010eb2a", "problem_statement": "Some issues with idiff\nidiff doesn't support Eq, and it also doesn't support f(x) instead of y. Both should be easy to correct.\r\n\r\n```\r\n>>> idiff(Eq(y*exp(y), x*exp(x)), y, x)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"./sympy/geometry/util.py\", line 582, in idiff\r\n    yp = solve(eq.diff(x), dydx)[0].subs(derivs)\r\nIndexError: list index out of range\r\n>>> idiff(f(x)*exp(f(x)) - x*exp(x), f(x), x)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"./sympy/geometry/util.py\", line 574, in idiff\r\n    raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\r\nValueError: expecting x-dependent symbol(s) but got: f(x)\r\n>>> idiff(y*exp(y)- x*exp(x), y, x)\r\n(x + 1)*exp(x - y)/(y + 1)\r\n```\n", "patch": "diff --git a/sympy/geometry/util.py b/sympy/geometry/util.py\n--- a/sympy/geometry/util.py\n+++ b/sympy/geometry/util.py\n@@ -570,12 +570,19 @@ def idiff(eq, y, x, n=1):\n         y = y[0]\n     elif isinstance(y, Symbol):\n         dep = {y}\n+    elif isinstance(y, Function):\n+        pass\n     else:\n-        raise ValueError(\"expecting x-dependent symbol(s) but got: %s\" % y)\n+        raise ValueError(\"expecting x-dependent symbol(s) or function(s) but got: %s\" % y)\n \n     f = dict([(s, Function(\n         s.name)(x)) for s in eq.free_symbols if s != x and s in dep])\n-    dydx = Function(y.name)(x).diff(x)\n+\n+    if isinstance(y, Symbol):\n+        dydx = Function(y.name)(x).diff(x)\n+    else:\n+        dydx = y.diff(x)\n+\n     eq = eq.subs(f)\n     derivs = {}\n     for i in range(n):\n"}}
{"instance_id": "pytest-dev__pytest-9359", "found_files": ["src/_pytest/terminal.py", "src/_pytest/assertion/rewrite.py", "src/_pytest/assertion/util.py", "src/_pytest/_io/terminalwriter.py"], "found_modules": ["src/_pytest/terminal.py:TerminalReporter", "src/_pytest/assertion/rewrite.py:_get_assertion_exprs", "src/_pytest/assertion/util.py:_diff_text", "src/_pytest/assertion/rewrite.py:AssertionRewriter", "src/_pytest/assertion/util.py:assertrepr_compare", "src/_pytest/_io/terminalwriter.py:TerminalWriter"], "found_entities": ["src/_pytest/terminal.py:TerminalReporter._locationline", "src/_pytest/assertion/rewrite.py:_get_assertion_exprs", "src/_pytest/terminal.py:TerminalReporter.pytest_runtest_logreport", "src/_pytest/assertion/rewrite.py:_get_assertion_exprs._write_and_reset", "src/_pytest/assertion/util.py:_diff_text", "src/_pytest/assertion/rewrite.py:AssertionRewriter.visit_Assert", "src/_pytest/assertion/util.py:assertrepr_compare", "src/_pytest/_io/terminalwriter.py:TerminalWriter.write"], "raw_output_loc": ["```\nsrc/_pytest/terminal.py:TerminalReporter._locationline\nline: 848-869\nfunction: TerminalReporter._locationline\n\nsrc/_pytest/terminal.py:TerminalReporter.pytest_runtest_logreport\nline: 509-568\nfunction: TerminalReporter.pytest_runtest_logreport\n\nsrc/_pytest/assertion/util.py:_diff_text\nline: 215-260\nfunction: _diff_text\n\nsrc/_pytest/assertion/util.py:assertrepr_compare\nline: 138-175\nfunction: assertrepr_compare\n\nsrc/_pytest/_io/terminalwriter.py:TerminalWriter.write\nline: 144-167\nfunction: TerminalWriter.write\n```", "```\nsrc/_pytest/assertion/rewrite.py\nline: 576\nfunction: _get_assertion_exprs\n\nsrc/_pytest/assertion/rewrite.py\nline: 567\nfunction: _get_assertion_exprs._write_and_reset\n\nsrc/_pytest/assertion/rewrite.py\nline: 846\nclass: AssertionRewriter\nfunction: AssertionRewriter.visit_Assert\n\nsrc/_pytest/assertion/rewrite.py\nline: 558\nfunction: _get_assertion_exprs\n\nsrc/_pytest/assertion/rewrite.py\nline: 847\nfunction: AssertionRewriter.visit_Assert\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "e2ee3144ed6e241dea8d96215fcdca18b3892551", "problem_statement": "Error message prints extra code line when using assert in python3.9\n<!--\r\nThanks for submitting an issue!\r\n\r\nQuick check-list while reporting bugs:\r\n-->\r\n\r\n- [x] a detailed description of the bug or problem you are having\r\n- [x] output of `pip list` from the virtual environment you are using\r\n- [x] pytest and operating system versions\r\n- [ ] minimal example if possible\r\n### Description\r\nI have a test like this:\r\n```\r\nfrom pytest import fixture\r\n\r\n\r\ndef t(foo):\r\n    return foo\r\n\r\n\r\n@fixture\r\ndef foo():\r\n    return 1\r\n\r\n\r\ndef test_right_statement(foo):\r\n    assert foo == (3 + 2) * (6 + 9)\r\n\r\n    @t\r\n    def inner():\r\n        return 2\r\n\r\n    assert 2 == inner\r\n\r\n\r\n@t\r\ndef outer():\r\n    return 2\r\n```\r\nThe test \"test_right_statement\" fails at the first assertion,but print extra code (the \"t\" decorator) in error details, like this:\r\n\r\n```\r\n ============================= test session starts =============================\r\nplatform win32 -- Python 3.9.6, pytest-6.2.5, py-1.10.0, pluggy-0.13.1 -- \r\ncachedir: .pytest_cache\r\nrootdir: \r\nplugins: allure-pytest-2.9.45\r\ncollecting ... collected 1 item\r\n\r\ntest_statement.py::test_right_statement FAILED                           [100%]\r\n\r\n================================== FAILURES ===================================\r\n____________________________ test_right_statement _____________________________\r\n\r\nfoo = 1\r\n\r\n    def test_right_statement(foo):\r\n>       assert foo == (3 + 2) * (6 + 9)\r\n    \r\n        @t\r\nE       assert 1 == 75\r\nE         +1\r\nE         -75\r\n\r\ntest_statement.py:14: AssertionError\r\n=========================== short test summary info ===========================\r\nFAILED test_statement.py::test_right_statement - assert 1 == 75\r\n============================== 1 failed in 0.12s ==============================\r\n```\r\nAnd the same thing **did not** happen when using python3.7.10\uff1a\r\n```\r\n============================= test session starts =============================\r\nplatform win32 -- Python 3.7.10, pytest-6.2.5, py-1.11.0, pluggy-1.0.0 -- \r\ncachedir: .pytest_cache\r\nrootdir: \r\ncollecting ... collected 1 item\r\n\r\ntest_statement.py::test_right_statement FAILED                           [100%]\r\n\r\n================================== FAILURES ===================================\r\n____________________________ test_right_statement _____________________________\r\n\r\nfoo = 1\r\n\r\n    def test_right_statement(foo):\r\n>       assert foo == (3 + 2) * (6 + 9)\r\nE       assert 1 == 75\r\nE         +1\r\nE         -75\r\n\r\ntest_statement.py:14: AssertionError\r\n=========================== short test summary info ===========================\r\nFAILED test_statement.py::test_right_statement - assert 1 == 75\r\n============================== 1 failed in 0.03s ==============================\r\n```\r\nIs there some problems when calculate the statement lineno?\r\n\r\n### pip list \r\n```\r\n$ pip list\r\nPackage            Version\r\n------------------ -------\r\natomicwrites       1.4.0\r\nattrs              21.2.0\r\ncolorama           0.4.4\r\nimportlib-metadata 4.8.2\r\niniconfig          1.1.1\r\npackaging          21.3\r\npip                21.3.1\r\npluggy             1.0.0\r\npy                 1.11.0\r\npyparsing          3.0.6\r\npytest             6.2.5\r\nsetuptools         59.4.0\r\ntoml               0.10.2\r\ntyping_extensions  4.0.0\r\nzipp               3.6.0\r\n\r\n```\r\n### pytest and operating system versions\r\npytest 6.2.5\r\nWindows 10 \r\nSeems to happen in python 3.9,not 3.7\r\n\n", "patch": "diff --git a/src/_pytest/_code/source.py b/src/_pytest/_code/source.py\n--- a/src/_pytest/_code/source.py\n+++ b/src/_pytest/_code/source.py\n@@ -149,6 +149,11 @@ def get_statement_startend2(lineno: int, node: ast.AST) -> Tuple[int, Optional[i\n     values: List[int] = []\n     for x in ast.walk(node):\n         if isinstance(x, (ast.stmt, ast.ExceptHandler)):\n+            # Before Python 3.8, the lineno of a decorated class or function pointed at the decorator.\n+            # Since Python 3.8, the lineno points to the class/def, so need to include the decorators.\n+            if isinstance(x, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)):\n+                for d in x.decorator_list:\n+                    values.append(d.lineno - 1)\n             values.append(x.lineno - 1)\n             for name in (\"finalbody\", \"orelse\"):\n                 val: Optional[List[ast.stmt]] = getattr(x, name, None)\n"}}
{"instance_id": "django__django-16527", "found_files": ["django/contrib/admin/templatetags/admin_modify.py"], "found_modules": ["django/contrib/admin/templatetags/admin_modify.py:submit_row"], "found_entities": ["django/contrib/admin/templatetags/admin_modify.py:submit_row"], "raw_output_loc": ["```\ndjango/contrib/admin/templatetags/admin_modify.py\nline: 102\nfunction: submit_row\n```", "```\ndjango/contrib/admin/templatetags/admin_modify.py\nline: 102\nfunction: submit_row\n```"], "meta_data": {"repo": "django/django", "base_commit": "bd366ca2aeffa869b7dbc0b0aa01caea75e6dc31", "problem_statement": "\"show_save_as_new\" in admin can add without this permission\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nAt \"django/contrib/admin/templatetags/admin_modify.py\" file, line 102, I think you must put one more verification for this tag: \"and has_add_permission\", because \"save_as_new\" is a add modification.\nI rewrite this for my project:\n\t\t\t\"show_save_as_new\": not is_popup\n\t\t\tand has_add_permission # This line that I put!!!\n\t\t\tand has_change_permission\n\t\t\tand change\n\t\t\tand save_as,\n", "patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -100,7 +100,7 @@ def submit_row(context):\n                 and context.get(\"show_delete\", True)\n             ),\n             \"show_save_as_new\": not is_popup\n-            and has_change_permission\n+            and has_add_permission\n             and change\n             and save_as,\n             \"show_save_and_add_another\": can_save_and_add_another,\n"}}
{"instance_id": "sphinx-doc__sphinx-8474", "found_files": ["sphinx/domains/std.py", "sphinx/environment/collectors/toctree.py"], "found_modules": ["sphinx/domains/std.py:StandardDomain", "sphinx/environment/collectors/toctree.py:TocTreeCollector", "sphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers"], "found_entities": ["sphinx/domains/std.py:StandardDomain._resolve_numref_xref", "sphinx/domains/std.py:StandardDomain.get_fignumber", "sphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers", "sphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers._walk_doctree", "sphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers.register_fignumber", "sphinx/domains/std.py:StandardDomain.get_enumerable_node_type", "sphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers.get_next_fignumber"], "raw_output_loc": ["```\nsphinx/domains/std.py:StandardDomain._resolve_numref_xref\nline: 851\nline: 853\nfunction: StandardDomain._resolve_numref_xref\n\nsphinx/domains/std.py:StandardDomain.get_fignumber\nline: 1058\nline: 1077\nfunction: StandardDomain.get_fignumber\n\nsphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers\nline: 213\nline: 258\nfunction: TocTreeCollector.assign_figure_numbers\n\nsphinx/domains/std.py:StandardDomain.get_enumerable_node_type\nline: 1042\nline: 1056\nfunction: StandardDomain.get_enumerable_node_type\n\nsphinx/domains/std.py:StandardDomain\nfunction: StandardDomain\n```", "```\nsphinx/domains/std.py:StandardDomain._resolve_numref_xref\nline: 855\nline: 856\nfunction: StandardDomain._resolve_numref_xref\n\nsphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers\nline: 276\nline: 278\nfunction: TocTreeCollector.assign_figure_numbers\n\nsphinx/domains/std.py:StandardDomain.get_fignumber\nline: 1058\nline: 1076\nfunction: StandardDomain.get_fignumber\n\nsphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers.register_fignumber\nline: 258\nfunction: TocTreeCollector.assign_figure_numbers.register_fignumber\n\nsphinx/environment/collectors/toctree.py:TocTreeCollector.assign_figure_numbers.get_next_fignumber\nline: 250\nfunction: TocTreeCollector.assign_figure_numbers.get_next_fignumber\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "3ea1ec84cc610f7a9f4f6b354e264565254923ff", "problem_statement": "v3.3 upgrade started generating \"WARNING: no number is assigned for table\" warnings\nWe've updated to Sphinx 3.3 in our documentation, and suddenly the following warning started popping up in our builds when we build either `singlehtml` or `latex`.:\r\n\r\n`WARNING: no number is assigned for table:`\r\n\r\nI looked through the changelog but it didn't seem like there was anything related to `numref` that was changed, but perhaps I missed something? Could anyone point me to a change in the numref logic so I can figure out where these warnings are coming from?\n", "patch": "diff --git a/sphinx/domains/std.py b/sphinx/domains/std.py\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -852,8 +852,9 @@ def _resolve_numref_xref(self, env: \"BuildEnvironment\", fromdocname: str,\n             if fignumber is None:\n                 return contnode\n         except ValueError:\n-            logger.warning(__(\"no number is assigned for %s: %s\"), figtype, labelid,\n-                           location=node)\n+            logger.warning(__(\"Failed to create a cross reference. Any number is not \"\n+                              \"assigned: %s\"),\n+                           labelid, location=node)\n             return contnode\n \n         try:\n"}}
{"instance_id": "django__django-11815", "found_files": ["django/db/migrations/serializer.py", "django/db/migrations/writer.py", "django/db/models/fields/__init__.py"], "found_modules": ["django/db/migrations/serializer.py:EnumSerializer", "django/db/migrations/writer.py:MigrationWriter", "django/db/models/fields/__init__.py:CharField"], "found_entities": ["django/db/migrations/serializer.py:EnumSerializer.serialize", "django/db/migrations/writer.py:MigrationWriter.serialize"], "raw_output_loc": ["```\ndjango/db/migrations/serializer.py\nline: 119\nclass: EnumSerializer\nfunction: EnumSerializer.serialize\n\ndjango/db/migrations/writer.py\nline: 270\nfunction: MigrationWriter.serialize\n\ndjango/db/models/fields/__init__.py\nline: 968\nclass: CharField\nfunction: CharField.__init__\n```", "```\ndjango/db/migrations/serializer.py\nline: 123\nclass: EnumSerializer\nfunction: EnumSerializer.serialize\n```"], "meta_data": {"repo": "django/django", "base_commit": "e02f67ef2d03d48128e7a118bf75f0418e24e8ac", "problem_statement": "Migrations uses value of enum object instead of its name.\nDescription\n\t \n\t\t(last modified by oasl)\n\t \nWhen using Enum object as a default value for a CharField, the generated migration file uses the value of the Enum object instead of the its name. This causes a problem when using Django translation on the value of the Enum object. \nThe problem is that, when the Enum object value get translated to the users language, the old migration files raise an error stating that the Enum does not have the corresponding value. (because the Enum value is translated to another language)\nExample:\nLet say we have this code in models.py:\nfrom enum import Enum\nfrom django.utils.translation import gettext_lazy as _\nfrom django.db import models\nclass Status(Enum):\n\tGOOD = _('Good') # 'Good' will be translated\n\tBAD = _('Bad') # 'Bad' will be translated\n\tdef __str__(self):\n\t\treturn self.name\nclass Item(models.Model):\n\tstatus = models.CharField(default=Status.GOOD, max_length=128)\nIn the generated migration file, the code will be:\n...\n('status', models.CharField(default=Status('Good'), max_length=128))\n...\nAfter the translation, 'Good' will be translated to another word and it will not be part of the Status Enum class any more, so the migration file will raise the error on the previous line:\nValueError: 'Good' is not a valid Status\nShouldn't the code generated by the migration uses the name of the Status Enum 'GOOD', not the value of it, since it is changeable?\nIt should be:\n('status', models.CharField(default=Status['GOOD'], max_length=128))\nThis will be correct regardless of the translated word\n", "patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,10 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        return (\n+            '%s.%s[%r]' % (module, enum_class.__name__, self.value.name),\n+            {'import %s' % module},\n+        )\n \n \n class FloatSerializer(BaseSimpleSerializer):\n"}}
{"instance_id": "sympy__sympy-24152", "found_files": ["sympy/physics/quantum/tensorproduct.py", "sympy/core/mul.py", "sympy/core/add.py"], "found_modules": ["sympy/physics/quantum/tensorproduct.py:TensorProduct", "sympy/core/add.py:Add"], "found_entities": ["sympy/physics/quantum/tensorproduct.py:TensorProduct._eval_expand_tensorproduct", "sympy/physics/quantum/tensorproduct.py:TensorProduct.__new__"], "raw_output_loc": ["```\nsympy/physics/quantum/tensorproduct.py\nline: 241\nfunction: TensorProduct._eval_expand_tensorproduct\n\nsympy/core/mul.py\nfunction: Mul.args_cnc\n\nsympy/core/add.py\nfunction: Add\n```", "```\nsympy/physics/quantum/tensorproduct.py\nline: 248\nline: 249\nline: 250\nline: 251\nclass: TensorProduct\nfunction: TensorProduct._eval_expand_tensorproduct\n\nsympy/physics/quantum/tensorproduct.py\nline: 122\nline: 123\nline: 124\nline: 125\nline: 126\nline: 127\nline: 128\nline: 129\nline: 130\nline: 131\nline: 132\nline: 133\nclass: TensorProduct\nfunction: TensorProduct.__new__\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "b9af885473ad7e34b5b0826cb424dd26d8934670", "problem_statement": "Bug in expand of TensorProduct + Workaround + Fix\n### Error description\r\nThe expansion of a TensorProduct object stops incomplete if summands in the tensor product factors have (scalar) factors, e.g.\r\n```\r\nfrom sympy import *\r\nfrom sympy.physics.quantum import *\r\nU = Operator('U')\r\nV = Operator('V')\r\nP = TensorProduct(2*U - V, U + V)\r\nprint(P) \r\n# (2*U - V)x(U + V)\r\nprint(P.expand(tensorproduct=True)) \r\n#result: 2*Ux(U + V) - Vx(U + V) #expansion has missed 2nd tensor factor and is incomplete\r\n```\r\nThis is clearly not the expected behaviour. It also effects other functions that rely on .expand(tensorproduct=True), as e.g. qapply() .\r\n\r\n### Work around\r\nRepeat .expand(tensorproduct=True) as may times as there are tensor factors, resp. until the expanded term does no longer change. This is however only reasonable in interactive session and not in algorithms.\r\n\r\n### Code Fix\r\n.expand relies on the method TensorProduct._eval_expand_tensorproduct(). The issue arises from an inprecise check in TensorProduct._eval_expand_tensorproduct() whether a recursive call is required; it fails when the creation of a TensorProduct object returns commutative (scalar) factors up front: in that case the constructor returns a Mul(c_factors, TensorProduct(..)).\r\nI thus propose the following  code fix in TensorProduct._eval_expand_tensorproduct() in quantum/tensorproduct.py.  I have marked the four lines to be added / modified:\r\n```\r\n    def _eval_expand_tensorproduct(self, **hints):\r\n                ...\r\n                for aa in args[i].args:\r\n                    tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\r\n                    c_part, nc_part = tp.args_cnc() #added\r\n                    if len(nc_part)==1 and isinstance(nc_part[0], TensorProduct): #modified\r\n                        nc_part = (nc_part[0]._eval_expand_tensorproduct(), ) #modified\r\n                    add_args.append(Mul(*c_part)*Mul(*nc_part)) #modified\r\n                break\r\n                ...\r\n```\r\nThe fix splits of commutative (scalar) factors from the tp returned. The TensorProduct object will be the one nc factor in nc_part (see TensorProduct.__new__ constructor), if any. Note that the constructor will return 0 if a tensor factor is 0, so there is no guarantee that tp contains a TensorProduct object (e.g. TensorProduct(U-U, U+V).\r\n\r\n\r\n\n", "patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -246,9 +246,12 @@ def _eval_expand_tensorproduct(self, **hints):\n             if isinstance(args[i], Add):\n                 for aa in args[i].args:\n                     tp = TensorProduct(*args[:i] + (aa,) + args[i + 1:])\n-                    if isinstance(tp, TensorProduct):\n-                        tp = tp._eval_expand_tensorproduct()\n-                    add_args.append(tp)\n+                    c_part, nc_part = tp.args_cnc()\n+                    # Check for TensorProduct object: is the one object in nc_part, if any:\n+                    # (Note: any other object type to be expanded must be added here)\n+                    if len(nc_part) == 1 and isinstance(nc_part[0], TensorProduct):\n+                        nc_part = (nc_part[0]._eval_expand_tensorproduct(), )\n+                    add_args.append(Mul(*c_part)*Mul(*nc_part))\n                 break\n \n         if add_args:\n"}}
{"instance_id": "django__django-14999", "found_files": ["django/db/migrations/operations/models.py"], "found_modules": ["django/db/migrations/operations/models.py:RenameModel"], "found_entities": ["django/db/migrations/operations/models.py:RenameModel.database_forwards"], "raw_output_loc": ["```\ndjango/db/migrations/operations/models.py\nline: 319\nclass: RenameModel\nfunction: RenameModel.database_forwards\n\n```", "```\ndjango/db/migrations/operations/models.py\nline: 324\nclass: RenameModel\nfunction: RenameModel.database_forwards\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "a754b82dac511475b6276039471ccd17cc64aeb8", "problem_statement": "RenameModel with db_table should be a noop.\nDescription\n\t\nA RenameModel operation that already has db_table defined must be a noop.\nIn Postgres, it drops and recreates foreign key constraints. In sqlite it recreates the table (as expected for a table renaming).\n", "patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,12 +320,13 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            old_db_table = old_model._meta.db_table\n+            new_db_table = new_model._meta.db_table\n+            # Don't alter when a table name is not changed.\n+            if old_db_table == new_db_table:\n+                return\n             # Move the main table\n-            schema_editor.alter_db_table(\n-                new_model,\n-                old_model._meta.db_table,\n-                new_model._meta.db_table,\n-            )\n+            schema_editor.alter_db_table(new_model, old_db_table, new_db_table)\n             # Alter the fields pointing to us\n             for related_object in old_model._meta.related_objects:\n                 if related_object.related_model == old_model:\n"}}
{"instance_id": "sympy__sympy-20212", "found_files": ["sympy/core/power.py", "sympy/core/numbers.py"], "found_modules": ["sympy/core/power.py:Pow", "sympy/core/numbers.py:ComplexInfinity"], "found_entities": ["sympy/core/numbers.py:ComplexInfinity._eval_power", "sympy/core/power.py:Pow.__new__"], "raw_output_loc": ["```\nsympy/core/power.py\nline: 300\nclass: Pow\nfunction: Pow.__new__\n\nsympy/core/numbers.py\nline: 3344\nclass: ComplexInfinity\nfunction: ComplexInfinity._eval_power\n```", "```\nsympy/core/power.py\nline: 210\nfunction: Pow\n\nsympy/core/numbers.py\nline: 3345\nfunction: ComplexInfinity._eval_power\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "a106f4782a9dbe7f8fd16030f15401d977e03ae9", "problem_statement": "0**-oo produces 0, the documentation says it should produce zoo\nUsing SymPy 1.5.1, evaluate `0**-oo` produces `0`.\r\n\r\nThe documentation for the Pow class states that it should return `ComplexInfinity`, aka `zoo`\r\n\r\n| expr | value | reason |\r\n| :-- | :-- | :--|\r\n| `0**-oo` | `zoo` | This is not strictly true, as 0**oo may be oscillating between positive and negative values or rotating in the complex plane. It is convenient, however, when the base is positive.|\r\n\n", "patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -291,6 +291,8 @@ def __new__(cls, b, e, evaluate=None):\n             ).warn()\n \n         if evaluate:\n+            if b is S.Zero and e is S.NegativeInfinity:\n+                return S.ComplexInfinity\n             if e is S.ComplexInfinity:\n                 return S.NaN\n             if e is S.Zero:\n"}}
{"instance_id": "sympy__sympy-12481", "found_files": ["sympy/combinatorics/permutations.py"], "found_modules": ["sympy/combinatorics/permutations.py:Permutation"], "found_entities": ["sympy/combinatorics/permutations.py:Permutation.__new__", "sympy/combinatorics/permutations.py:Permutation.cycles", "sympy/combinatorics/permutations.py:Permutation.array_form", "sympy/combinatorics/permutations.py:Permutation.cyclic_form", "sympy/combinatorics/permutations.py:Permutation.full_cyclic_form"], "raw_output_loc": ["```\nsympy/combinatorics/permutations.py\nline: 897\nfunction: Permutation.__new__\n\nsympy/combinatorics/permutations.py\nline: 900\nfunction: Permutation.__new__\n\nsympy/combinatorics/permutations.py\nline: 903\nfunction: Permutation.__new__\n```", "```\nsympy/combinatorics/permutations.py\nclass: Permutation\nfunction: Permutation.__new__\n\nsympy/combinatorics/permutations.py\nfunction: Permutation.cycles\n\nsympy/combinatorics/permutations.py\nfunction: Permutation.array_form\n\nsympy/combinatorics/permutations.py\nfunction: Permutation.cyclic_form\n\nsympy/combinatorics/permutations.py\nfunction: Permutation.full_cyclic_form\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "c807dfe7569692cad24f02a08477b70c1679a4dd", "problem_statement": "`Permutation` constructor fails with non-disjoint cycles\nCalling `Permutation([[0,1],[0,1]])` raises a `ValueError` instead of constructing the identity permutation.  If the cycles passed in are non-disjoint, they should be applied in left-to-right order and the resulting permutation should be returned.\r\n\r\nThis should be easy to compute.  I don't see a reason why non-disjoint cycles should be forbidden.\n", "patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -895,12 +895,8 @@ def __new__(cls, *args, **kwargs):\n         # counting starts from 1.\n \n         temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n-                raise ValueError('there were repeated elements.')\n+        if has_dups(temp) and not is_cycle:\n+            raise ValueError('there were repeated elements.')\n         temp = set(temp)\n \n         if not is_cycle and \\\n"}}
{"instance_id": "sympy__sympy-13915", "found_files": ["sympy/core/basic.py", "sympy/series/limits.py", "sympy/core/add.py", "sympy/core/expr.py", "sympy/core/mul.py", "sympy/core/power.py"], "found_modules": ["sympy/core/basic.py:Basic", "sympy/series/limits.py:limit", "sympy/core/add.py:Add", "sympy/core/expr.py:Expr", "sympy/core/mul.py:Mul", "sympy/core/power.py:Pow"], "found_entities": ["sympy/core/basic.py:Basic.subs", "sympy/core/basic.py:Basic._subs", "sympy/series/limits.py:limit", "sympy/core/add.py:Add._eval_subs", "sympy/core/expr.py:Expr.limit", "sympy/core/mul.py:Mul._eval_subs", "sympy/core/power.py:Pow._eval_subs"], "raw_output_loc": ["```\nsympy/core/basic.py\nline: 727\nfunction: Basic.subs\n\nsympy/core/basic.py\nline: 926\nfunction: Basic._subs\n\nsympy/core/add.py\nline: 721\nfunction: Add._eval_subs\n\nsympy/core/mul.py\nline: 1340\nfunction: Mul._eval_subs\n\nsympy/core/power.py\nline: 578\nfunction: Pow._eval_subs\n\nsympy/series/limits.py\nline: 17\nfunction: limit\n```", "```\nsympy/core/basic.py:Basic._subs\nline: 926\nfunction: Basic._subs\n\nsympy/core/basic.py:Basic.subs\nline: 727\nfunction: Basic.subs\n\nsympy/core/expr.py:Expr.limit\nline: 2868\nfunction: Expr.limit\n\nsympy/series/limits.py:limit\nfunction: limit\n\nsympy/core/expr.py:Expr._eval_subs\nfunction: Expr._eval_subs\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "5c1644ff85e15752f9f8721bc142bfbf975e7805", "problem_statement": "Issue with a substitution that leads to an undefined expression\n```\r\nPython 3.6.4 |Anaconda custom (64-bit)| (default, Dec 21 2017, 15:39:08) \r\nType 'copyright', 'credits' or 'license' for more information\r\nIPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.\r\n\r\nIn [1]: from sympy import *\r\n\r\nIn [2]: a,b = symbols('a,b')\r\n\r\nIn [3]: r = (1/(a+b) + 1/(a-b))/(1/(a+b) - 1/(a-b))\r\n\r\nIn [4]: r.subs(b,a)\r\nOut[4]: 1\r\n\r\nIn [6]: import sympy\r\n\r\nIn [7]: sympy.__version__\r\nOut[7]: '1.1.1'\r\n```\r\n\r\nIf b is substituted by a, r is undefined. It is possible to calculate the limit\r\n`r.limit(b,a) # -1`\r\n\r\nBut whenever a subexpression of r is undefined, r itself is undefined.\n", "patch": "diff --git a/sympy/core/mul.py b/sympy/core/mul.py\n--- a/sympy/core/mul.py\n+++ b/sympy/core/mul.py\n@@ -423,6 +423,11 @@ def _gather(c_powers):\n             changed = False\n             for b, e in c_powers:\n                 if e.is_zero:\n+                    # canceling out infinities yields NaN\n+                    if (b.is_Add or b.is_Mul) and any(infty in b.args\n+                        for infty in (S.ComplexInfinity, S.Infinity,\n+                                      S.NegativeInfinity)):\n+                        return [S.NaN], [], None\n                     continue\n                 if e is S.One:\n                     if b.is_Number:\n"}}
{"instance_id": "scikit-learn__scikit-learn-15535", "found_files": ["sklearn/utils/validation.py", "sklearn/metrics/cluster/_supervised.py", "sklearn/utils/fixes.py"], "found_modules": ["sklearn/utils/validation.py:check_array", "sklearn/metrics/cluster/_supervised.py:check_clusterings", "sklearn/metrics/cluster/_supervised.py:mutual_info_score", "sklearn/utils/validation.py:_assert_all_finite", "sklearn/utils/fixes.py:_object_dtype_isnan"], "found_entities": ["sklearn/utils/validation.py:check_array", "sklearn/metrics/cluster/_supervised.py:check_clusterings", "sklearn/metrics/cluster/_supervised.py:mutual_info_score", "sklearn/utils/validation.py:_assert_all_finite", "sklearn/utils/fixes.py:_object_dtype_isnan"], "raw_output_loc": ["```\nsklearn/utils/validation.py:check_array\nline: 461\nfunction: check_array\n\nsklearn/utils/validation.py:_assert_all_finite\nline: 62\nfunction: _assert_all_finite\n\nsklearn/utils/fixes.py:_object_dtype_isnan\nline: 185\nfunction: _object_dtype_isnan\n\nsklearn/metrics/cluster/_supervised.py:mutual_info_score\nline: 619\nfunction: mutual_info_score\n\nsklearn/metrics/cluster/_supervised.py:check_clusterings\nline: 45\nfunction: check_clusterings\n```", "```\nsklearn/utils/validation.py\nline: 461\nline: 554\nfunction: check_array\n\nsklearn/metrics/cluster/_supervised.py\nline: 45\nline: 49\nfunction: check_clusterings\n\nsklearn/metrics/cluster/_supervised.py\nline: 619\nfunction: mutual_info_score\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "70b0ddea992c01df1a41588fa9e2d130fb6b13f8", "problem_statement": "regression in input validation of clustering metrics\n```python\r\nfrom sklearn.metrics.cluster import mutual_info_score\r\nimport numpy as np\r\n\r\nx = np.random.choice(['a', 'b'], size=20).astype(object)\r\nmutual_info_score(x, x)\r\n```\r\nValueError: could not convert string to float: 'b'\r\n\r\nwhile\r\n```python\r\nx = np.random.choice(['a', 'b'], size=20)\r\nmutual_info_score(x, x)\r\n```\r\nworks with a warning?\r\n\r\nthis worked in 0.21.1 without a warning (as I think it should)\r\n\r\n\r\nEdit by @ogrisel: I removed the `.astype(object)` in the second code snippet.\n", "patch": "diff --git a/sklearn/metrics/cluster/_supervised.py b/sklearn/metrics/cluster/_supervised.py\n--- a/sklearn/metrics/cluster/_supervised.py\n+++ b/sklearn/metrics/cluster/_supervised.py\n@@ -43,10 +43,10 @@ def check_clusterings(labels_true, labels_pred):\n         The predicted labels.\n     \"\"\"\n     labels_true = check_array(\n-        labels_true, ensure_2d=False, ensure_min_samples=0\n+        labels_true, ensure_2d=False, ensure_min_samples=0, dtype=None,\n     )\n     labels_pred = check_array(\n-        labels_pred, ensure_2d=False, ensure_min_samples=0\n+        labels_pred, ensure_2d=False, ensure_min_samples=0, dtype=None,\n     )\n \n     # input checks\n"}}
{"instance_id": "psf__requests-2148", "found_files": ["requests/packages/urllib3/response.py", "requests/adapters.py", "requests/models.py", "requests/exceptions.py"], "found_modules": ["requests/packages/urllib3/response.py:HTTPResponse", "requests/adapters.py:HTTPAdapter", "requests/models.py:Response", "requests/models.py:Response.iter_content", "requests/exceptions.py:ConnectionError"], "found_entities": ["requests/packages/urllib3/response.py:HTTPResponse.read", "requests/adapters.py:HTTPAdapter.send", "requests/models.py:Response.iter_content.generate", "requests/packages/urllib3/response.py:HTTPResponse.from_httplib", "requests/models.py:Response.iter_content", "requests/models.py:Response.text", "requests/models.py:Response.content"], "raw_output_loc": ["```\nrequests/packages/urllib3/response.py\nline: 195\nline: 200\nline: 209\nfunction: HTTPResponse.read\n\nrequests/models.py\nline: 637\nline: 640\nline: 642\nfunction: Response.iter_content\n\nrequests/exceptions.py\nfunction: ConnectionError\n```", "```\nrequests/adapters.py:HTTPAdapter.send\nline: 389\nfunction: HTTPAdapter.send\n\nrequests/packages/urllib3/response.py:HTTPResponse.from_httplib\nline: 259\nfunction: HTTPResponse.from_httplib\n\nrequests/exceptions.py:ConnectionError\nline: 34\nfunction: ConnectionError\n\nrequests/models.py:Response.text\nline: 721\nfunction: Response.text\n\nrequests/models.py:Response.content\nline: 694\nfunction: Response.content\n```"], "meta_data": {"repo": "psf/requests", "base_commit": "fe693c492242ae532211e0c173324f09ca8cf227", "problem_statement": "socket.error exception not caught/wrapped in a requests exception (ConnectionError perhaps?)\nI just noticed a case where I had a socket reset on me, and was raised to me as a raw socket error as opposed to something like a requests.exceptions.ConnectionError:\n\n```\n  File \"/home/rtdean/***/***/***/***/***/***.py\", line 67, in dir_parse\n    root = ElementTree.fromstring(response.text)\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/requests-2.3.0-py2.7.egg/requests/models.py\", line 721, in text\n    if not self.content:\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/requests-2.3.0-py2.7.egg/requests/models.py\", line 694, in content\n    self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/requests-2.3.0-py2.7.egg/requests/models.py\", line 627, in generate\n    for chunk in self.raw.stream(chunk_size, decode_content=True):\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/requests-2.3.0-py2.7.egg/requests/packages/urllib3/response.py\", line 240, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/requests-2.3.0-py2.7.egg/requests/packages/urllib3/response.py\", line 187, in read\n    data = self._fp.read(amt)\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/httplib.py\", line 543, in read\n    return self._read_chunked(amt)\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/httplib.py\", line 612, in _read_chunked\n    value.append(self._safe_read(chunk_left))\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/httplib.py\", line 658, in _safe_read\n    chunk = self.fp.read(min(amt, MAXAMOUNT))\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/socket.py\", line 380, in read\n    data = self._sock.recv(left)\n  File \"/home/rtdean/.pyenv/versions/2.7.6/lib/python2.7/site-packages/gevent-1.0.1-py2.7-linux-x86_64.egg/gevent/socket.py\", line 385, in recv\n    return sock.recv(*args)\nsocket.error: [Errno 104] Connection reset by peer\n```\n\nNot sure if this is by accident or design... in general, I guess I'd expect a requests exception when using requests, but I can start looking for socket errors and the like as well.\n\n", "patch": "diff --git a/requests/models.py b/requests/models.py\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -9,6 +9,7 @@\n \n import collections\n import datetime\n+import socket\n \n from io import BytesIO, UnsupportedOperation\n from .hooks import default_hooks\n@@ -22,7 +23,7 @@\n from .packages.urllib3.exceptions import DecodeError\n from .exceptions import (\n     HTTPError, RequestException, MissingSchema, InvalidURL,\n-    ChunkedEncodingError, ContentDecodingError)\n+    ChunkedEncodingError, ContentDecodingError, ConnectionError)\n from .utils import (\n     guess_filename, get_auth_from_url, requote_uri,\n     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n@@ -640,6 +641,8 @@ def generate():\n                     raise ChunkedEncodingError(e)\n                 except DecodeError as e:\n                     raise ContentDecodingError(e)\n+                except socket.error as e:\n+                    raise ConnectionError(e)\n             except AttributeError:\n                 # Standard file-like object.\n                 while True:\n"}}
{"instance_id": "django__django-14382", "found_files": ["django/core/management/templates.py"], "found_modules": ["django/core/management/templates.py:TemplateCommand"], "found_entities": ["django/core/management/templates.py:TemplateCommand.handle"], "raw_output_loc": ["```\ndjango/core/management/templates.py\nline: 77\nclass: TemplateCommand\nfunction: TemplateCommand.handle\n```", "```\ndjango/core/management/templates.py\nline: 77\nclass: TemplateCommand\nfunction: TemplateCommand.handle\n```"], "meta_data": {"repo": "django/django", "base_commit": "29345aecf6e8d53ccb3577a3762bb0c263f7558d", "problem_statement": "django-admin startapp with trailing slash in directory name results in error\nDescription\n\t\nBash tab-completion appends trailing slashes to directory names. django-admin startapp name directory/ results in the error:\nCommandError: '' is not a valid app directory. Please make sure the directory is a valid identifier.\nThe error is caused by \u200bline 77 of django/core/management/templates.py by calling basename() on the path with no consideration for a trailing slash:\nself.validate_name(os.path.basename(target), 'directory')\nRemoving potential trailing slashes would solve the problem:\nself.validate_name(os.path.basename(target.rstrip(os.sep)), 'directory')\n", "patch": "diff --git a/django/core/management/templates.py b/django/core/management/templates.py\n--- a/django/core/management/templates.py\n+++ b/django/core/management/templates.py\n@@ -73,9 +73,9 @@ def handle(self, app_or_project, name, target=None, **options):\n             except OSError as e:\n                 raise CommandError(e)\n         else:\n-            if app_or_project == 'app':\n-                self.validate_name(os.path.basename(target), 'directory')\n             top_dir = os.path.abspath(os.path.expanduser(target))\n+            if app_or_project == 'app':\n+                self.validate_name(os.path.basename(top_dir), 'directory')\n             if not os.path.exists(top_dir):\n                 raise CommandError(\"Destination directory '%s' does not \"\n                                    \"exist, please create it first.\" % top_dir)\n"}}
{"instance_id": "pytest-dev__pytest-7168", "found_files": ["src/_pytest/_io/saferepr.py", "src/_pytest/nodes.py", "src/_pytest/runner.py", "src/_pytest/_code/code.py", "src/_pytest/reports.py", "src/_pytest/python.py"], "found_modules": ["src/_pytest/_io/saferepr.py:SafeRepr", "src/_pytest/nodes.py:Node", "src/_pytest/runner.py:pytest_runtest_makereport", "src/_pytest/_code/code.py:FormattedExcinfo", "src/_pytest/reports.py:TestReport", "src/_pytest/python.py:Function", "src/_pytest/_io/saferepr.py:_format_repr_exception"], "found_entities": ["src/_pytest/_io/saferepr.py:SafeRepr.repr_instance", "src/_pytest/_io/saferepr.py:SafeRepr.repr", "src/_pytest/runner.py:pytest_runtest_makereport", "src/_pytest/nodes.py:Node._repr_failure_py", "src/_pytest/reports.py:TestReport.from_item_and_call", "src/_pytest/_code/code.py:FormattedExcinfo.repr_args", "src/_pytest/python.py:Function.repr_failure", "src/_pytest/_io/saferepr.py:_format_repr_exception", "src/_pytest/_code/code.py:FormattedExcinfo.repr_locals"], "raw_output_loc": ["```\nsrc/_pytest/_io/saferepr.py\nline: 56\nline: 60\nclass: SafeRepr\nfunction: SafeRepr.repr_instance\n\nsrc/_pytest/runner.py\nline: 284\nfunction: pytest_runtest_makereport\n\nsrc/_pytest/reports.py\nline: 294\nfunction: TestReport.from_item_and_call\n\nsrc/_pytest/python.py\nline: 1541\nfunction: Function.repr_failure\n\nsrc/_pytest/nodes.py\nline: 355\nfunction: Node._repr_failure_py\n```", "```\nsrc/_pytest/_io/saferepr.py\nline: 51\nline: 60\nclass: SafeRepr\nfunction: SafeRepr.repr_instance\n\nsrc/_pytest/_code/code.py\nline: 693\nline: 756\nclass: FormattedExcinfo\nfunction: FormattedExcinfo.repr_args\n\nsrc/_pytest/nodes.py\nline: 355\nfunction: Node._repr_failure_py\n\nsrc/_pytest/_io/saferepr.py\nline: 15\nfunction: _format_repr_exception\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "4787fd64a4ca0dba5528b5651bddd254102fe9f3", "problem_statement": "INTERNALERROR when exception in __repr__\nMinimal code to reproduce the issue: \r\n```python\r\nclass SomeClass:\r\n    def __getattribute__(self, attr):\r\n        raise\r\n    def __repr__(self):\r\n        raise\r\ndef test():\r\n    SomeClass().attr\r\n```\r\nSession traceback:\r\n```\r\n============================= test session starts ==============================\r\nplatform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1 -- /usr/local/opt/python@3.8/bin/python3.8\r\ncachedir: .pytest_cache\r\nrootdir: ******\r\nplugins: asyncio-0.10.0, mock-3.0.0, cov-2.8.1\r\ncollecting ... collected 1 item\r\n\r\ntest_pytest.py::test \r\nINTERNALERROR> Traceback (most recent call last):\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 191, in wrap_session\r\nINTERNALERROR>     session.exitstatus = doit(config, session) or 0\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 247, in _main\r\nINTERNALERROR>     config.hook.pytest_runtestloop(session=session)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 208, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/main.py\", line 272, in pytest_runtestloop\r\nINTERNALERROR>     item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 208, in _multicall\r\nINTERNALERROR>     return outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 85, in pytest_runtest_protocol\r\nINTERNALERROR>     runtestprotocol(item, nextitem=nextitem)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 100, in runtestprotocol\r\nINTERNALERROR>     reports.append(call_and_report(item, \"call\", log))\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 188, in call_and_report\r\nINTERNALERROR>     report = hook.pytest_runtest_makereport(item=item, call=call)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/hooks.py\", line 286, in __call__\r\nINTERNALERROR>     return self._hookexec(self, self.get_hookimpls(), kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 93, in _hookexec\r\nINTERNALERROR>     return self._inner_hookexec(hook, methods, kwargs)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/manager.py\", line 84, in <lambda>\r\nINTERNALERROR>     self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 203, in _multicall\r\nINTERNALERROR>     gen.send(outcome)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/skipping.py\", line 129, in pytest_runtest_makereport\r\nINTERNALERROR>     rep = outcome.get_result()\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 80, in get_result\r\nINTERNALERROR>     raise ex[1].with_traceback(ex[2])\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/pluggy/callers.py\", line 187, in _multicall\r\nINTERNALERROR>     res = hook_impl.function(*args)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/runner.py\", line 260, in pytest_runtest_makereport\r\nINTERNALERROR>     return TestReport.from_item_and_call(item, call)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/reports.py\", line 294, in from_item_and_call\r\nINTERNALERROR>     longrepr = item.repr_failure(excinfo)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/python.py\", line 1513, in repr_failure\r\nINTERNALERROR>     return self._repr_failure_py(excinfo, style=style)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/nodes.py\", line 355, in _repr_failure_py\r\nINTERNALERROR>     return excinfo.getrepr(\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 634, in getrepr\r\nINTERNALERROR>     return fmt.repr_excinfo(self)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 879, in repr_excinfo\r\nINTERNALERROR>     reprtraceback = self.repr_traceback(excinfo_)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 823, in repr_traceback\r\nINTERNALERROR>     reprentry = self.repr_traceback_entry(entry, einfo)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 784, in repr_traceback_entry\r\nINTERNALERROR>     reprargs = self.repr_args(entry) if not short else None\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_code/code.py\", line 693, in repr_args\r\nINTERNALERROR>     args.append((argname, saferepr(argvalue)))\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 82, in saferepr\r\nINTERNALERROR>     return SafeRepr(maxsize).repr(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 51, in repr\r\nINTERNALERROR>     s = _format_repr_exception(exc, x)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 23, in _format_repr_exception\r\nINTERNALERROR>     exc_info, obj.__class__.__name__, id(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 47, in repr\r\nINTERNALERROR>     s = super().repr(x)\r\nINTERNALERROR>   File \"/usr/local/Cellar/python@3.8/3.8.1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/reprlib.py\", line 52, in repr\r\nINTERNALERROR>     return self.repr1(x, self.maxlevel)\r\nINTERNALERROR>   File \"/usr/local/Cellar/python@3.8/3.8.1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/reprlib.py\", line 62, in repr1\r\nINTERNALERROR>     return self.repr_instance(x, level)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 60, in repr_instance\r\nINTERNALERROR>     s = _format_repr_exception(exc, x)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 23, in _format_repr_exception\r\nINTERNALERROR>     exc_info, obj.__class__.__name__, id(obj)\r\nINTERNALERROR>   File \"/usr/local/lib/python3.8/site-packages/_pytest/_io/saferepr.py\", line 56, in repr_instance\r\nINTERNALERROR>     s = repr(x)\r\nINTERNALERROR>   File \"/Users/stiflou/Documents/projets/apischema/tests/test_pytest.py\", line 6, in __repr__\r\nINTERNALERROR>     raise\r\nINTERNALERROR> RuntimeError: No active exception to reraise\r\n\r\n============================ no tests ran in 0.09s ============================\r\n```\n", "patch": "diff --git a/src/_pytest/_io/saferepr.py b/src/_pytest/_io/saferepr.py\n--- a/src/_pytest/_io/saferepr.py\n+++ b/src/_pytest/_io/saferepr.py\n@@ -20,7 +20,7 @@ def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n     except BaseException as exc:\n         exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc))\n     return \"<[{} raised in repr()] {} object at 0x{:x}>\".format(\n-        exc_info, obj.__class__.__name__, id(obj)\n+        exc_info, type(obj).__name__, id(obj)\n     )\n \n \n"}}
{"instance_id": "mwaskom__seaborn-3010", "found_files": ["seaborn/_stats/regression.py"], "found_modules": ["seaborn/_stats/regression.py:PolyFit"], "found_entities": ["seaborn/_stats/regression.py:PolyFit._fit_predict"], "raw_output_loc": ["```\nseaborn/_stats/regression.py\nline: 24\nline: 25\nline: 30\nclass: PolyFit\nfunction: PolyFit._fit_predict\n```", "```\nseaborn/_stats/regression.py\nline: 24\nline: 25\nline: 30\nclass: PolyFit\nfunction: PolyFit._fit_predict\n```"], "meta_data": {"repo": "mwaskom/seaborn", "base_commit": "0f5a013e2cf43562deec3b879458e59a73853813", "problem_statement": "PolyFit is not robust to missing data\n```python\r\nso.Plot([1, 2, 3, None, 4], [1, 2, 3, 4, 5]).add(so.Line(), so.PolyFit())\r\n```\r\n\r\n<details><summary>Traceback</summary>\r\n\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nLinAlgError                               Traceback (most recent call last)\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/IPython/core/formatters.py:343, in BaseFormatter.__call__(self, obj)\r\n    341     method = get_real_method(obj, self.print_method)\r\n    342     if method is not None:\r\n--> 343         return method()\r\n    344     return None\r\n    345 else:\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:265, in Plot._repr_png_(self)\r\n    263 def _repr_png_(self) -> tuple[bytes, dict[str, float]]:\r\n--> 265     return self.plot()._repr_png_()\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:804, in Plot.plot(self, pyplot)\r\n    800 \"\"\"\r\n    801 Compile the plot spec and return the Plotter object.\r\n    802 \"\"\"\r\n    803 with theme_context(self._theme_with_defaults()):\r\n--> 804     return self._plot(pyplot)\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:822, in Plot._plot(self, pyplot)\r\n    819 plotter._setup_scales(self, common, layers, coord_vars)\r\n    821 # Apply statistical transform(s)\r\n--> 822 plotter._compute_stats(self, layers)\r\n    824 # Process scale spec for semantic variables and coordinates computed by stat\r\n    825 plotter._setup_scales(self, common, layers)\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:1110, in Plotter._compute_stats(self, spec, layers)\r\n   1108     grouper = grouping_vars\r\n   1109 groupby = GroupBy(grouper)\r\n-> 1110 res = stat(df, groupby, orient, scales)\r\n   1112 if pair_vars:\r\n   1113     data.frames[coord_vars] = res\r\n\r\nFile ~/code/seaborn/seaborn/_stats/regression.py:41, in PolyFit.__call__(self, data, groupby, orient, scales)\r\n     39 def __call__(self, data, groupby, orient, scales):\r\n---> 41     return groupby.apply(data, self._fit_predict)\r\n\r\nFile ~/code/seaborn/seaborn/_core/groupby.py:109, in GroupBy.apply(self, data, func, *args, **kwargs)\r\n    106 grouper, groups = self._get_groups(data)\r\n    108 if not grouper:\r\n--> 109     return self._reorder_columns(func(data, *args, **kwargs), data)\r\n    111 parts = {}\r\n    112 for key, part_df in data.groupby(grouper, sort=False):\r\n\r\nFile ~/code/seaborn/seaborn/_stats/regression.py:30, in PolyFit._fit_predict(self, data)\r\n     28     xx = yy = []\r\n     29 else:\r\n---> 30     p = np.polyfit(x, y, self.order)\r\n     31     xx = np.linspace(x.min(), x.max(), self.gridsize)\r\n     32     yy = np.polyval(p, xx)\r\n\r\nFile <__array_function__ internals>:180, in polyfit(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/lib/polynomial.py:668, in polyfit(x, y, deg, rcond, full, w, cov)\r\n    666 scale = NX.sqrt((lhs*lhs).sum(axis=0))\r\n    667 lhs /= scale\r\n--> 668 c, resids, rank, s = lstsq(lhs, rhs, rcond)\r\n    669 c = (c.T/scale).T  # broadcast scale coefficients\r\n    671 # warn on rank reduction, which indicates an ill conditioned matrix\r\n\r\nFile <__array_function__ internals>:180, in lstsq(*args, **kwargs)\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/linalg/linalg.py:2300, in lstsq(a, b, rcond)\r\n   2297 if n_rhs == 0:\r\n   2298     # lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\r\n   2299     b = zeros(b.shape[:-2] + (m, n_rhs + 1), dtype=b.dtype)\r\n-> 2300 x, resids, rank, s = gufunc(a, b, rcond, signature=signature, extobj=extobj)\r\n   2301 if m == 0:\r\n   2302     x[...] = 0\r\n\r\nFile ~/miniconda3/envs/seaborn-py39-latest/lib/python3.9/site-packages/numpy/linalg/linalg.py:101, in _raise_linalgerror_lstsq(err, flag)\r\n    100 def _raise_linalgerror_lstsq(err, flag):\r\n--> 101     raise LinAlgError(\"SVD did not converge in Linear Least Squares\")\r\n\r\nLinAlgError: SVD did not converge in Linear Least Squares\r\n\r\n```\r\n\r\n</details>\n", "patch": "diff --git a/seaborn/_stats/regression.py b/seaborn/_stats/regression.py\n--- a/seaborn/_stats/regression.py\n+++ b/seaborn/_stats/regression.py\n@@ -38,7 +38,10 @@ def _fit_predict(self, data):\n \n     def __call__(self, data, groupby, orient, scales):\n \n-        return groupby.apply(data, self._fit_predict)\n+        return (\n+            groupby\n+            .apply(data.dropna(subset=[\"x\", \"y\"]), self._fit_predict)\n+        )\n \n \n @dataclass\n"}}
{"instance_id": "django__django-12908", "found_files": ["django/db/models/query.py"], "found_modules": ["django/db/models/query.py:QuerySet"], "found_entities": ["django/db/models/query.py:QuerySet.distinct", "django/db/models/query.py:QuerySet._combinator_query"], "raw_output_loc": ["```\ndjango/db/models/query.py\nline: 1137\nfunction: QuerySet.distinct\n\n```", "```\ndjango/db/models/query.py\nline: 988\nfunction: QuerySet._combinator_query\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "49ae7ce50a874f8a04cd910882fb9571ff3a0d7a", "problem_statement": "Union queryset should raise on distinct().\nDescription\n\t \n\t\t(last modified by Sielc Technologies)\n\t \nAfter using\n.annotate() on 2 different querysets\nand then .union()\n.distinct() will not affect the queryset\n\tdef setUp(self) -> None:\n\t\tuser = self.get_or_create_admin_user()\n\t\tSample.h.create(user, name=\"Sam1\")\n\t\tSample.h.create(user, name=\"Sam2 acid\")\n\t\tSample.h.create(user, name=\"Sam3\")\n\t\tSample.h.create(user, name=\"Sam4 acid\")\n\t\tSample.h.create(user, name=\"Dub\")\n\t\tSample.h.create(user, name=\"Dub\")\n\t\tSample.h.create(user, name=\"Dub\")\n\t\tself.user = user\n\tdef test_union_annotated_diff_distinct(self):\n\t\tqs = Sample.objects.filter(user=self.user)\n\t\tqs1 = qs.filter(name='Dub').annotate(rank=Value(0, IntegerField()))\n\t\tqs2 = qs.filter(name='Sam1').annotate(rank=Value(1, IntegerField()))\n\t\tqs = qs1.union(qs2)\n\t\tqs = qs.order_by('name').distinct('name') # THIS DISTINCT DOESN'T WORK\n\t\tself.assertEqual(qs.count(), 2)\nexpected to get wrapped union\n\tSELECT DISTINCT ON (siebox_sample.name) * FROM (SELECT ... UNION SELECT ...) AS siebox_sample\n", "patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1138,6 +1138,7 @@ def distinct(self, *field_names):\n         \"\"\"\n         Return a new QuerySet instance that will select only distinct results.\n         \"\"\"\n+        self._not_support_combined_queries('distinct')\n         assert not self.query.is_sliced, \\\n             \"Cannot create distinct fields once a slice has been taken.\"\n         obj = self._chain()\n"}}
{"instance_id": "sphinx-doc__sphinx-8801", "found_files": ["sphinx/ext/autodoc/__init__.py", "sphinx/ext/autodoc/importer.py", "sphinx/ext/autodoc/typehints.py", "sphinx/ext/autodoc/directive.py"], "found_modules": ["sphinx/ext/autodoc/__init__.py:ClassDocumenter", "sphinx/ext/autodoc/__init__.py:inherited_members_option", "sphinx/ext/autodoc/importer.py:get_class_members", "sphinx/ext/autodoc/__init__.py:Documenter.filter_members", "sphinx/ext/autodoc/typehints.py:record_typehints", "sphinx/ext/autodoc/directive.py:process_documenter_options", "sphinx/ext/autodoc/__init__.py:merge_members_option"], "found_entities": ["sphinx/ext/autodoc/__init__.py:ClassDocumenter.get_object_members", "sphinx/ext/autodoc/__init__.py:inherited_members_option", "sphinx/ext/autodoc/importer.py:get_class_members", "sphinx/ext/autodoc/__init__.py:Documenter.filter_members.is_filtered_inherited_member", "sphinx/ext/autodoc/typehints.py:record_typehints", "sphinx/ext/autodoc/directive.py:process_documenter_options", "sphinx/ext/autodoc/__init__.py:merge_members_option", "sphinx/ext/autodoc/__init__.py:ClassDocumenter.document_members"], "raw_output_loc": ["```\nsphinx/ext/autodoc/__init__.py\nline: 1633\nline: 1648\nclass: ClassDocumenter\nfunction: ClassDocumenter.get_object_members\n\nsphinx/ext/autodoc/importer.py\nline: 245\nline: 298\nfunction: get_class_members\n\nsphinx/ext/autodoc/typehints.py\nline: 23\nline: 37\nfunction: record_typehints\n\nsphinx/ext/autodoc/directive.py\nline: 84\nline: 95\nfunction: process_documenter_options\n```", "```\nsphinx/ext/autodoc/__init__.py\nline: 118\nfunction: inherited_members_option\n\nsphinx/ext/autodoc/__init__.py\nline: 679\nfunction: is_filtered_inherited_member\n\nsphinx/ext/autodoc/__init__.py\nline: 1440\nclass: ClassDocumenter\nfunction: ClassDocumenter.get_object_members\n\nsphinx/ext/autodoc/__init__.py\nline: 1648\nclass: ClassDocumenter\nfunction: ClassDocumenter.document_members\n\nsphinx/ext/autodoc/__init__.py\nline: 169\nfunction: merge_members_option\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "7ca279e33aebb60168d35e6be4ed059f4a68f2c1", "problem_statement": "autodoc: The annotation only member in superclass is treated as \"undocumented\"\n**Describe the bug**\r\nautodoc: The annotation only member in superclass is treated as \"undocumented\".\r\n\r\n**To Reproduce**\r\n\r\n```\r\n# example.py\r\nclass Foo:\r\n    \"\"\"docstring\"\"\"\r\n    attr1: int  #: docstring\r\n\r\n\r\nclass Bar(Foo):\r\n    \"\"\"docstring\"\"\"\r\n    attr2: str  #: docstring\r\n```\r\n```\r\n# index.rst\r\n.. autoclass:: example.Bar\r\n   :members:\r\n   :inherited-members:\r\n```\r\n\r\n`Bar.attr1` is not documented. It will be shown if I give `:undoc-members:` option to the autoclass directive call. It seems the attribute is treated as undocumented.\r\n\r\n**Expected behavior**\r\nIt should be shown.\r\n\r\n**Your project**\r\nNo\r\n\r\n**Screenshots**\r\nNo\r\n\r\n**Environment info**\r\n- OS: Mac\r\n- Python version: 3.9.1\r\n- Sphinx version: HEAD of 3.x\r\n- Sphinx extensions: sphinx.ext.autodoc\r\n- Extra tools: No\r\n\r\n**Additional context**\r\nNo\r\n\n", "patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -294,24 +294,35 @@ def get_class_members(subject: Any, objpath: List[str], attrgetter: Callable\n \n     try:\n         for cls in getmro(subject):\n+            try:\n+                modname = safe_getattr(cls, '__module__')\n+                qualname = safe_getattr(cls, '__qualname__')\n+                analyzer = ModuleAnalyzer.for_module(modname)\n+                analyzer.analyze()\n+            except AttributeError:\n+                qualname = None\n+                analyzer = None\n+            except PycodeError:\n+                analyzer = None\n+\n             # annotation only member (ex. attr: int)\n             for name in getannotations(cls):\n                 name = unmangle(cls, name)\n                 if name and name not in members:\n-                    members[name] = ObjectMember(name, INSTANCEATTR, class_=cls)\n+                    if analyzer and (qualname, name) in analyzer.attr_docs:\n+                        docstring = '\\n'.join(analyzer.attr_docs[qualname, name])\n+                    else:\n+                        docstring = None\n+\n+                    members[name] = ObjectMember(name, INSTANCEATTR, class_=cls,\n+                                                 docstring=docstring)\n \n             # append instance attributes (cf. self.attr1) if analyzer knows\n-            try:\n-                modname = safe_getattr(cls, '__module__')\n-                qualname = safe_getattr(cls, '__qualname__')\n-                analyzer = ModuleAnalyzer.for_module(modname)\n-                analyzer.analyze()\n+            if analyzer:\n                 for (ns, name), docstring in analyzer.attr_docs.items():\n                     if ns == qualname and name not in members:\n                         members[name] = ObjectMember(name, INSTANCEATTR, class_=cls,\n                                                      docstring='\\n'.join(docstring))\n-            except (AttributeError, PycodeError):\n-                pass\n     except AttributeError:\n         pass\n \n"}}
{"instance_id": "pallets__flask-4992", "found_files": ["src/flask/config.py"], "found_modules": ["src/flask/config.py:Config"], "found_entities": ["src/flask/config.py:Config.from_file"], "raw_output_loc": ["```\nsrc/flask/config.py\nline: 232\nline: 264\nclass: Config\nfunction: Config.from_file\n```", "```\nsrc/flask/config.py\nline: 232\nline: 264\nclass: Config\nfunction: Config.from_file\n```"], "meta_data": {"repo": "pallets/flask", "base_commit": "4c288bc97ea371817199908d0d9b12de9dae327e", "problem_statement": "Add a file mode parameter to flask.Config.from_file()\nPython 3.11 introduced native TOML support with the `tomllib` package. This could work nicely with the `flask.Config.from_file()` method as an easy way to load TOML config files:\r\n\r\n```python\r\napp.config.from_file(\"config.toml\", tomllib.load)\r\n```\r\n\r\nHowever, `tomllib.load()` takes an object readable in binary mode, while `flask.Config.from_file()` opens a file in text mode, resulting in this error:\r\n\r\n```\r\nTypeError: File must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`\r\n```\r\n\r\nWe can get around this with a more verbose expression, like loading from a file opened with the built-in `open()` function and passing the `dict` to `app.Config.from_mapping()`:\r\n\r\n```python\r\n# We have to repeat the path joining that from_file() does\r\nwith open(os.path.join(app.config.root_path, \"config.toml\"), \"rb\") as file:\r\n    app.config.from_mapping(tomllib.load(file))\r\n```\r\n\r\nBut adding a file mode parameter to `flask.Config.from_file()` would enable the use of a simpler expression. E.g.:\r\n\r\n```python\r\napp.config.from_file(\"config.toml\", tomllib.load, mode=\"b\")\r\n```\r\n\n", "patch": "diff --git a/src/flask/config.py b/src/flask/config.py\n--- a/src/flask/config.py\n+++ b/src/flask/config.py\n@@ -234,6 +234,7 @@ def from_file(\n         filename: str,\n         load: t.Callable[[t.IO[t.Any]], t.Mapping],\n         silent: bool = False,\n+        text: bool = True,\n     ) -> bool:\n         \"\"\"Update the values in the config from a file that is loaded\n         using the ``load`` parameter. The loaded data is passed to the\n@@ -244,8 +245,8 @@ def from_file(\n             import json\n             app.config.from_file(\"config.json\", load=json.load)\n \n-            import toml\n-            app.config.from_file(\"config.toml\", load=toml.load)\n+            import tomllib\n+            app.config.from_file(\"config.toml\", load=tomllib.load, text=False)\n \n         :param filename: The path to the data file. This can be an\n             absolute path or relative to the config root path.\n@@ -254,14 +255,18 @@ def from_file(\n         :type load: ``Callable[[Reader], Mapping]`` where ``Reader``\n             implements a ``read`` method.\n         :param silent: Ignore the file if it doesn't exist.\n+        :param text: Open the file in text or binary mode.\n         :return: ``True`` if the file was loaded successfully.\n \n+        .. versionchanged:: 2.3\n+            The ``text`` parameter was added.\n+\n         .. versionadded:: 2.0\n         \"\"\"\n         filename = os.path.join(self.root_path, filename)\n \n         try:\n-            with open(filename) as f:\n+            with open(filename, \"r\" if text else \"rb\") as f:\n                 obj = load(f)\n         except OSError as e:\n             if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n"}}
{"instance_id": "django__django-16873", "found_files": ["django/template/defaultfilters.py"], "found_modules": ["django/template/defaultfilters.py:join"], "found_entities": ["django/template/defaultfilters.py:join"], "raw_output_loc": ["```\ndjango/template/defaultfilters.py\nline: 590\nfunction: join\n```", "```\ndjango/template/defaultfilters.py\nline: 585\nfunction: join\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "fce90950bef348803fa7cc3e6bc65f4bce429b82", "problem_statement": "Template filter `join` should not escape the joining string if `autoescape` is `off`\nDescription\n\t\nConsider the following template code snippet:\n{% autoescape off %}\n{{ some_list|join:some_var }}\n{% endautoescape %}\nin this case, the items inside some_list will not be escaped (matching the expected behavior) but some_var will forcibly be escaped. From the docs for autoescape or join I don't think this is expected behavior.\nThe following testcase illustrates what I think is a bug in the join filter (run inside the template_tests/filter_tests folder):\nfrom django.template.defaultfilters import escape\nfrom django.test import SimpleTestCase\nfrom ..utils import setup\nclass RegressionTests(SimpleTestCase):\n\t@setup({\"join01\": '{{ some_list|join:some_var }}'})\n\tdef test_join01(self):\n\t\tsome_list = [\"<p>Hello World!</p>\", \"beta & me\", \"<script>Hi!</script>\"]\n\t\tsome_var = \"<br/>\"\n\t\toutput = self.engine.render_to_string(\"join01\", {\"some_list\": some_list, \"some_var\": some_var})\n\t\tself.assertEqual(output, escape(some_var.join(some_list)))\n\t@setup({\"join02\": '{% autoescape off %}{{ some_list|join:some_var }}{% endautoescape %}'})\n\tdef test_join02(self):\n\t\tsome_list = [\"<p>Hello World!</p>\", \"beta & me\", \"<script>Hi!</script>\"]\n\t\tsome_var = \"<br/>\"\n\t\toutput = self.engine.render_to_string(\"join02\", {\"some_list\": some_list, \"some_var\": some_var})\n\t\tself.assertEqual(output, some_var.join(some_list))\nResult of this run in current main is:\n.F\n======================================================================\nFAIL: test_join02 (template_tests.filter_tests.test_regression.RegressionTests.test_join02)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n File \"/home/nessita/fellowship/django/django/test/utils.py\", line 443, in inner\n\treturn func(*args, **kwargs)\n\t\t ^^^^^^^^^^^^^^^^^^^^^\n File \"/home/nessita/fellowship/django/tests/template_tests/utils.py\", line 58, in inner\n\tfunc(self)\n File \"/home/nessita/fellowship/django/tests/template_tests/filter_tests/test_regression.py\", line 21, in test_join02\n\tself.assertEqual(output, some_var.join(some_list))\nAssertionError: '<p>Hello World!</p>&lt;br/&gt;beta & me&lt;br/&gt;<script>Hi!</script>' != '<p>Hello World!</p><br/>beta & me<br/><script>Hi!</script>'\n----------------------------------------------------------------------\nRan 2 tests in 0.007s\n", "patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -586,8 +586,9 @@ def join(value, arg, autoescape=True):\n     \"\"\"Join a list with a string, like Python's ``str.join(list)``.\"\"\"\n     try:\n         if autoescape:\n-            value = [conditional_escape(v) for v in value]\n-        data = conditional_escape(arg).join(value)\n+            data = conditional_escape(arg).join([conditional_escape(v) for v in value])\n+        else:\n+            data = arg.join(value)\n     except TypeError:  # Fail silently if arg isn't iterable.\n         return value\n     return mark_safe(data)\n"}}
{"instance_id": "django__django-16255", "found_files": ["django/contrib/sitemaps/__init__.py", "django/contrib/sitemaps/views.py"], "found_modules": ["django/contrib/sitemaps/__init__.py:Sitemap", "django/contrib/sitemaps/views.py:index"], "found_entities": ["django/contrib/sitemaps/__init__.py:Sitemap.get_latest_lastmod", "django/contrib/sitemaps/views.py:index"], "raw_output_loc": ["```\ndjango/contrib/sitemaps/__init__.py\nline: 165\nclass: Sitemap\nfunction: Sitemap.get_latest_lastmod\n\ndjango/contrib/sitemaps/views.py\nline: 76\nfunction: index\n```", "```\ndjango/contrib/sitemaps/__init__.py\nline: 170\nclass: Sitemap\nfunction: Sitemap.get_latest_lastmod\n```"], "meta_data": {"repo": "django/django", "base_commit": "444b6da7cc229a58a2c476a52e45233001dc7073", "problem_statement": "Sitemaps without items raise ValueError on callable lastmod.\nDescription\n\t\nWhen sitemap contains not items, but supports returning lastmod for an item, it fails with a ValueError:\nTraceback (most recent call last):\n File \"/usr/local/lib/python3.10/site-packages/django/core/handlers/exception.py\", line 55, in inner\n\tresponse = get_response(request)\n File \"/usr/local/lib/python3.10/site-packages/django/core/handlers/base.py\", line 197, in _get_response\n\tresponse = wrapped_callback(request, *callback_args, **callback_kwargs)\n File \"/usr/local/lib/python3.10/site-packages/django/utils/decorators.py\", line 133, in _wrapped_view\n\tresponse = view_func(request, *args, **kwargs)\n File \"/usr/local/lib/python3.10/site-packages/django/contrib/sitemaps/views.py\", line 34, in inner\n\tresponse = func(request, *args, **kwargs)\n File \"/usr/local/lib/python3.10/site-packages/django/contrib/sitemaps/views.py\", line 76, in index\n\tsite_lastmod = site.get_latest_lastmod()\n File \"/usr/local/lib/python3.10/site-packages/django/contrib/sitemaps/__init__.py\", line 170, in get_latest_lastmod\n\treturn max([self.lastmod(item) for item in self.items()])\nException Type: ValueError at /sitemap.xml\nException Value: max() arg is an empty sequence\nSomething like this might be a solution:\n\t def get_latest_lastmod(self):\n\t\t if not hasattr(self, \"lastmod\"):\n\t\t\t return None\n\t\t if callable(self.lastmod):\n\t\t\t try:\n\t\t\t\t return max([self.lastmod(item) for item in self.items()])\n-\t\t\texcept TypeError:\n+\t\t\texcept (TypeError, ValueError):\n\t\t\t\t return None\n\t\t else:\n\t\t\t return self.lastmod\n", "patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,7 +167,7 @@ def get_latest_lastmod(self):\n             return None\n         if callable(self.lastmod):\n             try:\n-                return max([self.lastmod(item) for item in self.items()])\n+                return max([self.lastmod(item) for item in self.items()], default=None)\n             except TypeError:\n                 return None\n         else:\n"}}
{"instance_id": "pylint-dev__pylint-7993", "found_files": ["pylint/reporters/text.py", "pylint/message/message.py", "pylint/lint/pylinter.py"], "found_modules": ["pylint/reporters/text.py:TextReporter", "pylint/message/message.py:Message", "pylint/lint/pylinter.py:PyLinter"], "found_entities": ["pylint/reporters/text.py:TextReporter.write_message", "pylint/reporters/text.py:TextReporter.on_set_current_module", "pylint/reporters/text.py:TextReporter.handle_message", "pylint/message/message.py:Message.format"], "raw_output_loc": ["```\npylint/reporters/text.py\nline: 178\nclass: TextReporter\nfunction: TextReporter.on_set_current_module\n\npylint/reporters/text.py\nline: 180\nclass: TextReporter\nfunction: TextReporter.on_set_current_module\n\npylint/reporters/text.py\nline: 185\nclass: TextReporter\nfunction: TextReporter.on_set_current_module\n\npylint/reporters/text.py\nline: 206\nclass: TextReporter\nfunction: TextReporter.handle_message\n\npylint/reporters/text.py\nline: 196\nclass: TextReporter\nfunction: TextReporter.write_message\n```", "```\npylint/reporters/text.py\nline: 159\nclass: TextReporter\nfunction: TextReporter.__init__\n\npylint/reporters/text.py\nline: 188\nclass: TextReporter\nfunction: TextReporter.write_message\n\npylint/message/message.py\nline: 73\nfunction: Message.format\n\npylint/lint/pylinter.py\nline: 271\nclass: PyLinter\nfunction: PyLinter.__init__\n```"], "meta_data": {"repo": "pylint-dev/pylint", "base_commit": "e90702074e68e20dc8e5df5013ee3ecf22139c3e", "problem_statement": "Using custom braces in message template does not work\n### Bug description\n\nHave any list of errors:\r\n\r\nOn pylint 1.7 w/ python3.6 - I am able to use this as my message template\r\n```\r\n$ pylint test.py --msg-template='{{ \"Category\": \"{category}\" }}'\r\nNo config file found, using default configuration\r\n************* Module [redacted].test\r\n{ \"Category\": \"convention\" }\r\n{ \"Category\": \"error\" }\r\n{ \"Category\": \"error\" }\r\n{ \"Category\": \"convention\" }\r\n{ \"Category\": \"convention\" }\r\n{ \"Category\": \"convention\" }\r\n{ \"Category\": \"error\" }\r\n```\r\n\r\nHowever, on Python3.9 with Pylint 2.12.2, I get the following:\r\n```\r\n$ pylint test.py --msg-template='{{ \"Category\": \"{category}\" }}'\r\n[redacted]/site-packages/pylint/reporters/text.py:206: UserWarning: Don't recognize the argument '{ \"Category\"' in the --msg-template. Are you sure it is supported on the current version of pylint?\r\n  warnings.warn(\r\n************* Module [redacted].test\r\n\" }\r\n\" }\r\n\" }\r\n\" }\r\n\" }\r\n\" }\r\n```\r\n\r\nIs this intentional or a bug?\n\n### Configuration\n\n_No response_\n\n### Command used\n\n```shell\npylint test.py --msg-template='{{ \"Category\": \"{category}\" }}'\n```\n\n\n### Pylint output\n\n```shell\n[redacted]/site-packages/pylint/reporters/text.py:206: UserWarning: Don't recognize the argument '{ \"Category\"' in the --msg-template. Are you sure it is supported on the current version of pylint?\r\n  warnings.warn(\r\n************* Module [redacted].test\r\n\" }\r\n\" }\r\n\" }\r\n\" }\r\n\" }\r\n\" }\n```\n\n\n### Expected behavior\n\nExpect the dictionary to print out with `\"Category\"` as the key.\n\n### Pylint version\n\n```shell\nAffected Version:\r\npylint 2.12.2\r\nastroid 2.9.2\r\nPython 3.9.9+ (heads/3.9-dirty:a2295a4, Dec 21 2021, 22:32:52) \r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]\r\n\r\n\r\nPreviously working version:\r\nNo config file found, using default configuration\r\npylint 1.7.4, \r\nastroid 1.6.6\r\nPython 3.6.8 (default, Nov 16 2020, 16:55:22) \r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)]\n```\n\n\n### OS / Environment\n\n_No response_\n\n### Additional dependencies\n\n_No response_\n", "patch": "diff --git a/pylint/reporters/text.py b/pylint/reporters/text.py\n--- a/pylint/reporters/text.py\n+++ b/pylint/reporters/text.py\n@@ -175,7 +175,7 @@ def on_set_current_module(self, module: str, filepath: str | None) -> None:\n         self._template = template\n \n         # Check to see if all parameters in the template are attributes of the Message\n-        arguments = re.findall(r\"\\{(.+?)(:.*)?\\}\", template)\n+        arguments = re.findall(r\"\\{(\\w+?)(:.*)?\\}\", template)\n         for argument in arguments:\n             if argument[0] not in MESSAGE_FIELDS:\n                 warnings.warn(\n"}}
{"instance_id": "sympy__sympy-14396", "found_files": ["sympy/polys/polyoptions.py", "sympy/polys/domains/domain.py", "sympy/polys/domains/polynomialring.py", "sympy/polys/domains/realfield.py"], "found_modules": ["sympy/polys/polyoptions.py:Domain", "sympy/polys/domains/domain.py:Domain"], "found_entities": ["sympy/polys/polyoptions.py:Domain.preprocess", "sympy/polys/domains/domain.py:Domain.poly_ring"], "raw_output_loc": ["```\nsympy/polys/polyoptions.py\nline: 480\nfunction: Domain.preprocess\n\nsympy/polys/domains/domain.py\nline: 379\nfunction: Domain.poly_ring\n\nsympy/polys/domains/polynomialring.py\nfunction: PolynomialRing.__new__\n\nsympy/polys/domains/realfield.py\nfunction: RealField.__new__\n```", "```\nsympy/polys/polyoptions.py\nline: 405\nline: 408\nclass: Domain\nfunction: Domain.preprocess\n\nsympy/polys/polyoptions.py\nline: 428\nline: 453\nclass: Domain\nfunction: Domain.preprocess\n\nsympy/polys/polyoptions.py\nline: 483\nclass: Domain\nfunction: Domain.preprocess\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "f35ad6411f86a15dd78db39c29d1e5291f66f9b5", "problem_statement": "Poly(domain='RR[y,z]') doesn't work\n``` py\nIn [14]: Poly(1.2*x*y*z, x)\nOut[14]: Poly(1.2*y*z*x, x, domain='RR[y,z]')\n\nIn [15]: Poly(1.2*x*y*z, x, domain='RR[y,z]')\n---------------------------------------------------------------------------\nOptionError                               Traceback (most recent call last)\n<ipython-input-15-d83389519ae1> in <module>()\n----> 1 Poly(1.2*x*y*z, x, domain='RR[y,z]')\n\n/Users/aaronmeurer/Documents/Python/sympy/sympy-scratch/sympy/polys/polytools.py in __new__(cls, rep, *gens, **args)\n     69     def __new__(cls, rep, *gens, **args):\n     70         \"\"\"Create a new polynomial instance out of something useful. \"\"\"\n---> 71         opt = options.build_options(gens, args)\n     72\n     73         if 'order' in opt:\n\n/Users/aaronmeurer/Documents/Python/sympy/sympy-scratch/sympy/polys/polyoptions.py in build_options(gens, args)\n    718\n    719     if len(args) != 1 or 'opt' not in args or gens:\n--> 720         return Options(gens, args)\n    721     else:\n    722         return args['opt']\n\n/Users/aaronmeurer/Documents/Python/sympy/sympy-scratch/sympy/polys/polyoptions.py in __init__(self, gens, args, flags, strict)\n    151                     self[option] = cls.preprocess(value)\n    152\n--> 153         preprocess_options(args)\n    154\n    155         for key, value in dict(defaults).items():\n\n/Users/aaronmeurer/Documents/Python/sympy/sympy-scratch/sympy/polys/polyoptions.py in preprocess_options(args)\n    149\n    150                 if value is not None:\n--> 151                     self[option] = cls.preprocess(value)\n    152\n    153         preprocess_options(args)\n\n/Users/aaronmeurer/Documents/Python/sympy/sympy-scratch/sympy/polys/polyoptions.py in preprocess(cls, domain)\n    480                 return sympy.polys.domains.QQ.algebraic_field(*gens)\n    481\n--> 482         raise OptionError('expected a valid domain specification, got %s' % domain)\n    483\n    484     @classmethod\n\nOptionError: expected a valid domain specification, got RR[y,z]\n```\n\nAlso, the wording of error message could be improved\n\n", "patch": "diff --git a/sympy/polys/polyoptions.py b/sympy/polys/polyoptions.py\n--- a/sympy/polys/polyoptions.py\n+++ b/sympy/polys/polyoptions.py\n@@ -405,7 +405,7 @@ class Domain(with_metaclass(OptionType, Option)):\n     _re_realfield = re.compile(r\"^(R|RR)(_(\\d+))?$\")\n     _re_complexfield = re.compile(r\"^(C|CC)(_(\\d+))?$\")\n     _re_finitefield = re.compile(r\"^(FF|GF)\\((\\d+)\\)$\")\n-    _re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ)\\[(.+)\\]$\")\n+    _re_polynomial = re.compile(r\"^(Z|ZZ|Q|QQ|R|RR|C|CC)\\[(.+)\\]$\")\n     _re_fraction = re.compile(r\"^(Z|ZZ|Q|QQ)\\((.+)\\)$\")\n     _re_algebraic = re.compile(r\"^(Q|QQ)\\<(.+)\\>$\")\n \n@@ -459,8 +459,12 @@ def preprocess(cls, domain):\n \n                 if ground in ['Z', 'ZZ']:\n                     return sympy.polys.domains.ZZ.poly_ring(*gens)\n-                else:\n+                elif ground in ['Q', 'QQ']:\n                     return sympy.polys.domains.QQ.poly_ring(*gens)\n+                elif ground in ['R', 'RR']:\n+                    return sympy.polys.domains.RR.poly_ring(*gens)\n+                else:\n+                    return sympy.polys.domains.CC.poly_ring(*gens)\n \n             r = cls._re_fraction.match(domain)\n \n"}}
{"instance_id": "mwaskom__seaborn-3190", "found_files": ["seaborn/_core/scales.py", "seaborn/_core/plot.py"], "found_modules": ["seaborn/_core/scales.py:ContinuousBase", "seaborn/_core/scales.py:_make_identity_transforms", "seaborn/_core/plot.py:Plotter", "seaborn/_core/plot.py:Plot"], "found_entities": ["seaborn/_core/scales.py:ContinuousBase._setup", "seaborn/_core/scales.py:_make_identity_transforms", "seaborn/_core/scales.py:ContinuousBase._get_transform", "seaborn/_core/plot.py:Plotter._setup_scales", "seaborn/_core/plot.py:Plot._plot"], "raw_output_loc": ["```\nseaborn/_core/scales.py:ContinuousBase._setup\nline: 350\nline: 351\nfunction: ContinuousBase._setup\n\nseaborn/_core/scales.py:_make_identity_transforms\nfunction: _make_identity_transforms\n\nseaborn/_core/scales.py:_get_transform\nfunction: ContinuousBase._get_transform\n\nseaborn/_core/plot.py:Plotter._setup_scales\nfunction: Plotter._setup_scales\n\nseaborn/_core/plot.py:Plot._plot\nfunction: Plot._plot\n```", "```\nseaborn/_core/scales.py\nline: 350\nline: 351\nfunction: ContinuousBase._setup\n```"], "meta_data": {"repo": "mwaskom/seaborn", "base_commit": "4a9e54962a29c12a8b103d75f838e0e795a6974d", "problem_statement": "Color mapping fails with boolean data\n```python\r\nso.Plot([\"a\", \"b\"], [1, 2], color=[True, False]).add(so.Bar())\r\n```\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n...\r\nFile ~/code/seaborn/seaborn/_core/plot.py:841, in Plot._plot(self, pyplot)\r\n    838 plotter._compute_stats(self, layers)\r\n    840 # Process scale spec for semantic variables and coordinates computed by stat\r\n--> 841 plotter._setup_scales(self, common, layers)\r\n    843 # TODO Remove these after updating other methods\r\n    844 # ---- Maybe have debug= param that attaches these when True?\r\n    845 plotter._data = common\r\n\r\nFile ~/code/seaborn/seaborn/_core/plot.py:1252, in Plotter._setup_scales(self, p, common, layers, variables)\r\n   1250     self._scales[var] = Scale._identity()\r\n   1251 else:\r\n-> 1252     self._scales[var] = scale._setup(var_df[var], prop)\r\n   1254 # Everything below here applies only to coordinate variables\r\n   1255 # We additionally skip it when we're working with a value\r\n   1256 # that is derived from a coordinate we've already processed.\r\n   1257 # e.g., the Stat consumed y and added ymin/ymax. In that case,\r\n   1258 # we've already setup the y scale and ymin/max are in scale space.\r\n   1259 if axis is None or (var != coord and coord in p._variables):\r\n\r\nFile ~/code/seaborn/seaborn/_core/scales.py:351, in ContinuousBase._setup(self, data, prop, axis)\r\n    349 vmin, vmax = axis.convert_units((vmin, vmax))\r\n    350 a = forward(vmin)\r\n--> 351 b = forward(vmax) - forward(vmin)\r\n    353 def normalize(x):\r\n    354     return (x - a) / b\r\n\r\nTypeError: numpy boolean subtract, the `-` operator, is not supported, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\r\n```\n", "patch": "diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -346,7 +346,7 @@ def _setup(\n                 vmin, vmax = data.min(), data.max()\n             else:\n                 vmin, vmax = new.norm\n-            vmin, vmax = axis.convert_units((vmin, vmax))\n+            vmin, vmax = map(float, axis.convert_units((vmin, vmax)))\n             a = forward(vmin)\n             b = forward(vmax) - forward(vmin)\n \n"}}
{"instance_id": "sympy__sympy-21627", "found_files": ["sympy/functions/elementary/hyperbolic.py", "sympy/core/expr.py", "sympy/functions/elementary/trigonometric.py", "sympy/core/basic.py"], "found_modules": ["sympy/functions/elementary/hyperbolic.py:cosh", "sympy/functions/elementary/hyperbolic.py:acosh"], "found_entities": ["sympy/functions/elementary/hyperbolic.py:cosh.eval", "sympy/functions/elementary/hyperbolic.py:acosh.eval"], "raw_output_loc": ["```\nsympy/functions/elementary/hyperbolic.py\nline: 338\nline: 339\nclass: cosh\nfunction: cosh.eval\n\nsympy/functions/elementary/hyperbolic.py\nline: 1250\nline: 1251\nclass: acosh\nfunction: acosh.eval\n\nsympy/core/expr.py\nfunction: Expr.is_zero\n\nsympy/functions/elementary/hyperbolic.py\nline: 312\nline: 313\nclass: cosh\nfunction: cosh._eval_is_zero\n\nsympy/functions/elementary/hyperbolic.py\nline: 1260\nline: 1261\nclass: acosh\nfunction: acosh._eval_is_zero\n```", "```\nsympy/functions/elementary/hyperbolic.py:cosh\nfunction: cosh._eval_is_zero\n\nsympy/core/expr.py:Expr\nfunction: Expr.is_zero\n\nsympy/functions/elementary/trigonometric.py:acos\nfunction: acos._eval_is_zero\n\nsympy/functions/elementary/hyperbolic.py:acosh\nfunction: acosh._eval_is_zero\n\nsympy/core/basic.py:Basic\nfunction: Basic._eval_is_zero\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "126f80578140e752ad5135aac77b8ff887eede3e", "problem_statement": "Bug: maximum recusion depth error when checking is_zero of cosh expression\nThe following code causes a `RecursionError: maximum recursion depth exceeded while calling a Python object` error when checked if it is zero:\r\n```\r\nexpr =sympify(\"cosh(acos(-i + acosh(-g + i)))\")\r\nexpr.is_zero\r\n```\n", "patch": "diff --git a/sympy/functions/elementary/complexes.py b/sympy/functions/elementary/complexes.py\n--- a/sympy/functions/elementary/complexes.py\n+++ b/sympy/functions/elementary/complexes.py\n@@ -607,6 +607,8 @@ def eval(cls, arg):\n             arg2 = -S.ImaginaryUnit * arg\n             if arg2.is_extended_nonnegative:\n                 return arg2\n+        if arg.is_extended_real:\n+            return\n         # reject result if all new conjugates are just wrappers around\n         # an expression that was already in the arg\n         conj = signsimp(arg.conjugate(), evaluate=False)\n"}}
{"instance_id": "django__django-15819", "found_files": ["django/core/management/commands/inspectdb.py"], "found_modules": ["django/core/management/commands/inspectdb.py:Command"], "found_entities": ["django/core/management/commands/inspectdb.py:Command.handle_inspection"], "raw_output_loc": ["```\ndjango/core/management/commands/inspectdb.py\nline: 166\nfunction: Command.handle_inspection\n\n```", "```\ndjango/core/management/commands/inspectdb.py\nline: 166\nline: 184\nfunction: Command.handle_inspection\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "877c800f255ccaa7abde1fb944de45d1616f5cc9", "problem_statement": "inspectdb should generate related_name on same relation links.\nDescription\n\t\nHi!\nAfter models generation with inspectdb command we have issue with relations to same enities\nmodule.Model.field1: (fields.E304) Reverse accessor for 'module.Model.field1' clashes with reverse accessor for 'module.Model.field2'.\nHINT: Add or change a related_name argument to the definition for 'module.Model.field1' or 'module.Model.field2'.\n*\nMaybe we can autogenerate\nrelated_name='attribute_name'\nto all fields in model if related Model was used for this table\n", "patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -127,12 +127,14 @@ def table2model(table_name):\n                     yield \"# The error was: %s\" % e\n                     continue\n \n+                model_name = table2model(table_name)\n                 yield \"\"\n                 yield \"\"\n-                yield \"class %s(models.Model):\" % table2model(table_name)\n-                known_models.append(table2model(table_name))\n+                yield \"class %s(models.Model):\" % model_name\n+                known_models.append(model_name)\n                 used_column_names = []  # Holds column names used in the table so far\n                 column_to_field_name = {}  # Maps column names to names of model fields\n+                used_relations = set()  # Holds foreign relations used in the table.\n                 for row in table_description:\n                     comment_notes = (\n                         []\n@@ -186,6 +188,12 @@ def table2model(table_name):\n                             field_type = \"%s(%s\" % (rel_type, rel_to)\n                         else:\n                             field_type = \"%s('%s'\" % (rel_type, rel_to)\n+                        if rel_to in used_relations:\n+                            extra_params[\"related_name\"] = \"%s_%s_set\" % (\n+                                model_name.lower(),\n+                                att_name,\n+                            )\n+                        used_relations.add(rel_to)\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.\n"}}
{"instance_id": "matplotlib__matplotlib-23987", "found_files": ["lib/matplotlib/layout_engine.py", "lib/matplotlib/figure.py"], "found_modules": ["lib/matplotlib/figure.py:FigureBase", "lib/matplotlib/figure.py:Figure"], "found_entities": ["lib/matplotlib/figure.py:FigureBase.subplots_adjust", "lib/matplotlib/figure.py:Figure.set_layout_engine", "lib/matplotlib/figure.py:Figure.get_layout_engine", "lib/matplotlib/figure.py:Figure._check_layout_engines_compat"], "raw_output_loc": ["```\nlib/matplotlib/layout_engine.py:ConstrainedLayoutEngine\nline: 199\nfunction: ConstrainedLayoutEngine._adjust_compatible\n\nlib/matplotlib/figure.py:FigureBase.subplots_adjust\nline: 1312\nline: 1317\nfunction: FigureBase.subplots_adjust\n\nlib/matplotlib/figure.py:Figure.set_layout_engine\nline: 2560\nline: 2563\nfunction: Figure.set_layout_engine\n\nlib/matplotlib/figure.py:Figure.get_layout_engine\nline: 2588\nfunction: Figure.get_layout_engine\n\nlib/matplotlib/figure.py:Figure._check_layout_engines_compat\nline: 2503\nfunction: Figure._check_layout_engines_compat\n```", "```\nlib/matplotlib/layout_engine.py\nline: 199\nclass: ConstrainedLayoutEngine\nfunction: ConstrainedLayoutEngine._adjust_compatible\n\nlib/matplotlib/figure.py\nline: 1312\nline: 1313\nline: 1314\nline: 1315\nline: 1316\nline: 1317\nline: 1318\nfunction: FigureBase.subplots_adjust\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "e98d8d085e8f53ec0467422b326f7738a2dd695e", "problem_statement": "[Bug]: Constrained layout UserWarning even when False\n### Bug summary\r\n\r\nWhen using layout settings such as `plt.subplots_adjust` or `bbox_inches='tight`, a UserWarning is produced due to incompatibility with constrained_layout, even if constrained_layout = False. This was not the case in previous versions.\r\n\r\n### Code for reproduction\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\na = np.linspace(0,2*np.pi,100)\r\nb = np.sin(a)\r\nc = np.cos(a)\r\nfig,ax = plt.subplots(1,2,figsize=(8,2),constrained_layout=False)\r\nax[0].plot(a,b)\r\nax[1].plot(a,c)\r\nplt.subplots_adjust(wspace=0)\r\n```\r\n\r\n\r\n### Actual outcome\r\n\r\nThe plot works fine but the warning is generated\r\n\r\n`/var/folders/ss/pfgdfm2x7_s4cyw2v0b_t7q80000gn/T/ipykernel_76923/4170965423.py:7: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\r\n  plt.subplots_adjust(wspace=0)`\r\n\r\n### Expected outcome\r\n\r\nno warning\r\n\r\n### Additional information\r\n\r\nWarning disappears when constrained_layout=False is removed\r\n\r\n### Operating system\r\n\r\nOS/X\r\n\r\n### Matplotlib Version\r\n\r\n3.6.0\r\n\r\n### Matplotlib Backend\r\n\r\n_No response_\r\n\r\n### Python version\r\n\r\n_No response_\r\n\r\n### Jupyter version\r\n\r\n_No response_\r\n\r\n### Installation\r\n\r\nconda\n", "patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2426,9 +2426,12 @@ def __init__(self,\n             if isinstance(tight_layout, dict):\n                 self.get_layout_engine().set(**tight_layout)\n         elif constrained_layout is not None:\n-            self.set_layout_engine(layout='constrained')\n             if isinstance(constrained_layout, dict):\n+                self.set_layout_engine(layout='constrained')\n                 self.get_layout_engine().set(**constrained_layout)\n+            elif constrained_layout:\n+                self.set_layout_engine(layout='constrained')\n+\n         else:\n             # everything is None, so use default:\n             self.set_layout_engine(layout=layout)\n"}}
{"instance_id": "matplotlib__matplotlib-23563", "found_files": ["lib/mpl_toolkits/mplot3d/art3d.py", "lib/mpl_toolkits/mplot3d/axes3d.py"], "found_modules": ["lib/mpl_toolkits/mplot3d/art3d.py:Line3D", "lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D", "lib/mpl_toolkits/mplot3d/art3d.py:line_2d_to_3d"], "found_entities": ["lib/mpl_toolkits/mplot3d/art3d.py:Line3D.set_3d_properties", "lib/mpl_toolkits/mplot3d/art3d.py:line_2d_to_3d", "lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D.plot", "lib/mpl_toolkits/mplot3d/art3d.py:Line3D.set_data_3d", "lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D.errorbar"], "raw_output_loc": ["```\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 169\nclass: Line3D\nfunction: Line3D.__init__\n\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 175\nclass: Line3D\nfunction: Line3D.set_3d_properties\n\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 196\nclass: Line3D\nfunction: Line3D.set_data_3d\n\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 1284\nclass: Axes3D\nfunction: Axes3D.plot\n\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 224\nfunction: line_2d_to_3d\n```", "```\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 168-169\nclass: Line3D\nfunction: Line3D.__init__\n\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 171-176\nclass: Line3D\nfunction: Line3D.set_3d_properties\n\nlib/mpl_toolkits/mplot3d/art3d.py\nline: 221-225\nfunction: line_2d_to_3d\n\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 1249-1288\nclass: Axes3D\nfunction: Axes3D.plot\n\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 2773-3093\nclass: Axes3D\nfunction: Axes3D.errorbar\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "149a0398b391cfc4eddb5e659f50b3c66f32ea65", "problem_statement": "[Bug]: 'Line3D' object has no attribute '_verts3d'\n### Bug summary\n\nI use matplotlib 3D to visualize some lines in 3D. When I first run the following code, the code can run right. But, if I give `x_s_0[n]` a numpy array, it will report the error 'input operand has more dimensions than allowed by the axis remapping'. The point is when next I give  `x_s_0[n]` and other variables an int number, the AttributeError: 'Line3D' object has no attribute '_verts3d' will appear and can not be fixed whatever I change the variables or delete them. The error can be only fixed when I restart the kernel of ipython console. I don't know why it happens, so I come here for help.\n\n### Code for reproduction\n\n```python\nx_s_0 = np.array(['my int number list'])\r\nx_e_0 = np.array(['my int number list'])\r\ny_s_0 = np.array(['my int number list'])\r\ny_e_0 = np.array(['my int number list'])\r\nz_s_0 = np.array(['my int number list'])\r\nz_e_0 = np.array(['my int number list'])\r\n\r\nfig = plt.figure()\r\n        ax = fig.gca(projection='3d')\r\n        ax.view_init(elev=90, azim=0)\r\n        ax.set_zlim3d(-10, 10)\r\n        clr_list = 'r-'\r\n\r\n        for n in range(np.size(z_s_0, axis=0)):\r\n            ax.plot([int(x_s_0[n]), int(x_e_0[n])],\r\n                    [int(y_s_0[n]), int(y_e_0[n])],\r\n                    [int(z_s_0[n]), int(z_e_0[n])], clr_list)\r\n\r\n        plt.xlabel('x')\r\n        plt.ylabel('y')\r\n        # ax.zlabel('z')\r\n        plt.title('90-0')\r\n        plt.show()\n```\n\n\n### Actual outcome\n\nTraceback (most recent call last):\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-80-e04907066a16>\", line 20, in <module>\r\n    plt.show()\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/pyplot.py\", line 368, in show\r\n    return _backend_mod.show(*args, **kwargs)\r\n  File \"/home/hanyaning/.pycharm_helpers/pycharm_matplotlib_backend/backend_interagg.py\", line 29, in __call__\r\n    manager.show(**kwargs)\r\n  File \"/home/hanyaning/.pycharm_helpers/pycharm_matplotlib_backend/backend_interagg.py\", line 112, in show\r\n    self.canvas.show()\r\n  File \"/home/hanyaning/.pycharm_helpers/pycharm_matplotlib_backend/backend_interagg.py\", line 68, in show\r\n    FigureCanvasAgg.draw(self)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py\", line 436, in draw\r\n    self.figure.draw(self.renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/artist.py\", line 73, in draw_wrapper\r\n    result = draw(artist, renderer, *args, **kwargs)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/artist.py\", line 50, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/figure.py\", line 2803, in draw\r\n    mimage._draw_list_compositing_images(\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\r\n    a.draw(renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/artist.py\", line 50, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/mpl_toolkits/mplot3d/axes3d.py\", line 469, in draw\r\n    super().draw(renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/artist.py\", line 50, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/axes/_base.py\", line 3082, in draw\r\n    mimage._draw_list_compositing_images(\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/image.py\", line 132, in _draw_list_compositing_images\r\n    a.draw(renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/matplotlib/artist.py\", line 50, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"/home/hanyaning/anaconda3/envs/SBeA/lib/python3.8/site-packages/mpl_toolkits/mplot3d/art3d.py\", line 215, in draw\r\n    xs3d, ys3d, zs3d = self._verts3d\r\nAttributeError: 'Line3D' object has no attribute '_verts3d'\n\n### Expected outcome\n\nSome 3D lines\n\n### Additional information\n\n_No response_\n\n### Operating system\n\nLocal: windows + pycharm, Remote: Ubuntu 20.04\n\n### Matplotlib Version\n\n3.5.0\n\n### Matplotlib Backend\n\nmodule://backend_interagg\n\n### Python version\n\n3.8.12\n\n### Jupyter version\n\n_No response_\n\n### Installation\n\npip\n", "patch": "diff --git a/lib/mpl_toolkits/mplot3d/art3d.py b/lib/mpl_toolkits/mplot3d/art3d.py\n--- a/lib/mpl_toolkits/mplot3d/art3d.py\n+++ b/lib/mpl_toolkits/mplot3d/art3d.py\n@@ -171,6 +171,7 @@ def __init__(self, xs, ys, zs, *args, **kwargs):\n     def set_3d_properties(self, zs=0, zdir='z'):\n         xs = self.get_xdata()\n         ys = self.get_ydata()\n+        zs = cbook._to_unmasked_float_array(zs).ravel()\n         zs = np.broadcast_to(zs, len(xs))\n         self._verts3d = juggle_axes(xs, ys, zs, zdir)\n         self.stale = True\n"}}
{"instance_id": "django__django-15814", "found_files": ["django/db/models/query.py", "django/db/models/sql/query.py", "django/db/models/sql/compiler.py"], "found_modules": ["django/db/models/query.py:RelatedPopulator", "django/db/models/query.py:prefetch_related_objects", "django/db/models/sql/query.py:Query", "django/db/models/query.py:get_related_populators", "django/db/models/query.py:ModelIterable", "django/db/models/sql/compiler.py:SQLCompiler.get_select_for_update_of_arguments"], "found_entities": ["django/db/models/sql/query.py:Query.deferred_to_data", "django/db/models/query.py:prefetch_related_objects", "django/db/models/query.py:get_related_populators", "django/db/models/query.py:ModelIterable.__iter__", "django/db/models/sql/query.py:Query.join_parent_model", "django/db/models/sql/compiler.py:SQLCompiler.get_select_for_update_of_arguments._get_parent_klass_info", "django/db/models/sql/query.py:Query.names_to_path"], "raw_output_loc": ["```\ndjango/db/models/query.py\nline: 2243\nline: 2248\nclass: RelatedPopulator\nfunction: RelatedPopulator.__init__\n\ndjango/db/models/query.py\nline: 2268\nfunction: get_related_populators\n\ndjango/db/models/sql/query.py\nline: 745\nfunction: Query.deferred_to_data\n\ndjango/db/models/sql/query.py\nline: 1100\nfunction: Query.join_parent_model\n\ndjango/db/models/sql/query.py\nline: 1729\nfunction: Query.names_to_path\n```", "```\ndjango/db/models/query.py\nline: 2598-2600\nclass: RelatedPopulator\nfunction: RelatedPopulator.__init__\n\ndjango/db/models/sql/query.py\nline: 745\nfunction: Query.deferred_to_data\n\ndjango/db/models/query.py\nline: 95-101\nclass: ModelIterable\nfunction: ModelIterable.__iter__\n\ndjango/db/models/query.py\nline: 2620-2626\nfunction: get_related_populators\n\ndjango/db/models/sql/compiler.py\nline: 1206-1223\nfunction: _get_parent_klass_info\n```"], "meta_data": {"repo": "django/django", "base_commit": "5eb6a2b33d70b9889e1cafa12594ad6f80773d3a", "problem_statement": "QuerySet.only() after select_related() crash on proxy models.\nDescription\n\t\nWhen I optimize a query using select_related() and only() methods from the proxy model I encounter an error:\nWindows 10; Python 3.10; Django 4.0.5\nTraceback (most recent call last):\n File \"D:\\study\\django_college\\manage.py\", line 22, in <module>\n\tmain()\n File \"D:\\study\\django_college\\manage.py\", line 18, in main\n\texecute_from_command_line(sys.argv)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 446, in execute_from_command_line\n\tutility.execute()\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\core\\management\\__init__.py\", line 440, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\core\\management\\base.py\", line 414, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\core\\management\\base.py\", line 460, in execute\n\toutput = self.handle(*args, **options)\n File \"D:\\study\\django_college\\project\\users\\management\\commands\\test_proxy.py\", line 9, in handle\n\tobjs = list(AnotherModel.objects.select_related(\"custom\").only(\"custom__name\").all())\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\db\\models\\query.py\", line 302, in __len__\n\tself._fetch_all()\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\db\\models\\query.py\", line 1507, in _fetch_all\n\tself._result_cache = list(self._iterable_class(self))\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\db\\models\\query.py\", line 71, in __iter__\n\trelated_populators = get_related_populators(klass_info, select, db)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\db\\models\\query.py\", line 2268, in get_related_populators\n\trel_cls = RelatedPopulator(rel_klass_info, select, db)\n File \"D:\\Anaconda3\\envs\\django\\lib\\site-packages\\django\\db\\models\\query.py\", line 2243, in __init__\n\tself.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\nValueError: 'id' is not in list\nModels:\nclass CustomModel(models.Model):\n\tname = models.CharField(max_length=16)\nclass ProxyCustomModel(CustomModel):\n\tclass Meta:\n\t\tproxy = True\nclass AnotherModel(models.Model):\n\tcustom = models.ForeignKey(\n\t\tProxyCustomModel,\n\t\ton_delete=models.SET_NULL,\n\t\tnull=True,\n\t\tblank=True,\n\t)\nCommand:\nclass Command(BaseCommand):\n\tdef handle(self, *args, **options):\n\t\tlist(AnotherModel.objects.select_related(\"custom\").only(\"custom__name\").all())\nAt django/db/models/sql/query.py in 745 line there is snippet:\nopts = cur_model._meta\nIf I replace it by \nopts = cur_model._meta.concrete_model._meta\nall works as expected.\n", "patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -748,6 +748,7 @@ def deferred_to_data(self, target):\n                     cur_model = source.related_model\n                 else:\n                     cur_model = source.remote_field.model\n+                cur_model = cur_model._meta.concrete_model\n                 opts = cur_model._meta\n                 # Even if we're \"just passing through\" this model, we must add\n                 # both the current model's pk and the related reference field\n"}}
{"instance_id": "pytest-dev__pytest-7432", "found_files": ["src/_pytest/skipping.py", "src/_pytest/python.py", "src/_pytest/nodes.py"], "found_modules": ["src/_pytest/skipping.py:pytest_runtest_makereport", "src/_pytest/skipping.py:pytest_runtest_setup", "src/_pytest/python.py:PyobjMixin", "src/_pytest/nodes.py:Item"], "found_entities": ["src/_pytest/skipping.py:pytest_runtest_makereport", "src/_pytest/skipping.py:pytest_runtest_setup", "src/_pytest/python.py:PyobjMixin.reportinfo", "src/_pytest/nodes.py:Item.reportinfo"], "raw_output_loc": ["```\nsrc/_pytest/skipping.py\nline: 238\nfunction: pytest_runtest_makereport\n\nsrc/_pytest/skipping.py\nline: 236\nfunction: pytest_runtest_setup\n\nsrc/_pytest/skipping.py\nline: 234\nfunction: pytest_runtest_setup\n\nsrc/_pytest/skipping.py\nline: 273\nfunction: pytest_runtest_makereport\n\nsrc/_pytest/skipping.py\nline: 241\nfunction: pytest_runtest_setup\n```", "```\nsrc/_pytest/skipping.py\nline: 273\nline: 274\nline: 294-305\nfunction: pytest_runtest_makereport\n\nsrc/_pytest/python.py\nline: 326-341\nfunction: PyobjMixin.reportinfo\n\nsrc/_pytest/nodes.py\nline: 654-655\nfunction: Item.reportinfo\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "e6e300e729dd33956e5448d8be9a0b1540b4e53a", "problem_statement": "skipping: --runxfail breaks pytest.mark.skip location reporting\npytest versions: 5.4.x, current master\r\n\r\nWhen `@pytest.mark.skip`/`skipif` marks are used to skip a test, for example\r\n\r\n```py\r\nimport pytest\r\n@pytest.mark.skip\r\ndef test_skip_location() -> None:\r\n    assert 0\r\n```\r\n\r\nthe expected skip location reported should point to the item itself, and this is indeed what happens when running with `pytest -rs`:\r\n\r\n```\r\nSKIPPED [1] test_it.py:3: unconditional skip\r\n```\r\n\r\nHowever, adding `pytest -rs --runxfail` breaks this:\r\n\r\n```\r\nSKIPPED [1] src/_pytest/skipping.py:238: unconditional skip\r\n```\r\n\r\nThe `--runxfail` is only about xfail and should not affect this at all.\r\n\r\n---\r\n\r\nHint: the bug is in `src/_pytest/skipping.py`, the `pytest_runtest_makereport` hook.\n", "patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,8 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n"}}
{"instance_id": "django__django-15347", "found_files": ["django/contrib/messages/storage/cookie.py", "django/contrib/messages/storage/session.py", "django/contrib/messages/api.py", "django/contrib/messages/storage/base.py"], "found_modules": ["django/contrib/messages/storage/cookie.py:MessageEncoder", "django/contrib/messages/storage/session.py:SessionStorage", "django/contrib/messages/api.py:debug", "django/contrib/messages/api.py:info", "django/contrib/messages/storage/base.py:Message"], "found_entities": ["django/contrib/messages/storage/cookie.py:MessageEncoder.default", "django/contrib/messages/storage/session.py:SessionStorage.serialize_messages", "django/contrib/messages/api.py:debug", "django/contrib/messages/api.py:info"], "raw_output_loc": ["```\ndjango/contrib/messages/storage/cookie.py\nline: 22\nclass: MessageEncoder\nfunction: MessageEncoder.default\n\ndjango/contrib/messages/storage/session.py\nline: 45\nclass: SessionStorage\nfunction: SessionStorage.serialize_messages\n\ndjango/contrib/messages/api.py\nline: 69\nfunction: debug\nline: 75\nfunction: info\n\ndjango/contrib/messages/storage/base.py\nline: 14\nclass: Message\nfunction: Message.__init__\n```", "```\ndjango/contrib/messages/storage/cookie.py\nline: 22\nclass: MessageEncoder\nfunction: MessageEncoder.default\n```"], "meta_data": {"repo": "django/django", "base_commit": "7c4f3965098baad2396e24501e09237425a7bd6f", "problem_statement": "Messages framework incorrectly serializes/deserializes extra_tags when it's an empty string\nDescription\n\t\nWhen a message is serialised and then deserialised with any of the built in storage backends, then extra_tags==\"\" is converted to extra_tags==None. This is because MessageEncoder checks for the truthyness of extra_tags rather than checking it is not None.\nTo replicate this bug\n>>> from django.conf import settings\n>>> settings.configure() # Just to allow the following import\n>>> from django.contrib.messages.storage.base import Message\n>>> from django.contrib.messages.storage.cookie import MessageEncoder, MessageDecoder\n>>> original_message = Message(10, \"Here is a message\", extra_tags=\"\")\n>>> encoded_message = MessageEncoder().encode(original_message)\n>>> decoded_message = MessageDecoder().decode(encoded_message)\n>>> original_message.extra_tags == \"\"\nTrue\n>>> decoded_message.extra_tags is None\nTrue\nEffect of the bug in application behaviour\nThis error occurred in the wild with a template tag similar to the following:\n{% if x not in message.extra_tags %}\nWhen the message was displayed as part of a redirect, it had been serialised and deserialized which meant that extra_tags was None instead of the empty string. This caused an error.\nIt's important to note that this bug affects all of the standard API (messages.debug, messages.info etc. all have a default value of extra_tags equal to \"\").\n", "patch": "diff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -19,7 +19,7 @@ def default(self, obj):\n             # Using 0/1 here instead of False/True to produce more compact json\n             is_safedata = 1 if isinstance(obj.message, SafeData) else 0\n             message = [self.message_key, is_safedata, obj.level, obj.message]\n-            if obj.extra_tags:\n+            if obj.extra_tags is not None:\n                 message.append(obj.extra_tags)\n             return message\n         return super().default(obj)\n"}}
{"instance_id": "django__django-15498", "found_files": ["django/views/static.py"], "found_modules": ["django/views/static.py:was_modified_since"], "found_entities": ["django/views/static.py:was_modified_since"], "raw_output_loc": ["```\ndjango/views/static.py:was_modified_since\nline: 129\nline: 131\nfunction: was_modified_since\n```", "```\ndjango/views/static.py\nline: 129\nfunction: was_modified_since\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "d90e34c61b27fba2527834806639eebbcfab9631", "problem_statement": "Fix handling empty string for If-Modified-Since header\nDescription\n\t\nEmpty string used to be ignored for If-Modified-Since header, but now raises exception since d6aff369ad3.\nFix handling empty string for If-Modified-Since header\nDescription\n\t\nEmpty string used to be ignored for If-Modified-Since header, but now raises exception since d6aff369ad3.\n", "patch": "diff --git a/django/views/static.py b/django/views/static.py\n--- a/django/views/static.py\n+++ b/django/views/static.py\n@@ -129,12 +129,14 @@ def was_modified_since(header=None, mtime=0, size=0):\n         if header is None:\n             raise ValueError\n         matches = re.match(r\"^([^;]+)(; length=([0-9]+))?$\", header, re.IGNORECASE)\n+        if matches is None:\n+            raise ValueError\n         header_mtime = parse_http_date(matches[1])\n         header_len = matches[3]\n         if header_len and int(header_len) != size:\n             raise ValueError\n         if int(mtime) > header_mtime:\n             raise ValueError\n-    except (AttributeError, ValueError, OverflowError):\n+    except (ValueError, OverflowError):\n         return True\n     return False\n"}}
{"instance_id": "sphinx-doc__sphinx-8595", "found_files": ["sphinx/ext/autodoc/__init__.py", "sphinx/util/inspect.py"], "found_modules": ["sphinx/ext/autodoc/__init__.py:ModuleDocumenter", "sphinx/util/inspect.py:getall"], "found_entities": ["sphinx/ext/autodoc/__init__.py:ModuleDocumenter.import_object", "sphinx/util/inspect.py:getall"], "raw_output_loc": ["```\nsphinx/ext/autodoc/__init__.py\nline: 1015\nclass: ModuleDocumenter\nfunction: ModuleDocumenter.import_object\n\nsphinx/util/inspect.py\nline: 144\nfunction: getall\n```", "```\nsphinx/ext/autodoc/__init__.py\nline: 1020\nclass: ModuleDocumenter\nfunction: ModuleDocumenter.import_object\n\nsphinx/util/inspect.py\nline: 144\nfunction: getall\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "b19bce971e82f2497d67fdacdeca8db08ae0ba56", "problem_statement": "autodoc: empty __all__ attribute is ignored\n**Describe the bug**\r\nautodoc: empty `__all__` attribute is ignored\r\n\r\n**To Reproduce**\r\n```\r\n# example.py\r\n__all__ = []\r\n\r\n\r\ndef foo():\r\n    \"docstring\"\r\n\r\n\r\ndef bar():\r\n    \"docstring\"\r\n\r\n\r\ndef baz():\r\n    \"docstring\"\r\n```\r\n```\r\n# index.rst\r\n.. automodule:: example\r\n   :members:\r\n```\r\n\r\nAll foo, bar, and baz are shown.\r\n\r\n**Expected behavior**\r\nNo entries should be shown because `__all__` is empty.\r\n\r\n**Your project**\r\nNo\r\n\r\n**Screenshots**\r\nNo\r\n\r\n**Environment info**\r\n- OS: Mac\r\n- Python version: 3.9.1\r\n- Sphinx version: HEAD of 3.x\r\n- Sphinx extensions: sphinx.ext.autodoc\r\n- Extra tools: No\r\n\r\n**Additional context**\r\nNo\n", "patch": "diff --git a/sphinx/ext/autodoc/__init__.py b/sphinx/ext/autodoc/__init__.py\n--- a/sphinx/ext/autodoc/__init__.py\n+++ b/sphinx/ext/autodoc/__init__.py\n@@ -1074,7 +1074,7 @@ def get_module_members(self) -> Dict[str, ObjectMember]:\n     def get_object_members(self, want_all: bool) -> Tuple[bool, ObjectMembers]:\n         members = self.get_module_members()\n         if want_all:\n-            if not self.__all__:\n+            if self.__all__ is None:\n                 # for implicit module members, check __module__ to avoid\n                 # documenting imported objects\n                 return True, list(members.values())\n"}}
{"instance_id": "django__django-16041", "found_files": ["django/forms/formsets.py"], "found_modules": ["django/forms/formsets.py:BaseFormSet"], "found_entities": ["django/forms/formsets.py:BaseFormSet.empty_form"], "raw_output_loc": ["```\ndjango/forms/formsets.py\nline: 259\nclass: BaseFormSet\nfunction: BaseFormSet.empty_form\n```", "```\ndjango/forms/formsets.py:BaseFormSet.empty_form\nline: 263\nfunction: BaseFormSet.empty_form\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "6df9398cce063874ae4d59db126d4adacb0fa8d3", "problem_statement": "Rendering empty_form crashes when empty_permitted is passed to form_kwargs\nDescription\n\t\nIssue\nWhen explicitly setting form_kwargs = {'empty_permitted':True} or form_kwargs = {'empty_permitted':False} , a KeyError occurs when rendering a template that uses a formset's empty_form.\nExpected Behavior\nempty_permitted is ignored for formset.empty_form since empty_permitted is irrelevant for empty_form, as empty_form is not meant to be used to pass data and therefore does not need to be validated.\nSteps to Reproduce\n# views.py\nfrom django.shortcuts import render\nfrom .models import MyModel\ndef test_view(request):\n\tcontext = {}\n\tff = modelformset_factory(MyModel, fields = ['a_field'])\n\tcontext['formset'] = ff(\n\t\tqueryset = MyModel.objects.none(),\n\t\tform_kwargs = {'empty_permitted':True} # or form_kwargs = {'empty_permitted':False}\n\t)\n\treturn render(request, 'my_app/my_model_formset.html', context)\n# urls.py\nfrom django.urls import path, include\nfrom .views import test_view\nurlpatterns = [\n\tpath('test', test_view)\n]\n# my_model_formset.html\n{% extends \"my_app/base.html\" %}\n{% block content %}\n<form id=\"my-form\" method=\"post\">\n {% csrf_token %}\n {{ formset }}\n <input type=\"submit\" value=\"Save\">\n</form>\n{{ formset.empty_form }}\n{% endblock %}\n", "patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -257,14 +257,15 @@ def extra_forms(self):\n \n     @property\n     def empty_form(self):\n-        form = self.form(\n-            auto_id=self.auto_id,\n-            prefix=self.add_prefix(\"__prefix__\"),\n-            empty_permitted=True,\n-            use_required_attribute=False,\n+        form_kwargs = {\n             **self.get_form_kwargs(None),\n-            renderer=self.renderer,\n-        )\n+            \"auto_id\": self.auto_id,\n+            \"prefix\": self.add_prefix(\"__prefix__\"),\n+            \"empty_permitted\": True,\n+            \"use_required_attribute\": False,\n+            \"renderer\": self.renderer,\n+        }\n+        form = self.form(**form_kwargs)\n         self.add_fields(form, None)\n         return form\n \n"}}
{"instance_id": "pylint-dev__pylint-5859", "found_files": ["pylint/checkers/misc.py"], "found_modules": ["pylint/checkers/misc.py:EncodingChecker"], "found_entities": ["pylint/checkers/misc.py:EncodingChecker.open", "pylint/checkers/misc.py:EncodingChecker.process_tokens"], "raw_output_loc": ["```\npylint/checkers/misc.py\nline: 122\nline: 123\nline: 124\nline: 125\nline: 126\nline: 127\nline: 128\nclass: EncodingChecker\nfunction: EncodingChecker.open\n\npylint/checkers/misc.py\nline: 190\nline: 191\nline: 192\nline: 193\nline: 194\nline: 195\nline: 196\nline: 197\nline: 198\nclass: EncodingChecker\nfunction: EncodingChecker.process_tokens\n```", "```\npylint/checkers/misc.py\nline: 122\nline: 126\nclass: EncodingChecker\nfunction: EncodingChecker.open\n```"], "meta_data": {"repo": "pylint-dev/pylint", "base_commit": "182cc539b8154c0710fcea7e522267e42eba8899", "problem_statement": "\"--notes\" option ignores note tags that are entirely punctuation\n### Bug description\n\nIf a note tag specified with the `--notes` option is entirely punctuation, pylint won't report a fixme warning (W0511).\r\n\r\n```python\r\n# YES: yes\r\n# ???: no\r\n```\r\n\r\n`pylint test.py --notes=\"YES,???\"` will return a fixme warning (W0511) for the first line, but not the second.\n\n### Configuration\n\n```ini\nDefault\n```\n\n\n### Command used\n\n```shell\npylint test.py --notes=\"YES,???\"\n```\n\n\n### Pylint output\n\n```shell\n************* Module test\r\ntest.py:1:1: W0511: YES: yes (fixme)\n```\n\n\n### Expected behavior\n\n```\r\n************* Module test\r\ntest.py:1:1: W0511: YES: yes (fixme)\r\ntest.py:2:1: W0511: ???: no (fixme)\r\n```\n\n### Pylint version\n\n```shell\npylint 2.12.2\r\nastroid 2.9.0\r\nPython 3.10.2 (main, Feb  2 2022, 05:51:25) [Clang 13.0.0 (clang-1300.0.29.3)]\n```\n\n\n### OS / Environment\n\nmacOS 11.6.1\n\n### Additional dependencies\n\n_No response_\n", "patch": "diff --git a/pylint/checkers/misc.py b/pylint/checkers/misc.py\n--- a/pylint/checkers/misc.py\n+++ b/pylint/checkers/misc.py\n@@ -121,9 +121,9 @@ def open(self):\n \n         notes = \"|\".join(re.escape(note) for note in self.config.notes)\n         if self.config.notes_rgx:\n-            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})\\b\"\n+            regex_string = rf\"#\\s*({notes}|{self.config.notes_rgx})(?=(:|\\s|\\Z))\"\n         else:\n-            regex_string = rf\"#\\s*({notes})\\b\"\n+            regex_string = rf\"#\\s*({notes})(?=(:|\\s|\\Z))\"\n \n         self._fixme_pattern = re.compile(regex_string, re.I)\n \n"}}
{"instance_id": "mwaskom__seaborn-2848", "found_files": ["seaborn/axisgrid.py", "seaborn/_core/rules.py", "seaborn/_oldcore.py"], "found_modules": ["seaborn/axisgrid.py:PairGrid", "seaborn/_core/rules.py:categorical_order", "seaborn/axisgrid.py:pairplot", "seaborn/_oldcore.py:HueMapping", "seaborn/_oldcore.py:categorical_order"], "found_entities": ["seaborn/_core/rules.py:categorical_order", "seaborn/_oldcore.py:HueMapping._lookup_single", "seaborn/axisgrid.py:pairplot", "seaborn/_oldcore.py:categorical_order"], "raw_output_loc": ["```\nseaborn/_core/rules.py\nline: 143\nfunction: categorical_order\n\nseaborn/axisgrid.py\nline: 1281\nclass: PairGrid\nfunction: PairGrid.__init__\n\nseaborn/axisgrid.py\nline: 2084\nfunction: pairplot\n```", "```\nseaborn/axisgrid.py:PairGrid\nline: 1281\nfunction: PairGrid.__init__\n\nseaborn/_oldcore.py:HueMapping._lookup_single\nline: 156\nfunction: HueMapping._lookup_single\n\nseaborn/_oldcore.py:categorical_order\nline: 1747\nfunction: categorical_order\n```"], "meta_data": {"repo": "mwaskom/seaborn", "base_commit": "94621cef29f80282436d73e8d2c0aa76dab81273", "problem_statement": "pairplot fails with hue_order not containing all hue values in seaborn 0.11.1\nIn seaborn < 0.11, one could plot only a subset of the values in the hue column, by passing a hue_order list containing only the desired values. Points with hue values not in the list were simply not plotted.\n```python\niris = sns.load_dataset(\"iris\")`\n# The hue column contains three different species; here we want to plot two\nsns.pairplot(iris, hue=\"species\", hue_order=[\"setosa\", \"versicolor\"])\n```\n\nThis no longer works in 0.11.1. Passing a hue_order list that does not contain some of the values in the hue column raises a long, ugly error traceback. The first exception arises in seaborn/_core.py:\n```\nTypeError: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\n```\nseaborn version: 0.11.1\nmatplotlib version: 3.3.2\nmatplotlib backends: MacOSX, Agg or jupyter notebook inline.", "patch": "diff --git a/seaborn/_oldcore.py b/seaborn/_oldcore.py\n--- a/seaborn/_oldcore.py\n+++ b/seaborn/_oldcore.py\n@@ -149,6 +149,13 @@ def _lookup_single(self, key):\n             # Use a value that's in the original data vector\n             value = self.lookup_table[key]\n         except KeyError:\n+\n+            if self.norm is None:\n+                # Currently we only get here in scatterplot with hue_order,\n+                # because scatterplot does not consider hue a grouping variable\n+                # So unused hue levels are in the data, but not the lookup table\n+                return (0, 0, 0, 0)\n+\n             # Use the colormap to interpolate between existing datapoints\n             # (e.g. in the context of making a continuous legend)\n             try:\n"}}
{"instance_id": "sympy__sympy-23191", "found_files": ["sympy/printing/pretty/pretty.py", "sympy/vector/coordsysrect.py", "sympy/vector/deloperator.py", "sympy/vector/vector.py", "sympy/vector/__init__.py", "sympy/printing/printer.py"], "found_modules": ["sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/vector/coordsysrect.py:CoordSys3D", "sympy/vector/vector.py:VectorAdd", "sympy/vector/deloperator.py:Del", "sympy/printing/pretty/pretty.py:pretty_print", "sympy/printing/printer.py:Printer"], "found_entities": ["sympy/printing/pretty/pretty.py:PrettyPrinter._print_BasisDependent", "sympy/vector/vector.py:VectorAdd._sympystr", "sympy/printing/pretty/pretty.py:pretty_print", "sympy/vector/coordsysrect.py:CoordSys3D._sympystr", "sympy/vector/coordsysrect.py:CoordSys3D.__new__", "sympy/vector/deloperator.py:Del._sympystr", "sympy/vector/deloperator.py:Del.__new__", "sympy/printing/printer.py:Printer._print"], "raw_output_loc": ["```\nsympy/printing/pretty/pretty.py\nline: 1094\nfunction: _print_BasisDependent\n\nsympy/vector/vector.py\nline: 415\nfunction: VectorAdd._sympystr\n\nsympy/vector/coordsysrect.py\nline: 254\nfunction: CoordSys3D._sympystr\n\nsympy/vector/deloperator.py\nline: 120\nfunction: Del._sympystr\n\nsympy/printing/printer.py\nline: 294\nfunction: Printer._print\n```", "```\nsympy/printing/pretty/pretty.py\nline: 1095\nfunction: PrettyPrinter._print_BasisDependent\n\nsympy/vector/coordsysrect.py\nline: 25\nclass: CoordSys3D\nfunction: CoordSys3D.__new__\n\nsympy/vector/deloperator.py\nline: 5\nclass: Del\nfunction: Del.__new__\n\nsympy/printing/pretty/pretty.py\nline: 2859\nfunction: pretty_print\n\nsympy/vector/__init__.py\nline: 1\nfunction: (module-level imports)\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "fa9b4b140ec0eaf75a62c1111131626ef0f6f524", "problem_statement": "display bug while using pretty_print with sympy.vector object in the terminal\nThe following code jumbles some of the outputs in the terminal, essentially by inserting the unit vector in the middle -\r\n```python\r\nfrom sympy import *\r\nfrom sympy.vector import CoordSys3D, Del\r\n\r\ninit_printing()\r\n\r\ndelop = Del()\r\nCC_ = CoordSys3D(\"C\")\r\nx,    y,    z    = CC_.x, CC_.y, CC_.z\r\nxhat, yhat, zhat = CC_.i, CC_.j, CC_.k\r\n\r\nt = symbols(\"t\")\r\nten = symbols(\"10\", positive=True)\r\neps, mu = 4*pi*ten**(-11), ten**(-5)\r\n\r\nBx = 2 * ten**(-4) * cos(ten**5 * t) * sin(ten**(-3) * y)\r\nvecB = Bx * xhat\r\nvecE = (1/eps) * Integral(delop.cross(vecB/mu).doit(), t)\r\n\r\npprint(vecB)\r\nprint()\r\npprint(vecE)\r\nprint()\r\npprint(vecE.doit())\r\n```\r\n\r\nOutput:\r\n```python\r\n\u239b     \u239by_C\u239e    \u239b  5  \u239e\u239e    \r\n\u239c2\u22c5sin\u239c\u2500\u2500\u2500\u239f i_C\u22c5cos\u239d10 \u22c5t\u23a0\u239f\r\n\u239c     \u239c  3\u239f           \u239f    \r\n\u239c     \u239d10 \u23a0           \u239f    \r\n\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u239f    \r\n\u239c           4         \u239f    \r\n\u239d         10          \u23a0    \r\n\r\n\u239b     \u2320                           \u239e    \r\n\u239c     \u23ae       \u239by_C\u239e    \u239b  5  \u239e    \u239f k_C\r\n\u239c     \u23ae -2\u22c5cos\u239c\u2500\u2500\u2500\u239f\u22c5cos\u239d10 \u22c5t\u23a0    \u239f    \r\n\u239c     \u23ae       \u239c  3\u239f               \u239f    \r\n\u239c  11 \u23ae       \u239d10 \u23a0               \u239f    \r\n\u239c10  \u22c5\u23ae \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 dt\u239f    \r\n\u239c     \u23ae             2             \u239f    \r\n\u239c     \u23ae           10              \u239f    \r\n\u239c     \u2321                           \u239f    \r\n\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u239f    \r\n\u239d               4\u22c5\u03c0               \u23a0    \r\n\r\n\u239b   4    \u239b  5  \u239e    \u239by_C\u239e \u239e    \r\n\u239c-10 \u22c5sin\u239d10 \u22c5t\u23a0\u22c5cos\u239c\u2500\u2500\u2500\u239f k_C \u239f\r\n\u239c                   \u239c  3\u239f \u239f    \r\n\u239c                   \u239d10 \u23a0 \u239f    \r\n\u239c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u239f    \r\n\u239d           2\u22c5\u03c0           \u23a0    ```\n", "patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -1144,22 +1144,24 @@ def _print_BasisDependent(self, expr):\n             if '\\n' in partstr:\n                 tempstr = partstr\n                 tempstr = tempstr.replace(vectstrs[i], '')\n-                if '\\N{right parenthesis extension}' in tempstr:   # If scalar is a fraction\n+                if '\\N{RIGHT PARENTHESIS EXTENSION}' in tempstr:   # If scalar is a fraction\n                     for paren in range(len(tempstr)):\n                         flag[i] = 1\n-                        if tempstr[paren] == '\\N{right parenthesis extension}':\n-                            tempstr = tempstr[:paren] + '\\N{right parenthesis extension}'\\\n+                        if tempstr[paren] == '\\N{RIGHT PARENTHESIS EXTENSION}' and tempstr[paren + 1] == '\\n':\n+                            # We want to place the vector string after all the right parentheses, because\n+                            # otherwise, the vector will be in the middle of the string\n+                            tempstr = tempstr[:paren] + '\\N{RIGHT PARENTHESIS EXTENSION}'\\\n                                          + ' '  + vectstrs[i] + tempstr[paren + 1:]\n                             break\n                 elif '\\N{RIGHT PARENTHESIS LOWER HOOK}' in tempstr:\n-                    flag[i] = 1\n-                    tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS LOWER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS LOWER HOOK}'\n-                                        + ' ' + vectstrs[i])\n-                else:\n-                    tempstr = tempstr.replace('\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                        '\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                        + ' ' + vectstrs[i])\n+                    # We want to place the vector string after all the right parentheses, because\n+                    # otherwise, the vector will be in the middle of the string. For this reason,\n+                    # we insert the vector string at the rightmost index.\n+                    index = tempstr.rfind('\\N{RIGHT PARENTHESIS LOWER HOOK}')\n+                    if index != -1: # then this character was found in this string\n+                        flag[i] = 1\n+                        tempstr = tempstr[:index] + '\\N{RIGHT PARENTHESIS LOWER HOOK}'\\\n+                                     + ' '  + vectstrs[i] + tempstr[index + 1:]\n                 o1[i] = tempstr\n \n         o1 = [x.split('\\n') for x in o1]\n"}}
{"instance_id": "django__django-12856", "found_files": ["django/db/models/constraints.py", "django/db/models/base.py", "django/db/migrations/autodetector.py"], "found_modules": ["django/db/models/constraints.py:UniqueConstraint", "django/db/models/base.py:Model", "django/db/migrations/autodetector.py:MigrationAutodetector"], "found_entities": ["django/db/models/base.py:Model._check_local_fields", "django/db/migrations/autodetector.py:MigrationAutodetector._detect_changes"], "raw_output_loc": ["```\ndjango/db/models/constraints.py:UniqueConstraint\nline: 80\nfunction: UniqueConstraint.__init__\n\n```", "```\ndjango/db/models/constraints.py:UniqueConstraint\nfunction: UniqueConstraint.__init__\n\ncore/checks/messages.py\nfunction: Error\n\ncore/checks/registry.py\nfunction: registry.register\n\ndjango/db/models/base.py\nline: 1640\nfunction: Model._check_local_fields\n\ndjango/db/migrations/autodetector.py\nfunction: MigrationAutodetector._detect_changes\n```"], "meta_data": {"repo": "django/django", "base_commit": "8328811f048fed0dd22573224def8c65410c9f2e", "problem_statement": "Add check for fields of UniqueConstraints.\nDescription\n\t \n\t\t(last modified by Marnanel Thurman)\n\t \nWhen a model gains a UniqueConstraint, makemigrations doesn't check that the fields named therein actually exist.\nThis is in contrast to the older unique_together syntax, which raises models.E012 if the fields don't exist.\nIn the attached demonstration, you'll need to uncomment \"with_unique_together\" in settings.py in order to show that unique_together raises E012.\n", "patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1926,6 +1926,12 @@ def _check_constraints(cls, databases):\n                         id='models.W038',\n                     )\n                 )\n+            fields = (\n+                field\n+                for constraint in cls._meta.constraints if isinstance(constraint, UniqueConstraint)\n+                for field in constraint.fields\n+            )\n+            errors.extend(cls._check_local_fields(fields, 'constraints'))\n         return errors\n \n \n"}}
{"instance_id": "scikit-learn__scikit-learn-13779", "found_files": ["sklearn/ensemble/voting.py"], "found_modules": ["sklearn/ensemble/voting.py:_BaseVoting"], "found_entities": ["sklearn/ensemble/voting.py:_BaseVoting.fit"], "raw_output_loc": ["```\nsklearn/ensemble/voting.py\nline: 79\nline: 80\nline: 81\nline: 82\nline: 83\nclass: _BaseVoting\nfunction: _BaseVoting.fit\n```", "```\nsklearn/ensemble/voting.py:_BaseVoting\nline: 79\nline: 80\nline: 81\nline: 82\nline: 83\nfunction: _BaseVoting.fit\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "b34751b7ed02b2cfcc36037fb729d4360480a299", "problem_statement": "Voting estimator will fail at fit if weights are passed and an estimator is None\nBecause we don't check for an estimator to be `None` in `sample_weight` support, `fit` is failing`.\r\n\r\n```python\r\n    X, y = load_iris(return_X_y=True)\r\n    voter = VotingClassifier(\r\n        estimators=[('lr', LogisticRegression()),\r\n                    ('rf', RandomForestClassifier())]\r\n    )\r\n    voter.fit(X, y, sample_weight=np.ones(y.shape))\r\n    voter.set_params(lr=None)\r\n    voter.fit(X, y, sample_weight=np.ones(y.shape))\r\n```\r\n\r\n```\r\nAttributeError: 'NoneType' object has no attribute 'fit'\r\n```\n", "patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,6 +78,8 @@ def fit(self, X, y, sample_weight=None):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n"}}
{"instance_id": "sympy__sympy-13437", "found_files": ["sympy/functions/combinatorial/numbers.py", "sympy/series/limits.py", "sympy/core/expr.py", "sympy/series/gruntz.py", "sympy/core/function.py"], "found_modules": ["sympy/core/expr.py:Expr", "sympy/series/limits.py:Limit", "sympy/functions/combinatorial/numbers.py:bell", "sympy/series/gruntz.py:gruntz", "sympy/series/gruntz.py:limitinf", "sympy/core/function.py:Function"], "found_entities": ["sympy/core/expr.py:Expr.limit", "sympy/series/limits.py:Limit.doit", "sympy/functions/combinatorial/numbers.py:bell.eval", "sympy/series/gruntz.py:gruntz", "sympy/series/gruntz.py:limitinf", "sympy/core/function.py:Function.__new__"], "raw_output_loc": ["```\nsympy/functions/combinatorial/numbers.py\nclass: bell\nfunction: bell._eval_as_leading_term\n\nsympy/core/expr.py\nfunction: Expr.limit\n\nsympy/series/limits.py\nclass: Limit\nfunction: Limit.doit\n\nsympy/series/gruntz.py\nfunction: gruntz\n\nsympy/series/gruntz.py\nfunction: limitinf\n```", "```\nsympy/functions/combinatorial/numbers.py\nline: 436\nclass: bell\nfunction: bell.eval\n\nsympy/series/limits.py\nline: 130\nclass: Limit\nfunction: Limit.doit\n\nsympy/core/function.py\nline: 436\nclass: Function\nfunction: Function.eval\n\nsympy/series/gruntz.py\nline: 628\nfunction: gruntz\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "674afc619d7f5c519b6a5393a8b0532a131e57e0", "problem_statement": "bell(n).limit(n, oo) should be oo rather than bell(oo)\n`bell(n).limit(n,oo)` should take the value infinity, but the current output is `bell(oo)`. As the Bell numbers represent the number of partitions of a set, it seems natural that `bell(oo)` should be able to be evaluated rather than be returned unevaluated. This issue is also in line with the recent fixes to the corresponding limit for the Fibonacci numbers and Lucas numbers.\n\n```\nfrom sympy import *\nn = symbols('n')\nbell(n).limit(n,oo)\n\nOutput:\nbell(oo)\n```\n\nI'm new to Sympy, so I'd appreciate the opportunity to fix this bug myself if that's alright.\n\n", "patch": "diff --git a/sympy/functions/combinatorial/numbers.py b/sympy/functions/combinatorial/numbers.py\n--- a/sympy/functions/combinatorial/numbers.py\n+++ b/sympy/functions/combinatorial/numbers.py\n@@ -424,6 +424,15 @@ def _bell_incomplete_poly(n, k, symbols):\n \n     @classmethod\n     def eval(cls, n, k_sym=None, symbols=None):\n+        if n is S.Infinity:\n+            if k_sym is None:\n+                return S.Infinity\n+            else:\n+                raise ValueError(\"Bell polynomial is not defined\")\n+\n+        if n.is_negative or n.is_integer is False:\n+            raise ValueError(\"a non-negative integer expected\")\n+\n         if n.is_Integer and n.is_nonnegative:\n             if k_sym is None:\n                 return Integer(cls._bell(int(n)))\n"}}
{"instance_id": "sympy__sympy-16281", "found_files": ["sympy/printing/pretty/pretty.py", "sympy/concrete/products.py"], "found_modules": ["sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/concrete/products.py:Product"], "found_entities": ["sympy/printing/pretty/pretty.py:PrettyPrinter._print_Product"], "raw_output_loc": ["```\nsympy/printing/pretty/pretty.py\nline: 473\nfunction: PrettyPrinter._print_Product\n\nsympy/printing/pretty/pretty.py\nline: 493\nline: 495\nline: 496\nline: 497\nfunction: PrettyPrinter._print_Product\n\nsympy/printing/pretty/pretty.py\nline: 484\nfunction: PrettyPrinter._print_Product\n```", "```\nsympy/printing/pretty/pretty.py\nline: 473\nclass: PrettyPrinter\nfunction: PrettyPrinter._print_Product\n\nsympy/concrete/products.py\nline: 13\nclass: Product\nfunction: Product\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "41490b75f3621408e0468b0e7b6dc409601fc6ff", "problem_statement": "Product pretty print could be improved\nThis is what the pretty printing for `Product` looks like:\r\n\r\n```\r\n>>> pprint(Product(1, (n, 1, oo)))\r\n  \u221e\r\n\u252c\u2500\u2500\u2500\u252c\r\n\u2502   \u2502 1\r\n\u2502   \u2502\r\nn = 1\r\n>>> pprint(Product(1/n, (n, 1, oo)))\r\n   \u221e\r\n\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\r\n\u2502      \u2502 1\r\n\u2502      \u2502 \u2500\r\n\u2502      \u2502 n\r\n\u2502      \u2502\r\n n = 1\r\n>>> pprint(Product(1/n**2, (n, 1, oo)))\r\n    \u221e\r\n\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\r\n\u2502        \u2502 1\r\n\u2502        \u2502 \u2500\u2500\r\n\u2502        \u2502  2\r\n\u2502        \u2502 n\r\n\u2502        \u2502\r\n  n = 1\r\n>>> pprint(Product(1, (n, 1, oo)), use_unicode=False)\r\n  oo\r\n_____\r\n|   | 1\r\n|   |\r\nn = 1\r\n>>> pprint(Product(1/n, (n, 1, oo)), use_unicode=False)\r\n   oo\r\n________\r\n|      | 1\r\n|      | -\r\n|      | n\r\n|      |\r\n n = 1\r\n>>> pprint(Product(1/n**2, (n, 1, oo)), use_unicode=False)\r\n    oo\r\n__________\r\n|        | 1\r\n|        | --\r\n|        |  2\r\n|        | n\r\n|        |\r\n  n = 1\r\n```\r\n\r\n(if those don't look good in your browser copy paste them into the terminal)\r\n\r\nThis could be improved:\r\n\r\n- Why is there always an empty line at the bottom of the \u220f? Keeping everything below the horizontal line is good, but the bottom looks asymmetric, and it makes the \u220f bigger than it needs to be.\r\n\r\n- The \u220f is too fat IMO. \r\n\r\n- It might look better if we extended the top bar. I'm unsure about this. \r\n\r\nCompare this\r\n\r\n```\r\n    \u221e\r\n\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\r\n \u2502     \u2502  1\r\n \u2502     \u2502  \u2500\u2500\r\n \u2502     \u2502   2\r\n \u2502     \u2502  n\r\n  n = 1\r\n```\r\n\r\nThat's still almost twice as wide as the equivalent Sum, but if you make it much skinnier it starts to look bad.\r\n\r\n```\r\n  \u221e\r\n ____\r\n \u2572\r\n  \u2572   1\r\n   \u2572  \u2500\u2500\r\n   \u2571   2\r\n  \u2571   n\r\n \u2571\r\n \u203e\u203e\u203e\u203e\r\nn = 1\r\n```\n", "patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -491,10 +491,9 @@ def _print_Product(self, expr):\n \n         for lim in expr.limits:\n             width = (func_height + 2) * 5 // 3 - 2\n-            sign_lines = []\n-            sign_lines.append(corner_chr + (horizontal_chr*width) + corner_chr)\n-            for i in range(func_height + 1):\n-                sign_lines.append(vertical_chr + (' '*width) + vertical_chr)\n+            sign_lines = [horizontal_chr + corner_chr + (horizontal_chr * (width-2)) + corner_chr + horizontal_chr]\n+            for _ in range(func_height + 1):\n+                sign_lines.append(' ' + vertical_chr + (' ' * (width-2)) + vertical_chr + ' ')\n \n             pretty_sign = stringPict('')\n             pretty_sign = prettyForm(*pretty_sign.stack(*sign_lines))\n"}}
{"instance_id": "matplotlib__matplotlib-23314", "found_files": ["lib/mpl_toolkits/mplot3d/axes3d.py", "lib/matplotlib/artist.py"], "found_modules": ["lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D", "lib/matplotlib/artist.py:Artist"], "found_entities": ["lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D.draw", "lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D.set_axis_off", "lib/matplotlib/artist.py:Artist.set_visible", "lib/matplotlib/artist.py:Artist.draw", "lib/mpl_toolkits/mplot3d/axes3d.py:Axes3D.set_axis_on"], "raw_output_loc": ["```\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 389\nclass: Axes3D\nfunction: Axes3D.draw\n\nlib/matplotlib/artist.py\nline: 948\nfunction: Artist.draw\n\nlib/matplotlib/artist.py\nline: 1008\nfunction: Artist.set_visible\n```", "```\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 188\nline: 192\nclass: Axes3D\nfunction: Axes3D.set_axis_off\nfunction: Axes3D.set_axis_on\n\nlib/matplotlib/artist.py\nline: 1008\nclass: Artist\nfunction: Artist.set_visible\n\nlib/mpl_toolkits/mplot3d/axes3d.py\nline: 174\nclass: Axes3D\nfunction: Axes3D.spines\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "97fc1154992f64cfb2f86321155a7404efeb2d8a", "problem_statement": "[Bug]: set_visible() not working for 3d projection \n### Bug summary\r\n\r\nin the subplot projection=\"3d\" the set_visible function doesn't work even if the value is set to False\r\n\r\n### Code for reproduction\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.gridspec import GridSpec\r\n\r\nfig, (ax1, ax2) = plt.subplots(1, 2, subplot_kw={'projection': '3d'})\r\nax1.scatter(1,1,1)\r\nax2.scatter(1,1,1, c='r')\r\nax1.set_visible(False)\r\n\r\nplt.show()\r\n# Thanks Tim for your help! \r\n```\r\n\r\n\r\n### Actual outcome\r\n\r\nthe subplot remains visible which should not happen if the value is set to False\r\n\r\n### Expected outcome\r\n\r\nthe subplot is not visible if the value is set to False\r\n\r\n### Additional information\r\n\r\n_No response_\r\n\r\n### Operating system\r\n\r\n_No response_\r\n\r\n### Matplotlib Version\r\n\r\n3.4.2\r\n\r\n### Matplotlib Backend\r\n\r\nQt5Agg\r\n\r\n### Python version\r\n\r\n3.8.10\r\n\r\n### Jupyter version\r\n\r\n_No response_\r\n\r\n### Installation\r\n\r\n_No response_\n", "patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -387,6 +387,8 @@ def apply_aspect(self, position=None):\n \n     @martist.allow_rasterization\n     def draw(self, renderer):\n+        if not self.get_visible():\n+            return\n         self._unstale_viewLim()\n \n         # draw the background patch\n"}}
{"instance_id": "django__django-11848", "found_files": ["django/utils/http.py"], "found_modules": ["django/utils/http.py:parse_http_date"], "found_entities": ["django/utils/http.py:parse_http_date"], "raw_output_loc": ["```\ndjango/utils/http.py\nline: 177\nline: 178\nline: 179\nline: 180\nline: 181\nline: 182\nfunction: parse_http_date\n```", "```\ndjango/utils/http.py\nline: 177\nline: 178\nline: 179\nline: 180\nline: 181\nline: 182\nfunction: parse_http_date\n```"], "meta_data": {"repo": "django/django", "base_commit": "f0adf3b9b7a19cdee05368ff0c0c2d087f011180", "problem_statement": "django.utils.http.parse_http_date two digit year check is incorrect\nDescription\n\t \n\t\t(last modified by Ad Timmering)\n\t \nRFC 850 does not mention this, but in RFC 7231 (and there's something similar in RFC 2822), there's the following quote:\nRecipients of a timestamp value in rfc850-date format, which uses a\ntwo-digit year, MUST interpret a timestamp that appears to be more\nthan 50 years in the future as representing the most recent year in\nthe past that had the same last two digits.\nCurrent logic is hard coded to consider 0-69 to be in 2000-2069, and 70-99 to be 1970-1999, instead of comparing versus the current year.\n", "patch": "diff --git a/django/utils/http.py b/django/utils/http.py\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,14 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n+            current_year = datetime.datetime.utcnow().year\n+            current_century = current_year - (current_year % 100)\n+            if year - (current_year % 100) > 50:\n+                # year that appears to be more than 50 years in the future are\n+                # interpreted as representing the past.\n+                year += current_century - 100\n             else:\n-                year += 1900\n+                year += current_century\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"}}
{"instance_id": "django__django-16400", "found_files": ["django/core/management/commands/migrate.py", "django/core/management/sql.py", "django/contrib/auth/management/__init__.py", "django/db/utils.py"], "found_modules": ["django/core/management/commands/migrate.py:Command", "django/contrib/auth/management/__init__.py:create_permissions", "django/core/management/sql.py:emit_post_migrate_signal", "django/db/utils.py:ConnectionRouter"], "found_entities": ["django/core/management/commands/migrate.py:Command.handle", "django/contrib/auth/management/__init__.py:create_permissions", "django/core/management/sql.py:emit_post_migrate_signal", "django/db/utils.py:ConnectionRouter._router_func"], "raw_output_loc": ["```\ndjango/core/management/commands/migrate.py\nline: 98\nline: 112\nline: 356\nline: 383\nclass: Command\nfunction: Command.handle\n\ndjango/core/management/sql.py\nline: 42\nline: 52\nfunction: emit_post_migrate_signal\n\ndjango/contrib/auth/management/__init__.py\nline: 41\nline: 68\nline: 79\nline: 91\nfunction: create_permissions\n\ndjango/db/utils.py\nline: 204\nline: 237\nline: 238\nclass: ConnectionRouter\nfunction: ConnectionRouter._router_func\n\nutils/tenant_db_router.py\nline: 30\nline: 40\nclass: TenantDatabaseRouter\nfunction: TenantDatabaseRouter.db_for_read\nfunction: TenantDatabaseRouter.db_for_write\n```", "```\ndjango/core/management/commands/migrate.py\nline: 98\nfunction: Command.handle\n\ncore/management/sql.py\nline: 42\nfunction: emit_post_migrate_signal\n\ncore/management/sql.py\nline: 52\nfunction: models.signals.post_migrate.send\n```"], "meta_data": {"repo": "django/django", "base_commit": "0bd2c0c9015b53c41394a1c0989afbfd94dc2830", "problem_statement": "migrate management command does not respect database parameter when adding Permissions.\nDescription\n\t \n\t\t(last modified by Vasanth)\n\t \nWhen invoking migrate with a database parameter, the migration runs successfully. However, there seems to be a DB read request that runs after the migration. This call does not respect the db param and invokes the db router .\nWhen naming the db as a parameter, all DB calls in the context of the migrate command are expected to use the database specified.\nI came across this as I am currently using a thread-local variable to get the active DB with a custom DB router for a multi-tenant service .\nMinimal example \nSetup the custom middleware and custom DB Router as show below. Then run any DB migration. We see that \"read {}\" is being printed before the exception message.\nIdeally none of this code must be called as the DB was specified during management command.\nfrom threading import local\nfrom django.conf import settings\nlocal_state = local()\nclass InvalidTenantException(Exception):\n\tpass\nclass TenantSubdomainMiddleware:\n\tdef __init__(self, get_response):\n\t\tself.get_response = get_response\n\tdef __call__(self, request):\n\t\t## Get Subdomain\n\t\thost = request.get_host().split(\":\")[0]\n\t\tlocal_state.subdomain = (\n\t\t\t# We assume single level of subdomain : app.service.com \n\t\t\t# HOST_IP : used to for local dev. \n\t\t\thost if host in settings.HOST_IP else host.split(\".\")[0]\n\t\t)\n\t\tresponse = self.get_response(request)\n\t\treturn response\nclass TenantDatabaseRouter:\n\tdef _default_db(self):\n\t\tsubdomain = getattr(local_state, \"subdomain\", None)\n\t\tif subdomain is not None and subdomain in settings.TENANT_MAP:\n\t\t\tdb_name = settings.TENANT_MAP[local_state.subdomain]\n\t\t\treturn db_name\n\t\telse:\n\t\t\traise InvalidTenantException()\n\tdef db_for_read(self, model, **hints):\n\t\tprint(\"read\", hints)\n\t\treturn self._default_db()\n\tdef db_for_write(self, model, **hints):\n\t\tprint(\"write\", hints)\n\t\treturn self._default_db()\n\tdef allow_relation(self, obj1, obj2, **hints):\n\t\treturn None\n\tdef allow_migrate(self, db, app_label, model_name=None, **hints):\n\t\treturn None\n## settings.py\nMIDDLEWARE = [\n\t\"utils.tenant_db_router.TenantSubdomainMiddleware\",\n\t\"django.middleware.security.SecurityMiddleware\",\n\t...\n]\nTENANT_MAP = {\"localhost\":\"default\", \"tenant_1\":\"default\"}\nDATABASE_ROUTERS = [\"utils.tenant_db_router.TenantDatabaseRouter\"]\n", "patch": "diff --git a/django/contrib/auth/management/__init__.py b/django/contrib/auth/management/__init__.py\n--- a/django/contrib/auth/management/__init__.py\n+++ b/django/contrib/auth/management/__init__.py\n@@ -95,11 +95,16 @@ def create_permissions(\n         .values_list(\"content_type\", \"codename\")\n     )\n \n-    perms = [\n-        Permission(codename=codename, name=name, content_type=ct)\n-        for ct, (codename, name) in searched_perms\n-        if (ct.pk, codename) not in all_perms\n-    ]\n+    perms = []\n+    for ct, (codename, name) in searched_perms:\n+        if (ct.pk, codename) not in all_perms:\n+            permission = Permission()\n+            permission._state.db = using\n+            permission.codename = codename\n+            permission.name = name\n+            permission.content_type = ct\n+            perms.append(permission)\n+\n     Permission.objects.using(using).bulk_create(perms)\n     if verbosity >= 2:\n         for perm in perms:\n"}}
{"instance_id": "django__django-12589", "found_files": ["django/db/models/sql/query.py", "django/db/models/expressions.py", "django/db/models/query.py", "django/db/models/aggregates.py"], "found_modules": ["django/db/models/sql/query.py:Query", "django/db/models/expressions.py:Subquery", "django/db/models/query.py:QuerySet", "django/db/models/aggregates.py:Count"], "found_entities": ["django/db/models/sql/query.py:Query.set_group_by", "django/db/models/expressions.py:Subquery.get_group_by_cols", "django/db/models/query.py:QuerySet.annotate", "django/db/models/expressions.py:Subquery.as_sql"], "raw_output_loc": ["```\ndjango/db/models/sql/query.py\nline: 1921\nfunction: Query.set_group_by\n\n```", "```\ndjango/db/models/sql/query.py\nline: 1921\nfunction: Query.set_group_by\n\ndjango/db/models/expressions.py\nline: 1052\nfunction: Subquery.get_group_by_cols\n\ndjango/db/models/query.py\nline: 1067\nfunction: QuerySet.annotate\n\ndjango/db/models/aggregates.py\nline: 105\nfunction: Count\n\ndjango/db/models/expressions.py\nline: 1006\nclass: Subquery\nfunction: Subquery.as_sql\n```"], "meta_data": {"repo": "django/django", "base_commit": "895f28f9cbed817c00ab68770433170d83132d90", "problem_statement": "Django 3.0: \"GROUP BY\" clauses error with tricky field annotation\nDescription\n\t\nLet's pretend that we have next model structure with next model's relations:\nclass A(models.Model):\n\tbs = models.ManyToManyField('B',\n\t\t\t\t\t\t\t\trelated_name=\"a\",\n\t\t\t\t\t\t\t\tthrough=\"AB\")\nclass B(models.Model):\n\tpass\nclass AB(models.Model):\n\ta = models.ForeignKey(A, on_delete=models.CASCADE, related_name=\"ab_a\")\n\tb = models.ForeignKey(B, on_delete=models.CASCADE, related_name=\"ab_b\")\n\tstatus = models.IntegerField()\nclass C(models.Model):\n\ta = models.ForeignKey(\n\t\tA,\n\t\tnull=True,\n\t\tblank=True,\n\t\ton_delete=models.SET_NULL,\n\t\trelated_name=\"c\",\n\t\tverbose_name=_(\"a\")\n\t)\n\tstatus = models.IntegerField()\nLet's try to evaluate next query\nab_query = AB.objects.filter(a=OuterRef(\"pk\"), b=1)\nfilter_conditions = Q(pk=1) | Q(ab_a__b=1)\nquery = A.objects.\\\n\tfilter(filter_conditions).\\\n\tannotate(\n\t\tstatus=Subquery(ab_query.values(\"status\")),\n\t\tc_count=Count(\"c\"),\n)\nanswer = query.values(\"status\").annotate(total_count=Count(\"status\"))\nprint(answer.query)\nprint(answer)\nOn Django 3.0.4 we have an error\ndjango.db.utils.ProgrammingError: column reference \"status\" is ambiguous\nand query is next:\nSELECT (SELECT U0.\"status\" FROM \"test_app_ab\" U0 WHERE (U0.\"a_id\" = \"test_app_a\".\"id\" AND U0.\"b_id\" = 1)) AS \"status\", COUNT((SELECT U0.\"status\" FROM \"test_app_ab\" U0 WHERE (U0.\"a_id\" = \"test_app_a\".\"id\" AND U0.\"b_id\" = 1))) AS \"total_count\" FROM \"test_app_a\" LEFT OUTER JOIN \"test_app_ab\" ON (\"test_app_a\".\"id\" = \"test_app_ab\".\"a_id\") LEFT OUTER JOIN \"test_app_c\" ON (\"test_app_a\".\"id\" = \"test_app_c\".\"a_id\") WHERE (\"test_app_a\".\"id\" = 1 OR \"test_app_ab\".\"b_id\" = 1) GROUP BY \"status\"\nHowever, Django 2.2.11 processed this query properly with the next query:\nSELECT (SELECT U0.\"status\" FROM \"test_app_ab\" U0 WHERE (U0.\"a_id\" = (\"test_app_a\".\"id\") AND U0.\"b_id\" = 1)) AS \"status\", COUNT((SELECT U0.\"status\" FROM \"test_app_ab\" U0 WHERE (U0.\"a_id\" = (\"test_app_a\".\"id\") AND U0.\"b_id\" = 1))) AS \"total_count\" FROM \"test_app_a\" LEFT OUTER JOIN \"test_app_ab\" ON (\"test_app_a\".\"id\" = \"test_app_ab\".\"a_id\") LEFT OUTER JOIN \"test_app_c\" ON (\"test_app_a\".\"id\" = \"test_app_c\".\"a_id\") WHERE (\"test_app_a\".\"id\" = 1 OR \"test_app_ab\".\"b_id\" = 1) GROUP BY (SELECT U0.\"status\" FROM \"test_app_ab\" U0 WHERE (U0.\"a_id\" = (\"test_app_a\".\"id\") AND U0.\"b_id\" = 1))\nso, the difference in \"GROUP BY\" clauses\n(as DB provider uses \"django.db.backends.postgresql\", postgresql 11)\n", "patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1927,6 +1927,19 @@ def set_group_by(self, allow_aliases=True):\n         primary key, and the query would be equivalent, the optimization\n         will be made automatically.\n         \"\"\"\n+        # Column names from JOINs to check collisions with aliases.\n+        if allow_aliases:\n+            column_names = set()\n+            seen_models = set()\n+            for join in list(self.alias_map.values())[1:]:  # Skip base table.\n+                model = join.join_field.related_model\n+                if model not in seen_models:\n+                    column_names.update({\n+                        field.column\n+                        for field in model._meta.local_concrete_fields\n+                    })\n+                    seen_models.add(model)\n+\n         group_by = list(self.select)\n         if self.annotation_select:\n             for alias, annotation in self.annotation_select.items():\n@@ -1940,7 +1953,7 @@ def set_group_by(self, allow_aliases=True):\n                     warnings.warn(msg, category=RemovedInDjango40Warning)\n                     group_by_cols = annotation.get_group_by_cols()\n                 else:\n-                    if not allow_aliases:\n+                    if not allow_aliases or alias in column_names:\n                         alias = None\n                     group_by_cols = annotation.get_group_by_cols(alias=alias)\n                 group_by.extend(group_by_cols)\n"}}
{"instance_id": "scikit-learn__scikit-learn-10949", "found_files": ["sklearn/utils/validation.py"], "found_modules": ["sklearn/utils/validation.py:check_array"], "found_entities": ["sklearn/utils/validation.py:check_array"], "raw_output_loc": ["```\nsklearn/utils/validation.py\nline: 464\nline: 465\nline: 466\nline: 467\nfunction: check_array\n```", "```\nsklearn/utils/validation.py\nline: 464\nline: 576\nfunction: check_array\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "3b5abf76597ce6aff76192869f92647c1b5259e7", "problem_statement": "warn_on_dtype with DataFrame\n#### Description\r\n\r\n``warn_on_dtype`` has no effect when input is a pandas ``DataFrame``\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\nfrom sklearn.utils.validation import check_array\r\nimport pandas as pd\r\ndf = pd.DataFrame([[1, 2, 3], [2, 3, 4]], dtype=object)\r\nchecked = check_array(df, warn_on_dtype=True)\r\n```\r\n\r\n#### Expected result: \r\n\r\n```python-traceback\r\nDataConversionWarning: Data with input dtype object was converted to float64.\r\n```\r\n\r\n#### Actual Results\r\nNo warning is thrown\r\n\r\n#### Versions\r\nLinux-4.4.0-116-generic-x86_64-with-debian-stretch-sid\r\nPython 3.6.3 |Anaconda, Inc.| (default, Nov  3 2017, 19:19:16) \r\n[GCC 7.2.0]\r\nNumPy 1.13.1\r\nSciPy 0.19.1\r\nScikit-Learn 0.20.dev0\r\nPandas 0.21.0\r\n\nwarn_on_dtype with DataFrame\n#### Description\r\n\r\n``warn_on_dtype`` has no effect when input is a pandas ``DataFrame``\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\nfrom sklearn.utils.validation import check_array\r\nimport pandas as pd\r\ndf = pd.DataFrame([[1, 2, 3], [2, 3, 4]], dtype=object)\r\nchecked = check_array(df, warn_on_dtype=True)\r\n```\r\n\r\n#### Expected result: \r\n\r\n```python-traceback\r\nDataConversionWarning: Data with input dtype object was converted to float64.\r\n```\r\n\r\n#### Actual Results\r\nNo warning is thrown\r\n\r\n#### Versions\r\nLinux-4.4.0-116-generic-x86_64-with-debian-stretch-sid\r\nPython 3.6.3 |Anaconda, Inc.| (default, Nov  3 2017, 19:19:16) \r\n[GCC 7.2.0]\r\nNumPy 1.13.1\r\nSciPy 0.19.1\r\nScikit-Learn 0.20.dev0\r\nPandas 0.21.0\r\n\n", "patch": "diff --git a/sklearn/utils/validation.py b/sklearn/utils/validation.py\n--- a/sklearn/utils/validation.py\n+++ b/sklearn/utils/validation.py\n@@ -466,6 +466,12 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n         # not a data type (e.g. a column named dtype in a pandas DataFrame)\n         dtype_orig = None\n \n+    # check if the object contains several dtypes (typically a pandas\n+    # DataFrame), and store them. If not, store None.\n+    dtypes_orig = None\n+    if hasattr(array, \"dtypes\") and hasattr(array, \"__array__\"):\n+        dtypes_orig = np.array(array.dtypes)\n+\n     if dtype_numeric:\n         if dtype_orig is not None and dtype_orig.kind == \"O\":\n             # if input is object, convert to float.\n@@ -581,6 +587,16 @@ def check_array(array, accept_sparse=False, accept_large_sparse=True,\n     if copy and np.may_share_memory(array, array_orig):\n         array = np.array(array, dtype=dtype, order=order)\n \n+    if (warn_on_dtype and dtypes_orig is not None and\n+            {array.dtype} != set(dtypes_orig)):\n+        # if there was at the beginning some other types than the final one\n+        # (for instance in a DataFrame that can contain several dtypes) then\n+        # some data must have been converted\n+        msg = (\"Data with input dtype %s were all converted to %s%s.\"\n+               % (', '.join(map(str, sorted(set(dtypes_orig)))), array.dtype,\n+                  context))\n+        warnings.warn(msg, DataConversionWarning, stacklevel=3)\n+\n     return array\n \n \n"}}
{"instance_id": "django__django-12125", "found_files": ["django/db/migrations/serializer.py"], "found_modules": ["django/db/migrations/serializer.py:DeconstructableSerializer", "django/db/migrations/serializer.py:TypeSerializer"], "found_entities": ["django/db/migrations/serializer.py:DeconstructableSerializer._serialize_path", "django/db/migrations/serializer.py:TypeSerializer.serialize"], "raw_output_loc": ["```\ndjango/db/migrations/serializer.py\nline: 92\nfunction: DeconstructableSerializer._serialize_path\n\n```", "```\ndjango/db/migrations/serializer.py\nline: 258\nclass: TypeSerializer\nfunction: TypeSerializer.serialize\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "89d41cba392b759732ba9f1db4ff29ed47da6a56", "problem_statement": "makemigrations produces incorrect path for inner classes\nDescription\n\t\nWhen you define a subclass from django.db.models.Field as an inner class of some other class, and use this field inside a django.db.models.Model class, then when you run manage.py makemigrations, a migrations file is created which refers to the inner class as if it were a top-level class of the module it is in.\nTo reproduce, create the following as your model:\nclass Outer(object):\n\tclass Inner(models.CharField):\n\t\tpass\nclass A(models.Model):\n\tfield = Outer.Inner(max_length=20)\nAfter running manage.py makemigrations, the generated migrations file contains the following:\nmigrations.CreateModel(\n\tname='A',\n\tfields=[\n\t\t('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n\t\t('field', test1.models.Inner(max_length=20)),\n\t],\n),\nNote the test1.models.Inner, which should have been test1.models.Outer.Inner.\nThe real life case involved an EnumField from django-enumfields, defined as an inner class of a Django Model class, similar to this:\nimport enum\nfrom enumfields import Enum, EnumField\nclass Thing(models.Model):\n\t@enum.unique\n\tclass State(Enum):\n\t\ton = 'on'\n\t\toff = 'off'\n\tstate = EnumField(enum=State)\nThis results in the following migrations code:\nmigrations.CreateModel(\n\tname='Thing',\n\tfields=[\n\t\t('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),\n\t\t('state', enumfields.fields.EnumField(enum=test1.models.State, max_length=10)),\n\t],\n),\nThis refers to test1.models.State, instead of to test1.models.Thing.State.\n", "patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -269,7 +269,7 @@ def serialize(self):\n             if module == builtins.__name__:\n                 return self.value.__name__, set()\n             else:\n-                return \"%s.%s\" % (module, self.value.__name__), {\"import %s\" % module}\n+                return \"%s.%s\" % (module, self.value.__qualname__), {\"import %s\" % module}\n \n \n class UUIDSerializer(BaseSerializer):\n"}}
{"instance_id": "sympy__sympy-16988", "found_files": ["sympy/sets/sets.py", "sympy/core/operations.py"], "found_modules": ["sympy/sets/sets.py:Intersection", "sympy/core/operations.py:LatticeOp", "sympy/sets/sets.py:simplify_intersection"], "found_entities": ["sympy/sets/sets.py:Intersection.__new__", "sympy/core/operations.py:LatticeOp._new_args_filter", "sympy/sets/sets.py:simplify_intersection"], "raw_output_loc": ["```\nsympy/sets/sets.py\nline: 1259\nclass: Intersection\nfunction: Intersection.__new__\n```", "```\nsympy/core/operations.py:LatticeOp._new_args_filter\nline: 430\nfunction: LatticeOp._new_args_filter\n\nsympy/sets/sets.py:Intersection.__new__\nline: 1259\nfunction: Intersection.__new__\n\nsympy/sets/sets.py:simplify_intersection\nline: 1971\nfunction: simplify_intersection\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "e727339af6dc22321b00f52d971cda39e4ce89fb", "problem_statement": "Intersection should remove duplicates\n```python\r\n>>> Intersection({1},{1},{x})\r\nEmptySet()\r\n>>> Intersection({1},{x})\r\n{1}\r\n```\r\nThe answer should be `Piecewise(({1}, Eq(x, 1)), (S.EmptySet, True))` or remain unevaluated.\r\n\r\nThe routine should give the same answer if duplicates are present; my initial guess is that duplicates should just be removed at the outset of instantiation. Ordering them will produce canonical processing.\n", "patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1260,7 +1260,7 @@ def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n \n         # flatten inputs to merge intersections and iterables\n-        args = _sympify(args)\n+        args = list(ordered(set(_sympify(args))))\n \n         # Reduce sets using known rules\n         if evaluate:\n"}}
{"instance_id": "django__django-12308", "found_files": ["django/contrib/admin/utils.py"], "found_modules": ["django/contrib/admin/utils.py:display_for_field"], "found_entities": ["django/contrib/admin/utils.py:display_for_field"], "raw_output_loc": ["```\ndjango/contrib/admin/utils.py\nline: 380\nfunction: display_for_field\n\n```", "```\ndjango/contrib/admin/utils.py\nline: 380\nfunction: display_for_field\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "2e0f04507b17362239ba49830d26fec504d46978", "problem_statement": "JSONField are not properly displayed in admin when they are readonly.\nDescription\n\t\nJSONField values are displayed as dict when readonly in the admin.\nFor example, {\"foo\": \"bar\"} would be displayed as {'foo': 'bar'}, which is not valid JSON.\nI believe the fix would be to add a special case in django.contrib.admin.utils.display_for_field to call the prepare_value of the JSONField (not calling json.dumps directly to take care of the InvalidJSONInput case).\n", "patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,11 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField) and value:\n+        try:\n+            return field.get_prep_value(value)\n+        except TypeError:\n+            return display_for_value(value, empty_value_display)\n     else:\n         return display_for_value(value, empty_value_display)\n \n"}}
{"instance_id": "django__django-15320", "found_files": ["django/db/models/expressions.py"], "found_modules": ["django/db/models/expressions.py:Subquery"], "found_entities": ["django/db/models/expressions.py:Subquery.as_sql"], "raw_output_loc": ["```\ndjango/db/models/expressions.py\nline: 1150\nclass: Subquery\nfunction: Subquery.__init__\n\nline: 1182\nclass: Subquery\nfunction: Subquery.as_sql\n```", "```\ndjango/db/models/expressions.py\nline: 1150\nclass: Subquery\nfunction: Subquery.__init__\n\nline: 1182\nclass: Subquery\nfunction: Subquery.as_sql\n```"], "meta_data": {"repo": "django/django", "base_commit": "b55ebe32417e0884b6b8b3e1bc0379033aa221af", "problem_statement": "Subquery.as_sql() generates invalid SQL.\nDescription\n\t \n\t\t(last modified by M1ha Shvn)\n\t \nSince \u200bthis commit Subquery.as_sql(...) method returns incorrect SQL removing first and last symbols instead of absent breakets. Adding Subquery().query.subquery = True attribute fixes the problem. From my point of view, it should be set in Subquery constructor.\nfrom django.db import connection\nfrom apps.models import App\nq = Subquery(App.objects.all())\nprint(str(q.query))\n# Output SQL is valid:\n# 'SELECT \"apps_app\".\"id\", \"apps_app\".\"name\" FROM \"apps_app\"'\nprint(q.as_sql(q.query.get_compiler('default'), connection))\n# Outptut SQL is invalid (no S letter at the beggining and \" symbol at the end):\n# ('(ELECT \"apps_app\".\"id\", \"apps_app\".\"name\" FROM \"apps_app)', ())\nq.query.subquery = True\nprint(q.as_sql(q.query.get_compiler('default'), connection))\n# Outputs correct result\n('(SELECT \"apps_app\".\"id\", \"apps_app\".\"name\" FROM \"apps_app\")', ())\n", "patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1149,7 +1149,8 @@ class Subquery(BaseExpression, Combinable):\n \n     def __init__(self, queryset, output_field=None, **extra):\n         # Allow the usage of both QuerySet and sql.Query objects.\n-        self.query = getattr(queryset, 'query', queryset)\n+        self.query = getattr(queryset, 'query', queryset).clone()\n+        self.query.subquery = True\n         self.extra = extra\n         super().__init__(output_field)\n \n"}}
{"instance_id": "django__django-14580", "found_files": ["django/db/migrations/writer.py"], "found_modules": ["django/db/migrations/writer.py:MigrationWriter"], "found_entities": ["django/db/migrations/writer.py:MigrationWriter.as_string"], "raw_output_loc": ["```\ndjango/db/migrations/writer.py\nline: 166\nclass: MigrationWriter\nfunction: MigrationWriter.as_string\n```", "```\ndjango/db/migrations/writer.py\nline: 167\nline: 168\nline: 169\nfunction: MigrationWriter.as_string\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "36fa071d6ebd18a61c4d7f1b5c9d17106134bd44", "problem_statement": "Missing import statement in generated migration (NameError: name 'models' is not defined)\nDescription\n\t\nI found a bug in Django's latest release: 3.2.4. \nGiven the following contents of models.py:\nfrom django.db import models\nclass MyField(models.TextField):\n\tpass\nclass MyBaseModel(models.Model):\n\tclass Meta:\n\t\tabstract = True\nclass MyMixin:\n\tpass\nclass MyModel(MyMixin, MyBaseModel):\n\tname = MyField(primary_key=True)\nThe makemigrations command will generate the following migration file:\n# Generated by Django 3.2.4 on 2021-06-30 19:13\nimport app.models\nfrom django.db import migrations\nclass Migration(migrations.Migration):\n\tinitial = True\n\tdependencies = [\n\t]\n\toperations = [\n\t\tmigrations.CreateModel(\n\t\t\tname='MyModel',\n\t\t\tfields=[\n\t\t\t\t('name', app.models.MyField(primary_key=True, serialize=False)),\n\t\t\t],\n\t\t\toptions={\n\t\t\t\t'abstract': False,\n\t\t\t},\n\t\t\tbases=(app.models.MyMixin, models.Model),\n\t\t),\n\t]\nWhich will then fail with the following error:\n File \"/home/jj/django_example/app/migrations/0001_initial.py\", line 7, in <module>\n\tclass Migration(migrations.Migration):\n File \"/home/jj/django_example/app/migrations/0001_initial.py\", line 23, in Migration\n\tbases=(app.models.MyMixin, models.Model),\nNameError: name 'models' is not defined\nExpected behavior: Django generates a migration file that is valid Python.\nActual behavior: Django generates a migration file that is missing an import statement.\nI think this is a bug of the module django.db.migrations.writer, but I'm not sure. I will be happy to assist with debugging.\nThanks for your attention,\nJaap Joris\n", "patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -273,7 +273,7 @@ def _format(self):\n class TypeSerializer(BaseSerializer):\n     def serialize(self):\n         special_cases = [\n-            (models.Model, \"models.Model\", []),\n+            (models.Model, \"models.Model\", ['from django.db import models']),\n             (type(None), 'type(None)', []),\n         ]\n         for case, string, imports in special_cases:\n"}}
{"instance_id": "django__django-11039", "found_files": ["django/core/management/commands/sqlmigrate.py", "django/db/backends/base/features.py", "django/db/migrations/executor.py"], "found_modules": ["django/core/management/commands/sqlmigrate.py:Command", "django/db/migrations/executor.py:MigrationExecutor"], "found_entities": ["django/core/management/commands/sqlmigrate.py:Command.handle", "django/db/migrations/executor.py:MigrationExecutor.collect_sql"], "raw_output_loc": ["```\ndjango/core/management/commands/sqlmigrate.py\nline: 59\nfunction: Command.handle\n\n```", "```\ndjango/core/management/commands/sqlmigrate.py\nline: 59\nclass: Command\nfunction: Command.handle\n\ndjango/db/backends/base/features.py\nline: 167\nclass: BaseDatabaseFeatures\nfunction: BaseDatabaseFeatures.can_rollback_ddl\n\ndjango/db/migrations/executor.py\nline: 221\nclass: MigrationExecutor\nfunction: MigrationExecutor.collect_sql\n\ntests/migrations/test_commands.py\nfunction: TestSqlMigrate.test_non_atomic_migrations\n```"], "meta_data": {"repo": "django/django", "base_commit": "d5276398046ce4a102776a1e67dcac2884d80dfe", "problem_statement": "sqlmigrate wraps it's outpout in BEGIN/COMMIT even if the database doesn't support transactional DDL\nDescription\n\t \n\t\t(last modified by Simon Charette)\n\t \nThe migration executor only adds the outer BEGIN/COMMIT \u200bif the migration is atomic and \u200bthe schema editor can rollback DDL but the current sqlmigrate logic only takes migration.atomic into consideration.\nThe issue can be addressed by\nChanging sqlmigrate \u200bassignment of self.output_transaction to consider connection.features.can_rollback_ddl as well.\nAdding a test in tests/migrations/test_commands.py based on \u200ban existing test for non-atomic migrations that mocks connection.features.can_rollback_ddl to False instead of overdidding MIGRATION_MODULES to point to a non-atomic migration.\nI marked the ticket as easy picking because I included the above guidelines but feel free to uncheck it if you deem it inappropriate.\n", "patch": "diff --git a/django/core/management/commands/sqlmigrate.py b/django/core/management/commands/sqlmigrate.py\n--- a/django/core/management/commands/sqlmigrate.py\n+++ b/django/core/management/commands/sqlmigrate.py\n@@ -55,8 +55,9 @@ def handle(self, *args, **options):\n                 migration_name, app_label))\n         targets = [(app_label, migration.name)]\n \n-        # Show begin/end around output only for atomic migrations\n-        self.output_transaction = migration.atomic\n+        # Show begin/end around output for atomic migrations, if the database\n+        # supports transactional DDL.\n+        self.output_transaction = migration.atomic and connection.features.can_rollback_ddl\n \n         # Make a plan that represents just the requested migrations and show SQL\n         # for it\n"}}
{"instance_id": "pydata__xarray-3364", "found_files": ["xarray/core/concat.py"], "found_modules": ["xarray/core/concat.py:concat", "xarray/core/concat.py:_calc_concat_over", "xarray/core/concat.py:_dataset_concat", "xarray/core/concat.py:_dataarray_concat"], "found_entities": ["xarray/core/concat.py:concat", "xarray/core/concat.py:_calc_concat_over", "xarray/core/concat.py:_dataset_concat", "xarray/core/concat.py:_dataarray_concat"], "raw_output_loc": ["```\nxarray/core/concat.py\nline: 158\nfunction: _calc_concat_over\n\nxarray/core/concat.py\nline: 263\nfunction: _dataset_concat\n\nxarray/core/concat.py\nline: 10\nfunction: concat\n```", "```\nxarray/core/concat.py\nline: 10\nfunction: concat\n\nxarray/core/concat.py\nline: 263\nfunction: _dataset_concat\n\nxarray/core/concat.py\nline: 388\nfunction: _dataarray_concat\n```"], "meta_data": {"repo": "pydata/xarray", "base_commit": "863e49066ca4d61c9adfe62aca3bf21b90e1af8c", "problem_statement": "Ignore missing variables when concatenating datasets?\nSeveral users (@raj-kesavan, @richardotis, now myself) have wondered about how to concatenate xray Datasets with different variables.\n\nWith the current `xray.concat`, you need to awkwardly create dummy variables filled with `NaN` in datasets that don't have them (or drop mismatched variables entirely). Neither of these are great options -- `concat` should have an option (the default?) to take care of this for the user.\n\nThis would also be more consistent with `pd.concat`, which takes a more relaxed approach to matching dataframes with different variables (it does an outer join).\n\n", "patch": "diff --git a/xarray/core/concat.py b/xarray/core/concat.py\n--- a/xarray/core/concat.py\n+++ b/xarray/core/concat.py\n@@ -312,15 +312,9 @@ def _dataset_concat(\n         to_merge = {var: [] for var in variables_to_merge}\n \n         for ds in datasets:\n-            absent_merge_vars = variables_to_merge - set(ds.variables)\n-            if absent_merge_vars:\n-                raise ValueError(\n-                    \"variables %r are present in some datasets but not others. \"\n-                    % absent_merge_vars\n-                )\n-\n             for var in variables_to_merge:\n-                to_merge[var].append(ds.variables[var])\n+                if var in ds:\n+                    to_merge[var].append(ds.variables[var])\n \n         for var in variables_to_merge:\n             result_vars[var] = unique_variable(\n"}}
{"instance_id": "django__django-13964", "found_files": ["django/db/models/fields/related.py", "django/db/models/base.py"], "found_modules": ["django/db/models/fields/related.py:ForeignKey", "django/db/models/base.py:Model"], "found_entities": ["django/db/models/fields/related.py:ForeignKey.get_db_prep_save", "django/db/models/base.py:Model._prepare_related_fields_for_save", "django/db/models/base.py:Model.save"], "raw_output_loc": ["```\ndjango/db/models/fields/related.py:ForeignKey\nline: 965\nfunction: ForeignKey.get_db_prep_save\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/db/models/fields/related.py:ForeignKey.get_db_prep_save\nline: 965\nline: 966\nline: 967\nline: 968\nline: 969\nline: 970\nline: 971\nfunction: ForeignKey.get_db_prep_save\n\ndjango/db/models/base.py:Model.save\nline: 672\nline: 682\nfunction: Model.save\n\ndjango/db/models/base.py:Model._prepare_related_fields_for_save\nline: 911\nline: 936\nline: 937\nline: 938\nline: 939\nfunction: Model._prepare_related_fields_for_save\n```"], "meta_data": {"repo": "django/django", "base_commit": "f39634ff229887bf7790c069d0c411b38494ca38", "problem_statement": "Saving parent object after setting on child leads to data loss for parents with non-numeric primary key.\nDescription\n\t \n\t\t(last modified by Charlie DeTar)\n\t \nGiven a model with a foreign key relation to another model that has a non-auto CharField as its primary key:\nclass Product(models.Model):\n\tsku = models.CharField(primary_key=True, max_length=50)\nclass Order(models.Model):\n\tproduct = models.ForeignKey(Product, on_delete=models.CASCADE)\nIf the relation is initialized on the parent with an empty instance that does not yet specify its primary key, and the primary key is subsequently defined, the parent does not \"see\" the primary key's change:\nwith transaction.atomic():\n\torder = Order()\n\torder.product = Product()\n\torder.product.sku = \"foo\"\n\torder.product.save()\n\torder.save()\n\tassert Order.objects.filter(product_id=\"\").exists() # Succeeds, but shouldn't\n\tassert Order.objects.filter(product=order.product).exists() # Fails\nInstead of product_id being populated with product.sku, it is set to emptystring. The foreign key constraint which would enforce the existence of a product with sku=\"\" is deferred until the transaction commits. The transaction does correctly fail on commit with a ForeignKeyViolation due to the non-existence of a product with emptystring as its primary key.\nOn the other hand, if the related unsaved instance is initialized with its primary key before assignment to the parent, it is persisted correctly:\nwith transaction.atomic():\n\torder = Order()\n\torder.product = Product(sku=\"foo\")\n\torder.product.save()\n\torder.save()\n\tassert Order.objects.filter(product=order.product).exists() # succeeds\nCommitting the transaction also succeeds.\nThis may have something to do with how the Order.product_id field is handled at assignment, together with something about handling fetching of auto vs non-auto primary keys from the related instance.\n", "patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -933,7 +933,7 @@ def _prepare_related_fields_for_save(self, operation_name):\n                         \"%s() prohibited to prevent data loss due to unsaved \"\n                         \"related object '%s'.\" % (operation_name, field.name)\n                     )\n-                elif getattr(self, field.attname) is None:\n+                elif getattr(self, field.attname) in field.empty_values:\n                     # Use pk from related object if it has been saved after\n                     # an assignment.\n                     setattr(self, field.attname, obj.pk)\n"}}
{"instance_id": "django__django-16229", "found_files": ["django/contrib/postgres/forms/array.py", "django/contrib/admin/options.py"], "found_modules": ["django/contrib/postgres/forms/array.py:SimpleArrayField", "django/contrib/admin/options.py:InlineModelAdmin"], "found_entities": ["django/contrib/postgres/forms/array.py:SimpleArrayField.has_changed", "django/contrib/admin/options.py:InlineModelAdmin.get_formset"], "raw_output_loc": ["```\ndjango/contrib/postgres/forms/array.py:SimpleArrayField\nfunction: SimpleArrayField.has_changed\n\nmy_app/admin.py\nclass: RelatedModelInline\nfunction: RelatedModelInline.get_formset\n\nmy_app/forms.py\nclass: RelatedModelForm\nfunction: RelatedModelForm.clean\n\nmy_app/models.py\nclass: RelatedModel\nfunction: RelatedModel.plop\n\nmy_app/admin.py\nclass: ThingAdmin\nfunction: ThingAdmin.get_inline_instances\n```", "```\ndjango/contrib/admin/options.py:InlineModelAdmin\nclass: InlineModelAdmin\nfunction: InlineModelAdmin.get_formset\n\ncore/forms/fields.py\nfunction: Field.show_hidden_initial\n\ncore/forms/widgets.py\nfunction: HiddenInput._format_value\n\ncore/forms/forms.py\nfunction: BaseForm._clean_fields\n\ncore/forms/models.py\nfunction: BaseModelForm._post_clean\n```"], "meta_data": {"repo": "django/django", "base_commit": "04b15022e8d1f49af69d8a1e6cd678f31f1280ff", "problem_statement": "ModelForm fields with callable defaults don't correctly propagate default values\nDescription\n\t\nWhen creating an object via the admin, if an inline contains an ArrayField in error, the validation will be bypassed (and the inline dismissed) if we submit the form a second time (without modification).\ngo to /admin/my_app/thing/add/\ntype anything in plop\nsubmit -> it shows an error on the inline\nsubmit again -> no errors, plop become unfilled\n# models.py\nclass Thing(models.Model):\n\tpass\nclass RelatedModel(models.Model):\n\tthing = models.ForeignKey(Thing, on_delete=models.CASCADE)\n\tplop = ArrayField(\n\t\tmodels.CharField(max_length=42),\n\t\tdefault=list,\n\t)\n# admin.py\nclass RelatedModelForm(forms.ModelForm):\n\tdef clean(self):\n\t\traise ValidationError(\"whatever\")\nclass RelatedModelInline(admin.TabularInline):\n\tform = RelatedModelForm\n\tmodel = RelatedModel\n\textra = 1\n@admin.register(Thing)\nclass ThingAdmin(admin.ModelAdmin):\n\tinlines = [\n\t\tRelatedModelInline\n\t]\nIt seems related to the hidden input containing the initial value:\n<input type=\"hidden\" name=\"initial-relatedmodel_set-0-plop\" value=\"test\" id=\"initial-relatedmodel_set-0-id_relatedmodel_set-0-plop\">\nI can fix the issue locally by forcing show_hidden_initial=False on the field (in the form init)\n", "patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -96,9 +96,17 @@ def as_widget(self, widget=None, attrs=None, only_initial=False):\n             attrs.setdefault(\n                 \"id\", self.html_initial_id if only_initial else self.auto_id\n             )\n+        if only_initial and self.html_initial_name in self.form.data:\n+            # Propagate the hidden initial value.\n+            value = self.form._widget_data_value(\n+                self.field.hidden_widget(),\n+                self.html_initial_name,\n+            )\n+        else:\n+            value = self.value()\n         return widget.render(\n             name=self.html_initial_name if only_initial else self.html_name,\n-            value=self.value(),\n+            value=value,\n             attrs=attrs,\n             renderer=self.form.renderer,\n         )\n"}}
{"instance_id": "scikit-learn__scikit-learn-13497", "found_files": ["sklearn/feature_selection/mutual_info_.py"], "found_modules": ["sklearn/feature_selection/mutual_info_.py:_estimate_mi", "sklearn/feature_selection/mutual_info_.py:mutual_info_regression", "sklearn/feature_selection/mutual_info_.py:mutual_info_classif"], "found_entities": ["sklearn/feature_selection/mutual_info_.py:_estimate_mi", "sklearn/feature_selection/mutual_info_.py:mutual_info_regression", "sklearn/feature_selection/mutual_info_.py:mutual_info_classif"], "raw_output_loc": ["```\nsklearn/feature_selection/mutual_info_.py\nline: 250\nfunction: _estimate_mi\n\nsklearn/feature_selection/mutual_info_.py\nline: 368\nfunction: mutual_info_regression\n\nsklearn/feature_selection/mutual_info_.py\nline: 448\nfunction: mutual_info_classif\n```", "```\nsklearn/feature_selection/mutual_info_.py\nline: 250\nfunction: _estimate_mi\n\nsklearn/feature_selection/mutual_info_.py\nline: 368\nfunction: mutual_info_regression\n\nsklearn/feature_selection/mutual_info_.py\nline: 448\nfunction: mutual_info_classif\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "26f690961a52946dd2f53bf0fdd4264b2ae5be90", "problem_statement": "Comparing string to array in _estimate_mi\nIn ``_estimate_mi`` there is ``discrete_features == 'auto'`` but discrete features can be an array of indices or a boolean mask.\r\nThis will error in future versions of numpy.\r\nAlso this means we never test this function with discrete features != 'auto', it seems?\n", "patch": "diff --git a/sklearn/feature_selection/mutual_info_.py b/sklearn/feature_selection/mutual_info_.py\n--- a/sklearn/feature_selection/mutual_info_.py\n+++ b/sklearn/feature_selection/mutual_info_.py\n@@ -10,7 +10,7 @@\n from ..preprocessing import scale\n from ..utils import check_random_state\n from ..utils.fixes import _astype_copy_false\n-from ..utils.validation import check_X_y\n+from ..utils.validation import check_array, check_X_y\n from ..utils.multiclass import check_classification_targets\n \n \n@@ -247,14 +247,16 @@ def _estimate_mi(X, y, discrete_features='auto', discrete_target=False,\n     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n     n_samples, n_features = X.shape\n \n-    if discrete_features == 'auto':\n-        discrete_features = issparse(X)\n-\n-    if isinstance(discrete_features, bool):\n+    if isinstance(discrete_features, (str, bool)):\n+        if isinstance(discrete_features, str):\n+            if discrete_features == 'auto':\n+                discrete_features = issparse(X)\n+            else:\n+                raise ValueError(\"Invalid string value for discrete_features.\")\n         discrete_mask = np.empty(n_features, dtype=bool)\n         discrete_mask.fill(discrete_features)\n     else:\n-        discrete_features = np.asarray(discrete_features)\n+        discrete_features = check_array(discrete_features, ensure_2d=False)\n         if discrete_features.dtype != 'bool':\n             discrete_mask = np.zeros(n_features, dtype=bool)\n             discrete_mask[discrete_features] = True\n"}}
{"instance_id": "sympy__sympy-11897", "found_files": ["sympy/printing/latex.py", "sympy/printing/pretty/pretty.py", "sympy/printing/printer.py"], "found_modules": ["sympy/printing/latex.py:LatexPrinter", "sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/printing/printer.py:Printer"], "found_entities": ["sympy/printing/latex.py:LatexPrinter._print_Mul", "sympy/printing/latex.py:LatexPrinter._print_Pow", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Mul", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Pow", "sympy/printing/printer.py:Printer._print"], "raw_output_loc": ["```\nsympy/printing/latex.py:LatexPrinter._print_Mul\nline: 348\nfunction: LatexPrinter._print_Mul\n\nsympy/printing/latex.py:LatexPrinter._print_Pow\nline: 440\nfunction: LatexPrinter._print_Pow\n\nsympy/printing/pretty/pretty.py:PrettyPrinter._print_Mul\nline: 1393\nfunction: PrettyPrinter._print_Mul\n\nsympy/printing/pretty/pretty.py:PrettyPrinter._print_Pow\nline: 1491\nfunction: PrettyPrinter._print_Pow\n```", "```\nsympy/printing/latex.py:LatexPrinter._print_Mul\nline: 348\nfunction: LatexPrinter._print_Mul\n\nsympy/printing/latex.py:LatexPrinter._print_Pow\nline: 440\nfunction: LatexPrinter._print_Pow\n\nsympy/printing/pretty/pretty.py:PrettyPrinter._print_Mul\nline: 1393\nfunction: PrettyPrinter._print_Mul\n\nsympy/printing/pretty/pretty.py:PrettyPrinter._print_Pow\nline: 1491\nfunction: PrettyPrinter._print_Pow\n\nsympy/printing/printer.py:Printer._print\nline: 235\nfunction: Printer._print\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "e2918c1205c47345eb73c9be68b14c0f15fdeb17", "problem_statement": "LaTeX printer inconsistent with pretty printer\nThe LaTeX printer should always give the same output as the pretty printer, unless better output is possible from LaTeX. In some cases it is inconsistent. For instance:\n\n``` py\nIn [9]: var('x', positive=True)\nOut[9]: x\n\nIn [10]: latex(exp(-x)*log(x))\nOut[10]: '\\\\frac{1}{e^{x}} \\\\log{\\\\left (x \\\\right )}'\n\nIn [11]: pprint(exp(-x)*log(x))\n -x\n\u212f  \u22c5log(x)\n```\n\n(I also don't think the assumptions should affect printing). \n\n``` py\nIn [14]: var('x y')\nOut[14]: (x, y)\n\nIn [15]: latex(1/(x + y)/2)\nOut[15]: '\\\\frac{1}{2 x + 2 y}'\n\nIn [16]: pprint(1/(x + y)/2)\n    1\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n2\u22c5(x + y)\n```\n\n", "patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -235,10 +235,12 @@ def _needs_mul_brackets(self, expr, first=False, last=False):\n         elif expr.is_Mul:\n             if not first and _coeff_isneg(expr):\n                 return True\n+        if expr.is_Piecewise:\n+            return True\n         if any([expr.has(x) for x in (Mod,)]):\n             return True\n         if (not last and\n-            any([expr.has(x) for x in (Integral, Piecewise, Product, Sum)])):\n+            any([expr.has(x) for x in (Integral, Product, Sum)])):\n             return True\n \n         return False\n"}}
{"instance_id": "pydata__xarray-4094", "found_files": ["xarray/core/dataset.py", "xarray/core/dataarray.py", "xarray/core/common.py"], "found_modules": ["xarray/core/dataset.py:Dataset.to_stacked_array", "xarray/core/dataset.py:Dataset", "xarray/core/dataarray.py:DataArray", "xarray/core/common.py:DataWithCoords"], "found_entities": ["xarray/core/dataset.py:Dataset.to_stacked_array.ensure_stackable", "xarray/core/dataarray.py:DataArray.to_unstacked_dataset", "xarray/core/dataset.py:Dataset.to_stacked_array", "xarray/core/common.py:DataWithCoords.squeeze", "xarray/core/dataarray.py:DataArray.sel", "xarray/core/dataset.py:Dataset.isel"], "raw_output_loc": ["```\nxarray/core/dataset.py:Dataset.to_stacked_array\nline: 3454\nfunction: Dataset.to_stacked_array.ensure_stackable\n\nxarray/core/dataarray.py:DataArray.to_unstacked_dataset\nline: 1964\nfunction: DataArray.to_unstacked_dataset\n\nxarray/core/common.py:DataWithCoords.squeeze\nline: 343\nfunction: DataWithCoords.squeeze\n\nxarray/core/dataarray.py:DataArray.sel\nline: 1068\nfunction: DataArray.sel\n\nxarray/core/dataset.py:Dataset\nline: 1966\nfunction: Dataset\n```", "```\nxarray/core/dataset.py:Dataset.to_stacked_array\nline: 3454\nfunction: Dataset.to_stacked_array.ensure_stackable\n\nxarray/core/dataarray.py:DataArray.to_unstacked_dataset\nline: 1953\nfunction: DataArray.to_unstacked_dataset\n\nxarray/core/dataset.py:Dataset.to_stacked_array\nline: 3472\nfunction: Dataset.to_stacked_array\n\nxarray/core/dataarray.py:DataArray.to_unstacked_dataset\nline: 1961\nfunction: DataArray.to_unstacked_dataset\n\nxarray/core/dataset.py:Dataset.to_stacked_array\nline: 3482\nfunction: Dataset.to_stacked_array\n```"], "meta_data": {"repo": "pydata/xarray", "base_commit": "a64cf2d5476e7bbda099b34c40b7be1880dbd39a", "problem_statement": "to_unstacked_dataset broken for single-dim variables\n<!-- A short summary of the issue, if appropriate -->\r\n\r\n\r\n#### MCVE Code Sample\r\n\r\n```python\r\narr = xr.DataArray(\r\n     np.arange(3),\r\n     coords=[(\"x\", [0, 1, 2])],\r\n )\r\ndata = xr.Dataset({\"a\": arr, \"b\": arr})\r\nstacked = data.to_stacked_array('y', sample_dims=['x'])\r\nunstacked = stacked.to_unstacked_dataset('y')\r\n# MergeError: conflicting values for variable 'y' on objects to be combined. You can skip this check by specifying compat='override'.\r\n```\r\n\r\n#### Expected Output\r\nA working roundtrip.\r\n\r\n#### Problem Description\r\nI need to stack a bunch of variables and later unstack them again, however this doesn't work if the variables only have a single dimension.\r\n\r\n#### Versions\r\n\r\n<details><summary>Output of <tt>xr.show_versions()</tt></summary>\r\n\r\nINSTALLED VERSIONS\r\n------------------\r\ncommit: None\r\npython: 3.7.3 (default, Mar 27 2019, 22:11:17) \r\n[GCC 7.3.0]\r\npython-bits: 64\r\nOS: Linux\r\nOS-release: 4.15.0-96-generic\r\nmachine: x86_64\r\nprocessor: x86_64\r\nbyteorder: little\r\nLC_ALL: None\r\nLANG: en_GB.UTF-8\r\nLOCALE: en_GB.UTF-8\r\nlibhdf5: 1.10.4\r\nlibnetcdf: 4.6.2\r\n\r\nxarray: 0.15.1\r\npandas: 1.0.3\r\nnumpy: 1.17.3\r\nscipy: 1.3.1\r\nnetCDF4: 1.4.2\r\npydap: None\r\nh5netcdf: None\r\nh5py: 2.10.0\r\nNio: None\r\nzarr: None\r\ncftime: 1.0.4.2\r\nnc_time_axis: None\r\nPseudoNetCDF: None\r\nrasterio: None\r\ncfgrib: None\r\niris: None\r\nbottleneck: None\r\ndask: 2.10.1\r\ndistributed: 2.10.0\r\nmatplotlib: 3.1.1\r\ncartopy: None\r\nseaborn: 0.10.0\r\nnumbagg: None\r\nsetuptools: 41.0.0\r\npip: 19.0.3\r\nconda: 4.8.3\r\npytest: 5.3.5\r\nIPython: 7.9.0\r\nsphinx: None\r\n\r\n\r\n</details>\r\n\n", "patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1961,7 +1961,7 @@ def to_unstacked_dataset(self, dim, level=0):\n         # pull variables out of datarray\n         data_dict = {}\n         for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+            data_dict[k] = self.sel({variable_dim: k}, drop=True).squeeze(drop=True)\n \n         # unstacked dataset\n         return Dataset(data_dict)\n"}}
{"instance_id": "django__django-13447", "found_files": ["django/contrib/admin/sites.py"], "found_modules": ["django/contrib/admin/sites.py:AdminSite"], "found_entities": ["django/contrib/admin/sites.py:AdminSite._build_app_dict", "django/contrib/admin/sites.py:AdminSite.get_app_list", "django/contrib/admin/sites.py:AdminSite.index", "django/contrib/admin/sites.py:AdminSite.app_index"], "raw_output_loc": ["```\ndjango/contrib/admin/sites.py\nline: 433\nclass: AdminSite\nfunction: AdminSite._build_app_dict\n\ndjango/contrib/admin/sites.py\nline: 501\nclass: AdminSite\nfunction: AdminSite.get_app_list\n\ndjango/contrib/admin/sites.py\nline: 517\nclass: AdminSite\nfunction: AdminSite.index\n\ndjango/contrib/admin/sites.py\nline: 536\nclass: AdminSite\nfunction: AdminSite.app_index\n```", "```\ndjango/contrib/admin/sites.py\nline: 433\nclass: AdminSite\nfunction: AdminSite._build_app_dict\n\ndjango/contrib/admin/sites.py\nline: 501\nclass: AdminSite\nfunction: AdminSite.get_app_list\n\ndjango/contrib/admin/sites.py\nline: 536\nclass: AdminSite\nfunction: AdminSite.app_index\n\ndjango/contrib/admin/sites.py\nline: 517\nclass: AdminSite\nfunction: AdminSite.index\n```"], "meta_data": {"repo": "django/django", "base_commit": "0456d3e42795481a186db05719300691fe2a1029", "problem_statement": "Added model class to app_list context\nDescription\n\t \n\t\t(last modified by Raffaele Salmaso)\n\t \nI need to manipulate the app_list in my custom admin view, and the easiest way to get the result is to have access to the model class (currently the dictionary is a serialized model).\nIn addition I would make the _build_app_dict method public, as it is used by the two views index and app_index.\n", "patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -461,6 +461,7 @@ def _build_app_dict(self, request, label=None):\n \n             info = (app_label, model._meta.model_name)\n             model_dict = {\n+                'model': model,\n                 'name': capfirst(model._meta.verbose_name_plural),\n                 'object_name': model._meta.object_name,\n                 'perms': perms,\n"}}
{"instance_id": "sympy__sympy-24213", "found_files": ["sympy/physics/units/unitsystem.py", "sympy/physics/units/dimensions.py"], "found_modules": ["sympy/physics/units/unitsystem.py:UnitSystem", "sympy/physics/units/dimensions.py:DimensionSystem", "sympy/physics/units/dimensions.py:Dimension"], "found_entities": ["sympy/physics/units/unitsystem.py:UnitSystem._collect_factor_and_dimension", "sympy/physics/units/dimensions.py:DimensionSystem._get_dimensional_dependencies_for_name", "sympy/physics/units/dimensions.py:DimensionSystem.get_dimensional_dependencies", "sympy/physics/units/dimensions.py:Dimension.__add__"], "raw_output_loc": ["```\nsympy/physics/units/unitsystem.py\nline: 173\nline: 178\nfunction: UnitSystem._collect_factor_and_dimension\n\nsympy/physics/units/dimensions.py\nline: 365\nline: 368\nfunction: DimensionSystem._get_dimensional_dependencies_for_name\n\nsympy/physics/units/dimensions.py\nline: 422\nfunction: DimensionSystem.get_dimensional_dependencies\n\nsympy/physics/units/dimensions.py\nline: 194\nfunction: Dimension.__eq__\n```", "```\nsympy/physics/units/unitsystem.py\nline: 178\nclass: UnitSystem\nfunction: UnitSystem._collect_factor_and_dimension\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "e8c22f6eac7314be8d92590bfff92ced79ee03e2", "problem_statement": "collect_factor_and_dimension does not detect equivalent dimensions in addition\nCode to reproduce:\r\n```python\r\nfrom sympy.physics import units\r\nfrom sympy.physics.units.systems.si import SI\r\n\r\nv1 = units.Quantity('v1')\r\nSI.set_quantity_dimension(v1, units.velocity)\r\nSI.set_quantity_scale_factor(v1, 2 * units.meter / units.second)\r\n\r\na1 = units.Quantity('a1')\r\nSI.set_quantity_dimension(a1, units.acceleration)\r\nSI.set_quantity_scale_factor(a1, -9.8 * units.meter / units.second**2)\r\n\r\nt1 = units.Quantity('t1')\r\nSI.set_quantity_dimension(t1, units.time)\r\nSI.set_quantity_scale_factor(t1, 5 * units.second)\r\n\r\nexpr1 = a1*t1 + v1\r\nSI._collect_factor_and_dimension(expr1)\r\n```\r\nResults in:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Python\\Python310\\lib\\site-packages\\sympy\\physics\\units\\unitsystem.py\", line 179, in _collect_factor_and_dimension\r\n    raise ValueError(\r\nValueError: Dimension of \"v1\" is Dimension(velocity), but it should be Dimension(acceleration*time)\r\n```\n", "patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n"}}
{"instance_id": "django__django-16139", "found_files": ["django/contrib/auth/forms.py", "django/contrib/auth/admin.py"], "found_modules": ["django/contrib/auth/forms.py:UserChangeForm", "django/contrib/auth/admin.py:UserAdmin"], "found_entities": ["django/contrib/auth/admin.py:UserAdmin.get_urls"], "raw_output_loc": ["```\ndjango/contrib/auth/forms.py\nline: 162\nclass: UserChangeForm\nfunction: UserChangeForm.__init__\n\ndjango/contrib/auth/admin.py\nline: 100\nclass: UserAdmin\nfunction: UserAdmin.get_urls\n```", "```\ndjango/contrib/auth/forms.py\nline: 162\nline: 166\nclass: UserChangeForm\nfunction: UserChangeForm.__init__\n```"], "meta_data": {"repo": "django/django", "base_commit": "d559cb02da30f74debbb1fc3a46de0df134d2d80", "problem_statement": "Accessing UserAdmin via to_field leads to link to PasswordResetForm being broken (404)\nDescription\n\t \n\t\t(last modified by Simon Kern)\n\t \nAccessing the UserAdmin via another model's Admin that has a reference to User (with to_field set, e.g., to_field=\"uuid\") leads to the UserAdmin being accessed via an url that looks similar to this one:\n.../user/22222222-3333-4444-5555-666677778888/change/?_to_field=uuid\nHowever the underlying form looks like this: \nCode highlighting:\nclass UserChangeForm(forms.ModelForm):\n\tpassword = ReadOnlyPasswordHashField(\n\t\tlabel=_(\"Password\"),\n\t\thelp_text=_(\n\t\t\t\"Raw passwords are not stored, so there is no way to see this \"\n\t\t\t\"user\u2019s password, but you can change the password using \"\n\t\t\t'<a href=\"{}\">this form</a>.'\n\t\t),\n\t)\n\t...\n\t...\n\tdef __init__(self, *args, **kwargs):\n\t\tsuper().__init__(*args, **kwargs)\n\t\tpassword = self.fields.get(\"password\")\n\t\tif password:\n\t\t\tpassword.help_text = password.help_text.format(\"../password/\")\n\t...\n\t...\nThis results in the link to the PasswordResetForm being wrong and thus ending up in a 404. If we drop the assumption that UserAdmin is always accessed via its pk, then we're good to go. It's as simple as replacing password.help_text = password.help_text.format(\"../password/\") with password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\nI've opened a pull request on GitHub for this Ticket, please see:\n\u200bPR\n", "patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,9 @@ def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(\n+                f\"../../{self.instance.pk}/password/\"\n+            )\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n"}}
{"instance_id": "sympy__sympy-24066", "found_files": ["sympy/physics/units/unitsystem.py", "sympy/physics/units/dimensions.py", "sympy/core/function.py"], "found_modules": ["sympy/physics/units/unitsystem.py:UnitSystem", "sympy/physics/units/dimensions.py:DimensionSystem", "sympy/core/function.py:Application"], "found_entities": ["sympy/physics/units/unitsystem.py:UnitSystem._collect_factor_and_dimension", "sympy/physics/units/dimensions.py:DimensionSystem.is_dimensionless", "sympy/core/function.py:Application.func"], "raw_output_loc": ["```\nsympy/physics/units/unitsystem.py:UnitSystem._collect_factor_and_dimension\nline: 192\nline: 193\nline: 194\nline: 195\nline: 196\nfunction: UnitSystem._collect_factor_and_dimension\n\nsympy/physics/units/dimensions.py:DimensionSystem.is_dimensionless\nline: 447\nline: 448\nline: 449\nline: 450\nline: 451\nline: 452\nline: 453\nline: 454\nline: 455\nfunction: DimensionSystem.is_dimensionless\n\nsympy/core/function.py:Application.func\nline: 373\nline: 374\nfunction: Application.func\n```", "```\nsympy/physics/units/unitsystem.py\nline: 192\nline: 193\nline: 194\nline: 195\nline: 196\nclass: UnitSystem\nfunction: UnitSystem._collect_factor_and_dimension\n\nsympy/physics/units/dimensions.py\nline: 453\nline: 454\nline: 455\nclass: DimensionSystem\nfunction: DimensionSystem.is_dimensionless\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "514579c655bf22e2af14f0743376ae1d7befe345", "problem_statement": "SI._collect_factor_and_dimension() cannot properly detect that exponent is dimensionless\nHow to reproduce:\r\n\r\n```python\r\nfrom sympy import exp\r\nfrom sympy.physics import units\r\nfrom sympy.physics.units.systems.si import SI\r\n\r\nexpr = units.second / (units.ohm * units.farad)\r\ndim = SI._collect_factor_and_dimension(expr)[1]\r\n\r\nassert SI.get_dimension_system().is_dimensionless(dim)\r\n\r\nbuggy_expr = 100 + exp(expr)\r\nSI._collect_factor_and_dimension(buggy_expr)\r\n\r\n# results in ValueError: Dimension of \"exp(second/(farad*ohm))\" is Dimension(time/(capacitance*impedance)), but it should be Dimension(1)\r\n```\n", "patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -190,10 +190,9 @@ def _collect_factor_and_dimension(self, expr):\n                 dim /= idim**count\n             return factor, dim\n         elif isinstance(expr, Function):\n-            fds = [self._collect_factor_and_dimension(\n-                arg) for arg in expr.args]\n-            return (expr.func(*(f[0] for f in fds)),\n-                    *(d[1] for d in fds))\n+            fds = [self._collect_factor_and_dimension(arg) for arg in expr.args]\n+            dims = [Dimension(1) if self.get_dimension_system().is_dimensionless(d[1]) else d[1] for d in fds]\n+            return (expr.func(*(f[0] for f in fds)), *dims)\n         elif isinstance(expr, Dimension):\n             return S.One, expr\n         else:\n"}}
{"instance_id": "pylint-dev__pylint-7080", "found_files": ["pylint/lint/pylinter.py", "pylint/config/option_manager_mixin.py", "pylint/lint/expand_modules.py"], "found_modules": ["pylint/lint/pylinter.py:PyLinter", "pylint/config/option_manager_mixin.py:OptionsManagerMixIn", "pylint/lint/expand_modules.py:_is_ignored_file"], "found_entities": ["pylint/lint/pylinter.py:PyLinter.open", "pylint/config/option_manager_mixin.py:OptionsManagerMixIn._parse_toml", "pylint/lint/expand_modules.py:_is_ignored_file", "pylint/lint/pylinter.py:PyLinter._discover_files", "pylint/lint/pylinter.py:PyLinter.check"], "raw_output_loc": ["```\npylint/lint/pylinter.py\nline: 1014\nfunction: PyLinter.open\n\npylint/lint/expand_modules.py\nline: 49\nfunction: _is_ignored_file\n\npylint/lint/pylinter.py\nline: 600\nfunction: PyLinter._discover_files\n\npylint/config/option_manager_mixin.py\nline: 273\nfunction: OptionsManagerMixIn._parse_toml\n\npylint/lint/pylinter.py\nline: 635\nfunction: PyLinter.check\n```", "```\npylint/config/option_manager_mixin.py\nline: 291-297\nfunction: OptionsManagerMixIn._parse_toml\n\npylint/lint/pylinter.py\nline: 1014\nfunction: PyLinter.open\n\npylint/lint/expand_modules.py\nline: 49-60\nfunction: _is_ignored_file\n```"], "meta_data": {"repo": "pylint-dev/pylint", "base_commit": "3c5eca2ded3dd2b59ebaf23eb289453b5d2930f0", "problem_statement": "`--recursive=y` ignores `ignore-paths`\n### Bug description\r\n\r\nWhen running recursively, it seems `ignore-paths` in my settings in pyproject.toml is completely ignored\r\n\r\n### Configuration\r\n\r\n```ini\r\n[tool.pylint.MASTER]\r\nignore-paths = [\r\n  # Auto generated\r\n  \"^src/gen/.*$\",\r\n]\r\n```\r\n\r\n\r\n### Command used\r\n\r\n```shell\r\npylint --recursive=y src/\r\n```\r\n\r\n\r\n### Pylint output\r\n\r\n```shell\r\n************* Module region_selection\r\nsrc\\region_selection.py:170:0: R0914: Too many local variables (17/15) (too-many-locals)\r\n************* Module about\r\nsrc\\gen\\about.py:2:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\about.py:4:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\about.py:57:0: C0301: Line too long (504/120) (line-too-long)\r\nsrc\\gen\\about.py:12:0: C0103: Class name \"Ui_AboutAutoSplitWidget\" doesn't conform to '_?_?[a-zA-Z]+?$' pattern (invalid-name)\r\nsrc\\gen\\about.py:12:0: R0205: Class 'Ui_AboutAutoSplitWidget' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\nsrc\\gen\\about.py:13:4: C0103: Method name \"setupUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\about.py:13:22: C0103: Argument name \"AboutAutoSplitWidget\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\about.py:53:4: C0103: Method name \"retranslateUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\about.py:53:28: C0103: Argument name \"AboutAutoSplitWidget\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\about.py:24:8: W0201: Attribute 'ok_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\about.py:27:8: W0201: Attribute 'created_by_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\about.py:30:8: W0201: Attribute 'version_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\about.py:33:8: W0201: Attribute 'donate_text_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\about.py:37:8: W0201: Attribute 'donate_button_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\about.py:43:8: W0201: Attribute 'icon_label' defined outside __init__ (attribute-defined-outside-init)\r\n************* Module design\r\nsrc\\gen\\design.py:2:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\design.py:4:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\design.py:328:0: C0301: Line too long (123/120) (line-too-long)\r\nsrc\\gen\\design.py:363:0: C0301: Line too long (125/120) (line-too-long)\r\nsrc\\gen\\design.py:373:0: C0301: Line too long (121/120) (line-too-long)\r\nsrc\\gen\\design.py:412:0: C0301: Line too long (131/120) (line-too-long)\r\nsrc\\gen\\design.py:12:0: C0103: Class name \"Ui_MainWindow\" doesn't conform to '_?_?[a-zA-Z]+?$' pattern (invalid-name)\r\nsrc\\gen\\design.py:308:8: C0103: Attribute name \"actionSplit_Settings\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:318:8: C0103: Attribute name \"actionCheck_for_Updates_on_Open\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:323:8: C0103: Attribute name \"actionLoop_Last_Split_Image_To_First_Image\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:325:8: C0103: Attribute name \"actionAuto_Start_On_Reset\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:327:8: C0103: Attribute name \"actionGroup_dummy_splits_when_undoing_skipping\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:12:0: R0205: Class 'Ui_MainWindow' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\nsrc\\gen\\design.py:12:0: R0902: Too many instance attributes (69/15) (too-many-instance-attributes)\r\nsrc\\gen\\design.py:13:4: C0103: Method name \"setupUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:13:22: C0103: Argument name \"MainWindow\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:16:8: C0103: Variable name \"sizePolicy\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:13:4: R0915: Too many statements (339/50) (too-many-statements)\r\nsrc\\gen\\design.py:354:4: C0103: Method name \"retranslateUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:354:28: C0103: Argument name \"MainWindow\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\design.py:354:4: R0915: Too many statements (61/50) (too-many-statements)\r\nsrc\\gen\\design.py:31:8: W0201: Attribute 'central_widget' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:33:8: W0201: Attribute 'x_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:36:8: W0201: Attribute 'select_region_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:40:8: W0201: Attribute 'start_auto_splitter_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:44:8: W0201: Attribute 'reset_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:49:8: W0201: Attribute 'undo_split_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:54:8: W0201: Attribute 'skip_split_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:59:8: W0201: Attribute 'check_fps_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:63:8: W0201: Attribute 'fps_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:66:8: W0201: Attribute 'live_image' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:75:8: W0201: Attribute 'current_split_image' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:81:8: W0201: Attribute 'current_image_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:85:8: W0201: Attribute 'width_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:88:8: W0201: Attribute 'height_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:91:8: W0201: Attribute 'fps_value_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:95:8: W0201: Attribute 'width_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:101:8: W0201: Attribute 'height_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:107:8: W0201: Attribute 'capture_region_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:111:8: W0201: Attribute 'current_image_file_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:115:8: W0201: Attribute 'take_screenshot_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:119:8: W0201: Attribute 'x_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:128:8: W0201: Attribute 'y_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:136:8: W0201: Attribute 'y_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:139:8: W0201: Attribute 'align_region_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:143:8: W0201: Attribute 'select_window_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:147:8: W0201: Attribute 'browse_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:151:8: W0201: Attribute 'split_image_folder_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:154:8: W0201: Attribute 'split_image_folder_input' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:158:8: W0201: Attribute 'capture_region_window_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:162:8: W0201: Attribute 'image_loop_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:165:8: W0201: Attribute 'similarity_viewer_groupbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:169:8: W0201: Attribute 'table_live_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:173:8: W0201: Attribute 'table_highest_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:177:8: W0201: Attribute 'table_threshold_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:181:8: W0201: Attribute 'line_1' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:186:8: W0201: Attribute 'table_current_image_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:189:8: W0201: Attribute 'table_reset_image_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:192:8: W0201: Attribute 'line_2' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:197:8: W0201: Attribute 'line_3' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:202:8: W0201: Attribute 'line_4' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:207:8: W0201: Attribute 'line_5' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:212:8: W0201: Attribute 'table_current_image_live_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:216:8: W0201: Attribute 'table_current_image_highest_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:220:8: W0201: Attribute 'table_current_image_threshold_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:224:8: W0201: Attribute 'table_reset_image_live_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:228:8: W0201: Attribute 'table_reset_image_highest_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:232:8: W0201: Attribute 'table_reset_image_threshold_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:236:8: W0201: Attribute 'reload_start_image_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:240:8: W0201: Attribute 'start_image_status_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:243:8: W0201: Attribute 'start_image_status_value_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:246:8: W0201: Attribute 'image_loop_value_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:249:8: W0201: Attribute 'previous_image_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:254:8: W0201: Attribute 'next_image_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:296:8: W0201: Attribute 'menu_bar' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:299:8: W0201: Attribute 'menu_help' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:301:8: W0201: Attribute 'menu_file' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:304:8: W0201: Attribute 'action_view_help' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:306:8: W0201: Attribute 'action_about' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:308:8: W0201: Attribute 'actionSplit_Settings' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:310:8: W0201: Attribute 'action_save_profile' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:312:8: W0201: Attribute 'action_load_profile' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:314:8: W0201: Attribute 'action_save_profile_as' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:316:8: W0201: Attribute 'action_check_for_updates' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:318:8: W0201: Attribute 'actionCheck_for_Updates_on_Open' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:323:8: W0201: Attribute 'actionLoop_Last_Split_Image_To_First_Image' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:325:8: W0201: Attribute 'actionAuto_Start_On_Reset' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:327:8: W0201: Attribute 'actionGroup_dummy_splits_when_undoing_skipping' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:329:8: W0201: Attribute 'action_settings' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\design.py:331:8: W0201: Attribute 'action_check_for_updates_on_open' defined outside __init__ (attribute-defined-outside-init)\r\n************* Module resources_rc\r\nsrc\\gen\\resources_rc.py:1:0: C0302: Too many lines in module (2311/1000) (too-many-lines)\r\nsrc\\gen\\resources_rc.py:8:0: C0103: Constant name \"qt_resource_data\" doesn't conform to UPPER_CASE naming style (invalid-name)\r\nsrc\\gen\\resources_rc.py:2278:0: C0103: Constant name \"qt_resource_name\" doesn't conform to UPPER_CASE naming style (invalid-name)\r\nsrc\\gen\\resources_rc.py:2294:0: C0103: Constant name \"qt_resource_struct\" doesn't conform to UPPER_CASE naming style (invalid-name)\r\nsrc\\gen\\resources_rc.py:2305:0: C0103: Function name \"qInitResources\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\resources_rc.py:2308:0: C0103: Function name \"qCleanupResources\" doesn't conform to snake_case naming style (invalid-name)\r\n************* Module settings\r\nsrc\\gen\\settings.py:2:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\settings.py:4:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\settings.py:61:0: C0301: Line too long (158/120) (line-too-long)\r\nsrc\\gen\\settings.py:123:0: C0301: Line too long (151/120) (line-too-long)\r\nsrc\\gen\\settings.py:209:0: C0301: Line too long (162/120) (line-too-long)\r\nsrc\\gen\\settings.py:214:0: C0301: Line too long (121/120) (line-too-long)\r\nsrc\\gen\\settings.py:221:0: C0301: Line too long (177/120) (line-too-long)\r\nsrc\\gen\\settings.py:223:0: C0301: Line too long (181/120) (line-too-long)\r\nsrc\\gen\\settings.py:226:0: C0301: Line too long (461/120) (line-too-long)\r\nsrc\\gen\\settings.py:228:0: C0301: Line too long (192/120) (line-too-long)\r\nsrc\\gen\\settings.py:12:0: C0103: Class name \"Ui_DialogSettings\" doesn't conform to '_?_?[a-zA-Z]+?$' pattern (invalid-name)\r\nsrc\\gen\\settings.py:12:0: R0205: Class 'Ui_DialogSettings' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\nsrc\\gen\\settings.py:12:0: R0902: Too many instance attributes (35/15) (too-many-instance-attributes)\r\nsrc\\gen\\settings.py:13:4: C0103: Method name \"setupUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\settings.py:13:22: C0103: Argument name \"DialogSettings\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\settings.py:16:8: C0103: Variable name \"sizePolicy\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\settings.py:13:4: R0915: Too many statements (190/50) (too-many-statements)\r\nsrc\\gen\\settings.py:205:4: C0103: Method name \"retranslateUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\settings.py:205:28: C0103: Argument name \"DialogSettings\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\settings.py:26:8: W0201: Attribute 'capture_settings_groupbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:29:8: W0201: Attribute 'fps_limit_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:36:8: W0201: Attribute 'fps_limit_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:40:8: W0201: Attribute 'live_capture_region_checkbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:46:8: W0201: Attribute 'capture_method_combobox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:49:8: W0201: Attribute 'capture_method_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:52:8: W0201: Attribute 'capture_device_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:55:8: W0201: Attribute 'capture_device_combobox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:59:8: W0201: Attribute 'image_settings_groupbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:65:8: W0201: Attribute 'default_comparison_method' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:73:8: W0201: Attribute 'default_comparison_method_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:76:8: W0201: Attribute 'default_pause_time_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:80:8: W0201: Attribute 'default_pause_time_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:87:8: W0201: Attribute 'default_similarity_threshold_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:92:8: W0201: Attribute 'default_similarity_threshold_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:98:8: W0201: Attribute 'loop_splits_checkbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:104:8: W0201: Attribute 'custom_image_settings_info_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:111:8: W0201: Attribute 'default_delay_time_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:116:8: W0201: Attribute 'default_delay_time_spinbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:121:8: W0201: Attribute 'hotkeys_groupbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:127:8: W0201: Attribute 'set_pause_hotkey_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:131:8: W0201: Attribute 'split_input' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:137:8: W0201: Attribute 'undo_split_input' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:143:8: W0201: Attribute 'split_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:146:8: W0201: Attribute 'reset_input' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:152:8: W0201: Attribute 'set_undo_split_hotkey_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:156:8: W0201: Attribute 'reset_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:159:8: W0201: Attribute 'set_reset_hotkey_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:163:8: W0201: Attribute 'set_split_hotkey_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:167:8: W0201: Attribute 'pause_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:170:8: W0201: Attribute 'pause_input' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:176:8: W0201: Attribute 'undo_split_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:179:8: W0201: Attribute 'set_skip_split_hotkey_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:183:8: W0201: Attribute 'skip_split_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\settings.py:186:8: W0201: Attribute 'skip_split_input' defined outside __init__ (attribute-defined-outside-init)\r\n************* Module update_checker\r\nsrc\\gen\\update_checker.py:2:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\update_checker.py:4:0: R2044: Line with empty comment (empty-comment)\r\nsrc\\gen\\update_checker.py:12:0: C0103: Class name \"Ui_UpdateChecker\" doesn't conform to '_?_?[a-zA-Z]+?$' pattern (invalid-name)\r\nsrc\\gen\\update_checker.py:12:0: R0205: Class 'Ui_UpdateChecker' inherits from object, can be safely removed from bases in python3 (useless-object-inheritance)\r\nsrc\\gen\\update_checker.py:13:4: C0103: Method name \"setupUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:13:22: C0103: Argument name \"UpdateChecker\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:17:8: C0103: Variable name \"sizePolicy\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:33:8: C0103: Variable name \"sizePolicy\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:13:4: R0915: Too many statements (56/50) (too-many-statements)\r\nsrc\\gen\\update_checker.py:71:4: C0103: Method name \"retranslateUi\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:71:28: C0103: Argument name \"UpdateChecker\" doesn't conform to snake_case naming style (invalid-name)\r\nsrc\\gen\\update_checker.py:31:8: W0201: Attribute 'update_status_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:39:8: W0201: Attribute 'current_version_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:42:8: W0201: Attribute 'latest_version_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:45:8: W0201: Attribute 'go_to_download_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:48:8: W0201: Attribute 'left_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:52:8: W0201: Attribute 'right_button' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:55:8: W0201: Attribute 'current_version_number_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:59:8: W0201: Attribute 'latest_version_number_label' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:63:8: W0201: Attribute 'do_not_ask_again_checkbox' defined outside __init__ (attribute-defined-outside-init)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (region_capture -> region_selection) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (error_messages -> user_profile -> region_capture -> region_selection) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplitImage -> split_parser) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoControlledWorker -> error_messages -> AutoSplit) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> user_profile -> region_capture -> region_selection -> error_messages) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplitImage -> error_messages -> user_profile) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> menu_bar -> user_profile -> region_capture -> region_selection -> error_messages) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> region_selection -> error_messages) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> error_messages) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (error_messages -> user_profile -> region_selection) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (error_messages -> user_profile) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplitImage -> split_parser -> error_messages -> user_profile) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> menu_bar -> region_selection -> error_messages) (cyclic-import)\r\nsrc\\gen\\update_checker.py:1:0: R0401: Cyclic import (AutoSplit -> menu_bar -> error_messages) (cyclic-import)\r\n\r\n--------------------------------------------------------------------------\r\nYour code has been rated at -158.32/10 (previous run: -285.20/10, +126.88)\r\n```\r\n\r\n\r\n### Expected behavior\r\n\r\nsrc\\gen\\* should not be checked\r\n\r\n### Pylint version\r\n\r\n```shell\r\npylint 2.14.1\r\nastroid 2.11.5\r\nPython 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]\r\n```\r\n\r\n\r\n### OS / Environment\r\n\r\nWindows 10.0.19044\r\n\r\n\r\n### Additional dependencies\r\n\r\n_No response_\n", "patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -52,6 +52,7 @@ def _is_ignored_file(\n     ignore_list_re: list[Pattern[str]],\n     ignore_list_paths_re: list[Pattern[str]],\n ) -> bool:\n+    element = os.path.normpath(element)\n     basename = os.path.basename(element)\n     return (\n         basename in ignore_list\n"}}
{"instance_id": "django__django-14787", "found_files": ["django/utils/decorators.py"], "found_modules": ["django/utils/decorators.py:_multi_decorate"], "found_entities": ["django/utils/decorators.py:_multi_decorate._wrapper"], "raw_output_loc": ["```\ndjango/utils/decorators.py\nline: 35\nfunction: _multi_decorate._wrapper\n\n```", "```\ndjango/utils/decorators.py:_multi_decorate\nline: 40\nfunction: _multi_decorate._wrapper\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "004b4620f6f4ad87261e149898940f2dcd5757ef", "problem_statement": "method_decorator() should preserve wrapper assignments\nDescription\n\t\nthe function that is passed to the decorator is a partial object and does not have any of the attributes expected from a function i.e. __name__, __module__ etc...\nconsider the following case\ndef logger(func):\n\t@wraps(func)\n\tdef inner(*args, **kwargs):\n\t\ttry:\n\t\t\tresult = func(*args, **kwargs)\n\t\texcept Exception as e:\n\t\t\tresult = str(e)\n\t\tfinally:\n\t\t\tlogger.debug(f\"{func.__name__} called with args: {args} and kwargs: {kwargs} resulting: {result}\")\n\treturn inner\nclass Test:\n\t@method_decorator(logger)\n\tdef hello_world(self):\n\t\treturn \"hello\"\nTest().test_method()\nThis results in the following exception\nAttributeError: 'functools.partial' object has no attribute '__name__'\n", "patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -37,7 +37,7 @@ def _wrapper(self, *args, **kwargs):\n         # 'self' argument, but it's a closure over self so it can call\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n-        bound_method = partial(method.__get__(self, type(self)))\n+        bound_method = wraps(method)(partial(method.__get__(self, type(self))))\n         for dec in decorators:\n             bound_method = dec(bound_method)\n         return bound_method(*args, **kwargs)\n"}}
{"instance_id": "pytest-dev__pytest-5495", "found_files": ["src/_pytest/assertion/util.py", "src/_pytest/assertion/rewrite.py", "src/_pytest/_io/saferepr.py"], "found_modules": ["src/_pytest/assertion/util.py:_diff_text", "src/_pytest/assertion/rewrite.py:_format_assertmsg", "src/_pytest/assertion/util.py:assertrepr_compare", "src/_pytest/_io/saferepr.py:saferepr"], "found_entities": ["src/_pytest/assertion/util.py:_diff_text.escape_for_readable_diff", "src/_pytest/assertion/rewrite.py:_format_assertmsg", "src/_pytest/assertion/util.py:_diff_text", "src/_pytest/_io/saferepr.py:saferepr", "src/_pytest/assertion/util.py:assertrepr_compare"], "raw_output_loc": ["```\nsrc/_pytest/assertion/util.py\nline: 178\nfunction: _diff_text.escape_for_readable_diff\n\nsrc/_pytest/assertion/util.py\nline: 166\nfunction: _diff_text\n\nsrc/_pytest/assertion/util.py\nline: 116\nfunction: assertrepr_compare\n```", "```\nsrc/_pytest/assertion/rewrite.py\nline: 346\nfunction: _format_assertmsg\n\nsrc/_pytest/_io/saferepr.py\nline: 66\nfunction: saferepr\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "1aefb24b37c30fba8fd79a744829ca16e252f340", "problem_statement": "Confusing assertion rewriting message with byte strings\nThe comparison with assertion rewriting for byte strings is confusing: \r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"42\"\r\nE       AssertionError: assert b'' == b'42'\r\nE         Right contains more items, first extra item: 52\r\nE         Full diff:\r\nE         - b''\r\nE         + b'42'\r\nE         ?   ++\r\n```\r\n\r\n52 is the ASCII ordinal of \"4\" here.\r\n\r\nIt became clear to me when using another example:\r\n\r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"1\"\r\nE       AssertionError: assert b'' == b'1'\r\nE         Right contains more items, first extra item: 49\r\nE         Full diff:\r\nE         - b''\r\nE         + b'1'\r\nE         ?   +\r\n```\r\n\r\nNot sure what should/could be done here.\n", "patch": "diff --git a/src/_pytest/assertion/util.py b/src/_pytest/assertion/util.py\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -254,17 +254,38 @@ def _compare_eq_iterable(left, right, verbose=0):\n \n \n def _compare_eq_sequence(left, right, verbose=0):\n+    comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)\n     explanation = []\n     len_left = len(left)\n     len_right = len(right)\n     for i in range(min(len_left, len_right)):\n         if left[i] != right[i]:\n+            if comparing_bytes:\n+                # when comparing bytes, we want to see their ascii representation\n+                # instead of their numeric values (#5260)\n+                # using a slice gives us the ascii representation:\n+                # >>> s = b'foo'\n+                # >>> s[0]\n+                # 102\n+                # >>> s[0:1]\n+                # b'f'\n+                left_value = left[i : i + 1]\n+                right_value = right[i : i + 1]\n+            else:\n+                left_value = left[i]\n+                right_value = right[i]\n+\n             explanation += [\n-                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n+                \"At index {} diff: {!r} != {!r}\".format(i, left_value, right_value)\n             ]\n             break\n-    len_diff = len_left - len_right\n \n+    if comparing_bytes:\n+        # when comparing bytes, it doesn't help to show the \"sides contain one or more items\"\n+        # longer explanation, so skip it\n+        return explanation\n+\n+    len_diff = len_left - len_right\n     if len_diff:\n         if len_diff > 0:\n             dir_with_more = \"Left\"\n"}}
{"instance_id": "django__django-12284", "found_files": ["django/db/models/fields/__init__.py", "django/db/models/base.py", "django/db/models/options.py"], "found_modules": ["django/db/models/fields/__init__.py:Field", "django/db/models/base.py:Model", "django/db/models/options.py:Options", "django/db/models/base.py:ModelBase"], "found_entities": ["django/db/models/fields/__init__.py:Field.contribute_to_class", "django/db/models/base.py:Model._get_FIELD_display", "django/db/models/fields/__init__.py:Field._get_flatchoices", "django/db/models/options.py:Options.add_field", "django/db/models/base.py:ModelBase.__new__"], "raw_output_loc": ["```\ndjango/db/models/fields/__init__.py\nline: 766\nline: 770\nfunction: Field.contribute_to_class\n\n```", "```\ndjango/db/models/base.py\nline: 946\nline: 950\nfunction: Model._get_FIELD_display\n\ndjango/db/models/fields/__init__.py\nline: 152\nline: 154\nfunction: Field.__init__\n\ndjango/db/models/fields/__init__.py\nline: 868\nline: 878\nfunction: Field._get_flatchoices\n\ndjango/db/models/base.py\nline: 273\nline: 278\nclass: ModelBase\n\ndjango/db/models/options.py\nline: 266\nline: 277\nfunction: Options.add_field\n```"], "meta_data": {"repo": "django/django", "base_commit": "c5e373d48cbdd923575956fed477b63d66d9603f", "problem_statement": "Model.get_FOO_display() does not work correctly with inherited choices.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nGiven a base model with choices A containing 3 tuples\nChild Model inherits the base model overrides the choices A and adds 2 more tuples\nget_foo_display does not work correctly for the new tuples added\nExample:\nclass A(models.Model):\n foo_choice = [(\"A\",\"output1\"),(\"B\",\"output2\")]\n field_foo = models.CharField(max_length=254,choices=foo_choice)\n class Meta:\n\t abstract = True\nclass B(A):\n foo_choice = [(\"A\",\"output1\"),(\"B\",\"output2\"),(\"C\",\"output3\")]\n field_foo = models.CharField(max_length=254,choices=foo_choice)\nUpon invoking get_field_foo_display() on instance of B , \nFor value \"A\" and \"B\" the output works correctly i.e. returns \"output1\" / \"output2\"\nbut for value \"C\" the method returns \"C\" and not \"output3\" which is the expected behaviour\n", "patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -764,7 +764,11 @@ def contribute_to_class(self, cls, name, private_only=False):\n             if not getattr(cls, self.attname, None):\n                 setattr(cls, self.attname, self.descriptor_class(self))\n         if self.choices is not None:\n-            if not hasattr(cls, 'get_%s_display' % self.name):\n+            # Don't override a get_FOO_display() method defined explicitly on\n+            # this class, but don't check methods derived from inheritance, to\n+            # allow overriding inherited choices. For more complex inheritance\n+            # structures users should override contribute_to_class().\n+            if 'get_%s_display' % self.name not in cls.__dict__:\n                 setattr(\n                     cls,\n                     'get_%s_display' % self.name,\n"}}
{"instance_id": "scikit-learn__scikit-learn-25570", "found_files": ["sklearn/compose/_column_transformer.py"], "found_modules": ["sklearn/compose/_column_transformer.py:ColumnTransformer", "sklearn/compose/_column_transformer.py:_is_empty_column_selection"], "found_entities": ["sklearn/compose/_column_transformer.py:ColumnTransformer._iter", "sklearn/compose/_column_transformer.py:ColumnTransformer._hstack", "sklearn/compose/_column_transformer.py:ColumnTransformer._add_prefix_for_feature_names_out", "sklearn/compose/_column_transformer.py:_is_empty_column_selection", "sklearn/compose/_column_transformer.py:ColumnTransformer.fit_transform"], "raw_output_loc": ["```\nsklearn/compose/_column_transformer.py\nline: 394\nfunction: ColumnTransformer._iter\n\nsklearn/compose/_column_transformer.py\nline: 856\nline: 859\nfunction: ColumnTransformer._hstack\n\nsklearn/compose/_column_transformer.py\nline: 533\nfunction: ColumnTransformer._add_prefix_for_feature_names_out\n\nsklearn/compose/_column_transformer.py\nline: 750\nfunction: ColumnTransformer.fit_transform\n\nsklearn/compose/_column_transformer.py\nline: 824\nfunction: ColumnTransformer._hstack\n```", "```\nsklearn/compose/_column_transformer.py\nline: 856\nline: 859\nclass: ColumnTransformer\nfunction: ColumnTransformer._hstack\n\nsklearn/compose/_column_transformer.py\nline: 347\nclass: ColumnTransformer\nfunction: ColumnTransformer._iter\n\nsklearn/compose/_column_transformer.py\nline: 907\nfunction: _is_empty_column_selection\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "cd25abee0ad0ac95225d4a9be8948eff69f49690", "problem_statement": "ColumnTransformer with pandas output can't handle transformers with no features\n### Describe the bug\r\n\r\nHi,\r\n\r\nColumnTransformer doesn't deal well with transformers that apply to 0 features (categorical_features in the example below) when using \"pandas\" as output. It seems steps with 0 features are not fitted, hence don't appear in `self._iter(fitted=True)` (_column_transformer.py l.856) and hence break the input to the `_add_prefix_for_feature_names_out` function (l.859).\r\n\r\n\r\n### Steps/Code to Reproduce\r\n\r\nHere is some code to reproduce the error. If you remove .set_output(transform=\"pandas\") on the line before last, all works fine. If you remove the (\"categorical\", ...) step, it works fine too.\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom lightgbm import LGBMClassifier\r\nfrom sklearn.compose import ColumnTransformer\r\nfrom sklearn.impute import SimpleImputer\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.preprocessing import RobustScaler\r\n\r\nX = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],\r\n                 columns=[\"a\", \"b\", \"c\", \"d\"])\r\ny = np.array([0, 1])\r\ncategorical_features = []\r\nnumerical_features = [\"a\", \"b\", \"c\"]\r\nmodel_preprocessing = (\"preprocessing\",\r\n                       ColumnTransformer([\r\n                           ('categorical', 'passthrough', categorical_features),\r\n                           ('numerical', Pipeline([(\"scaler\", RobustScaler()),\r\n                                                   (\"imputer\", SimpleImputer(strategy=\"median\"))\r\n                                                   ]), numerical_features),\r\n                       ], remainder='drop'))\r\npipeline = Pipeline([model_preprocessing, (\"classifier\", LGBMClassifier())]).set_output(transform=\"pandas\")\r\npipeline.fit(X, y)\r\n```\r\n\r\n### Expected Results\r\n\r\nThe step with no features should be ignored.\r\n\r\n### Actual Results\r\n\r\nHere is the error message:\r\n```pytb\r\nTraceback (most recent call last):\r\n  File \"/home/philippe/workspace/script.py\", line 22, in <module>\r\n    pipeline.fit(X, y)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/pipeline.py\", line 402, in fit\r\n    Xt = self._fit(X, y, **fit_params_steps)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/pipeline.py\", line 360, in _fit\r\n    X, fitted_transformer = fit_transform_one_cached(\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/joblib/memory.py\", line 349, in __call__\r\n    return self.func(*args, **kwargs)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/pipeline.py\", line 894, in _fit_transform_one\r\n    res = transformer.fit_transform(X, y, **fit_params)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/utils/_set_output.py\", line 142, in wrapped\r\n    data_to_wrap = f(self, X, *args, **kwargs)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 750, in fit_transform\r\n    return self._hstack(list(Xs))\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\", line 862, in _hstack\r\n    output.columns = names_out\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/pandas/core/generic.py\", line 5596, in __setattr__\r\n    return object.__setattr__(self, name, value)\r\n  File \"pandas/_libs/properties.pyx\", line 70, in pandas._libs.properties.AxisProperty.__set__\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/pandas/core/generic.py\", line 769, in _set_axis\r\n    self._mgr.set_axis(axis, labels)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/pandas/core/internals/managers.py\", line 214, in set_axis\r\n    self._validate_set_axis(axis, new_labels)\r\n  File \"/home/philippe/.anaconda3/envs/deleteme/lib/python3.9/site-packages/pandas/core/internals/base.py\", line 69, in _validate_set_axis\r\n    raise ValueError(\r\nValueError: Length mismatch: Expected axis has 3 elements, new values have 0 elements\r\n\r\nProcess finished with exit code 1\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nSystem:\r\n    python: 3.9.15 (main, Nov 24 2022, 14:31:59)  [GCC 11.2.0]\r\nexecutable: /home/philippe/.anaconda3/envs/strategy-training/bin/python\r\n   machine: Linux-5.15.0-57-generic-x86_64-with-glibc2.31\r\n\r\nPython dependencies:\r\n      sklearn: 1.2.0\r\n          pip: 22.2.2\r\n   setuptools: 62.3.2\r\n        numpy: 1.23.5\r\n        scipy: 1.9.3\r\n       Cython: None\r\n       pandas: 1.4.1\r\n   matplotlib: 3.6.3\r\n       joblib: 1.2.0\r\nthreadpoolctl: 3.1.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       user_api: openmp\r\n   internal_api: openmp\r\n         prefix: libgomp\r\n       filepath: /home/philippe/.anaconda3/envs/strategy-training/lib/python3.9/site-packages/scikit_learn.libs/libgomp-a34b3233.so.1.0.0\r\n        version: None\r\n    num_threads: 12\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/philippe/.anaconda3/envs/strategy-training/lib/python3.9/site-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\r\n        version: 0.3.20\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 12\r\n\r\n       user_api: blas\r\n   internal_api: openblas\r\n         prefix: libopenblas\r\n       filepath: /home/philippe/.anaconda3/envs/strategy-training/lib/python3.9/site-packages/scipy.libs/libopenblasp-r0-41284840.3.18.so\r\n        version: 0.3.18\r\nthreading_layer: pthreads\r\n   architecture: Haswell\r\n    num_threads: 12\r\n```\r\n\n", "patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -865,7 +865,9 @@ def _hstack(self, Xs):\n                 transformer_names = [\n                     t[0] for t in self._iter(fitted=True, replace_strings=True)\n                 ]\n-                feature_names_outs = [X.columns for X in Xs]\n+                # Selection of columns might be empty.\n+                # Hence feature names are filtered for non-emptiness.\n+                feature_names_outs = [X.columns for X in Xs if X.shape[1] != 0]\n                 names_out = self._add_prefix_for_feature_names_out(\n                     list(zip(transformer_names, feature_names_outs))\n                 )\n"}}
{"instance_id": "astropy__astropy-12907", "found_files": ["astropy/modeling/separable.py", "astropy/modeling/core.py"], "found_modules": ["astropy/modeling/separable.py:_coord_matrix", "astropy/modeling/separable.py:_separable", "astropy/modeling/separable.py:separability_matrix", "astropy/modeling/separable.py:_cstack"], "found_entities": ["astropy/modeling/separable.py:_coord_matrix", "astropy/modeling/separable.py:_separable", "astropy/modeling/separable.py:separability_matrix", "astropy/modeling/separable.py:_cstack"], "raw_output_loc": ["```\nastropy/modeling/separable.py\nline: 171\nfunction: _coord_matrix\n\nastropy/modeling/separable.py\nline: 219\nfunction: _cstack\n\nastropy/modeling/separable.py\nline: 290\nfunction: _separable\n\nastropy/modeling/core.py\nline: 2894\nclass: CompoundModel\n\nastropy/modeling/separable.py\nline: 66\nfunction: separability_matrix\n```", "```\nastropy/modeling/separable.py:_coord_matrix\nline: 196\nline: 200\nline: 204\nline: 208\nfunction: _coord_matrix\n\nastropy/modeling/separable.py:_separable\nline: 307\nline: 308\nfunction: _separable\n\nastropy/modeling/separable.py:separability_matrix\nline: 100\nfunction: separability_matrix\n```"], "meta_data": {"repo": "astropy/astropy", "base_commit": "d16bfe05a744909de4b27f5875fe0d4ed41ce607", "problem_statement": "Modeling's `separability_matrix` does not compute separability correctly for nested CompoundModels\nConsider the following model:\r\n\r\n```python\r\nfrom astropy.modeling import models as m\r\nfrom astropy.modeling.separable import separability_matrix\r\n\r\ncm = m.Linear1D(10) & m.Linear1D(5)\r\n```\r\n\r\nIt's separability matrix as you might expect is a diagonal:\r\n\r\n```python\r\n>>> separability_matrix(cm)\r\narray([[ True, False],\r\n       [False,  True]])\r\n```\r\n\r\nIf I make the model more complex:\r\n```python\r\n>>> separability_matrix(m.Pix2Sky_TAN() & m.Linear1D(10) & m.Linear1D(5))\r\narray([[ True,  True, False, False],\r\n       [ True,  True, False, False],\r\n       [False, False,  True, False],\r\n       [False, False, False,  True]])\r\n```\r\n\r\nThe output matrix is again, as expected, the outputs and inputs to the linear models are separable and independent of each other.\r\n\r\nIf however, I nest these compound models:\r\n```python\r\n>>> separability_matrix(m.Pix2Sky_TAN() & cm)\r\narray([[ True,  True, False, False],\r\n       [ True,  True, False, False],\r\n       [False, False,  True,  True],\r\n       [False, False,  True,  True]])\r\n```\r\nSuddenly the inputs and outputs are no longer separable?\r\n\r\nThis feels like a bug to me, but I might be missing something?\n", "patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n \n"}}
{"instance_id": "matplotlib__matplotlib-24334", "found_files": ["lib/matplotlib/axis.py", "lib/matplotlib/axes/_axes.py"], "found_modules": ["lib/matplotlib/axis.py:Axis", "lib/matplotlib/axes/_axes.py:Axes"], "found_entities": ["lib/matplotlib/axis.py:Axis.set_ticks", "lib/matplotlib/axis.py:Axis.set_ticklabels", "lib/matplotlib/axis.py:Axis._set_tick_locations", "lib/matplotlib/axes/_axes.py:Axes._parse_scatter_color_args", "lib/matplotlib/axes/_axes.py:Axes.semilogx"], "raw_output_loc": ["```\nlib/matplotlib/axis.py:Axis.set_ticks\nline: 1990\nfunction: Axis.set_ticks\n\nlib/matplotlib/axis.py:Axis.set_ticklabels\nline: 1841\nfunction: Axis.set_ticklabels\n```", "```\nlib/matplotlib/axis.py:Axis.set_ticks\nline: 1990-2027\nfunction: Axis.set_ticks\n\nlib/matplotlib/axis.py:Axis.set_ticklabels\nline: 1841-1921\nfunction: Axis.set_ticklabels\n\nlib/matplotlib/axis.py:Axis._set_tick_locations\nline: 1964-1988\nfunction: Axis._set_tick_locations\n\nlib/matplotlib/axes/_axes.py:Axes._parse_scatter_color_args\nline: 4280-4427\nfunction: Axes._parse_scatter_color_args\n\nlib/matplotlib/axes/_axes.py:Axes.semilogx\nline: 1808-1851\nfunction: Axes.semilogx\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "332937997d03e0c173be6d9fc1841e9186e857df", "problem_statement": "[ENH]: Axes.set_xticks/Axis.set_ticks only validates kwargs if ticklabels are set, but they should\n### Problem\n\nPer the doc of `Axis.set_ticks`:\r\n```\r\n        **kwargs\r\n            `.Text` properties for the labels. These take effect only if you\r\n            pass *labels*. In other cases, please use `~.Axes.tick_params`.\r\n```\r\nThis means that in e.g. `ax.set_xticks([0, 1], xticklabels=[\"a\", \"b\"])`, the incorrect `xticklabels` silently do nothing; they are not even validated (because `labels` has not been passed).\n\n### Proposed solution\n\nWe should at least check that `kwargs` are valid Text properties in all cases; we could even consider making any kwargs an error if `labels` is not set.\n", "patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2029,6 +2029,9 @@ def set_ticks(self, ticks, labels=None, *, minor=False, **kwargs):\n         other limits, you should set the limits explicitly after setting the\n         ticks.\n         \"\"\"\n+        if labels is None and kwargs:\n+            raise ValueError('labels argument cannot be None when '\n+                             'kwargs are passed')\n         result = self._set_tick_locations(ticks, minor=minor)\n         if labels is not None:\n             self.set_ticklabels(labels, minor=minor, **kwargs)\n"}}
{"instance_id": "matplotlib__matplotlib-18869", "found_files": ["lib/matplotlib/__init__.py"], "found_modules": ["lib/matplotlib/__init__.py:__getattr__"], "found_entities": ["lib/matplotlib/__init__.py:__getattr__"], "raw_output_loc": ["```\nlib/matplotlib/__init__.py\nline: 133\nfunction: __getattr__\n```", "```\nlib/matplotlib/__init__.py\nline: 133\nfunction: __getattr__\n\nlib/matplotlib/__init__.py\nline: 149\nfunction: _version.version\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "b7d05919865fc0c37a0164cf467d5d5513bd0ede", "problem_statement": "Add easily comparable version info to toplevel\n<!--\r\nWelcome! Thanks for thinking of a way to improve Matplotlib.\r\n\r\n\r\nBefore creating a new feature request please search the issues for relevant feature requests.\r\n-->\r\n\r\n### Problem\r\n\r\nCurrently matplotlib only exposes `__version__`.  For quick version checks, exposing either a `version_info` tuple (which can be compared with other tuples) or a `LooseVersion` instance (which can be properly compared with other strings) would be a small usability improvement.\r\n\r\n(In practice I guess boring string comparisons will work just fine until we hit mpl 3.10 or 4.10 which is unlikely to happen soon, but that feels quite dirty :))\r\n<!--\r\nProvide a clear and concise description of the problem this feature will solve. \r\n\r\nFor example:\r\n* I'm always frustrated when [...] because [...]\r\n* I would like it if [...] happened when I [...] because [...]\r\n* Here is a sample image of what I am asking for [...]\r\n-->\r\n\r\n### Proposed Solution\r\n\r\nI guess I slightly prefer `LooseVersion`, but exposing just a `version_info` tuple is much more common in other packages (and perhaps simpler to understand).  The hardest(?) part is probably just bikeshedding this point :-)\r\n<!-- Provide a clear and concise description of a way to accomplish what you want. For example:\r\n\r\n* Add an option so that when [...]  [...] will happen\r\n -->\r\n\r\n### Additional context and prior art\r\n\r\n`version_info` is a pretty common thing (citation needed).\r\n<!-- Add any other context or screenshots about the feature request here. You can also include links to examples of other programs that have something similar to your request. For example:\r\n\r\n* Another project [...] solved this by [...]\r\n-->\r\n\n", "patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -129,25 +129,60 @@\n   year      = 2007\n }\"\"\"\n \n+# modelled after sys.version_info\n+_VersionInfo = namedtuple('_VersionInfo',\n+                          'major, minor, micro, releaselevel, serial')\n \n-def __getattr__(name):\n-    if name == \"__version__\":\n+\n+def _parse_to_version_info(version_str):\n+    \"\"\"\n+    Parse a version string to a namedtuple analogous to sys.version_info.\n+\n+    See:\n+    https://packaging.pypa.io/en/latest/version.html#packaging.version.parse\n+    https://docs.python.org/3/library/sys.html#sys.version_info\n+    \"\"\"\n+    v = parse_version(version_str)\n+    if v.pre is None and v.post is None and v.dev is None:\n+        return _VersionInfo(v.major, v.minor, v.micro, 'final', 0)\n+    elif v.dev is not None:\n+        return _VersionInfo(v.major, v.minor, v.micro, 'alpha', v.dev)\n+    elif v.pre is not None:\n+        releaselevel = {\n+            'a': 'alpha',\n+            'b': 'beta',\n+            'rc': 'candidate'}.get(v.pre[0], 'alpha')\n+        return _VersionInfo(v.major, v.minor, v.micro, releaselevel, v.pre[1])\n+    else:\n+        # fallback for v.post: guess-next-dev scheme from setuptools_scm\n+        return _VersionInfo(v.major, v.minor, v.micro + 1, 'alpha', v.post)\n+\n+\n+def _get_version():\n+    \"\"\"Return the version string used for __version__.\"\"\"\n+    # Only shell out to a git subprocess if really needed, and not on a\n+    # shallow clone, such as those used by CI, as the latter would trigger\n+    # a warning from setuptools_scm.\n+    root = Path(__file__).resolve().parents[2]\n+    if (root / \".git\").exists() and not (root / \".git/shallow\").exists():\n         import setuptools_scm\n+        return setuptools_scm.get_version(\n+            root=root,\n+            version_scheme=\"post-release\",\n+            local_scheme=\"node-and-date\",\n+            fallback_version=_version.version,\n+        )\n+    else:  # Get the version from the _version.py setuptools_scm file.\n+        return _version.version\n+\n+\n+def __getattr__(name):\n+    if name in (\"__version__\", \"__version_info__\"):\n         global __version__  # cache it.\n-        # Only shell out to a git subprocess if really needed, and not on a\n-        # shallow clone, such as those used by CI, as the latter would trigger\n-        # a warning from setuptools_scm.\n-        root = Path(__file__).resolve().parents[2]\n-        if (root / \".git\").exists() and not (root / \".git/shallow\").exists():\n-            __version__ = setuptools_scm.get_version(\n-                root=root,\n-                version_scheme=\"post-release\",\n-                local_scheme=\"node-and-date\",\n-                fallback_version=_version.version,\n-            )\n-        else:  # Get the version from the _version.py setuptools_scm file.\n-            __version__ = _version.version\n-        return __version__\n+        __version__ = _get_version()\n+        global __version__info__  # cache it.\n+        __version_info__ = _parse_to_version_info(__version__)\n+        return __version__ if name == \"__version__\" else __version_info__\n     raise AttributeError(f\"module {__name__!r} has no attribute {name!r}\")\n \n \n"}}
{"instance_id": "django__django-12497", "found_files": ["django/db/models/fields/related.py"], "found_modules": ["django/db/models/fields/related.py:ManyToManyField"], "found_entities": ["django/db/models/fields/related.py:ManyToManyField._check_relationship_model"], "raw_output_loc": ["```\ndjango/db/models/fields/related.py\nline: 1310\nline: 1316\nfunction: ManyToManyField._check_relationship_model\n\n```", "```\ndjango/db/models/fields/related.py\nline: 1310\nline: 1311\nline: 1312\nline: 1313\nline: 1314\nline: 1315\nline: 1316\nfunction: ManyToManyField._check_relationship_model\n\nline: 1330\nline: 1331\nline: 1332\nline: 1333\nline: 1334\nline: 1335\nline: 1336\nfunction: ManyToManyField._check_relationship_model\n```"], "meta_data": {"repo": "django/django", "base_commit": "a4881f5e5d7ee38b7e83301331a0b4962845ef8a", "problem_statement": "Wrong hint about recursive relationship.\nDescription\n\t \n\t\t(last modified by Matheus Cunha Motta)\n\t \nWhen there's more than 2 ForeignKeys in an intermediary model of a m2m field and no through_fields have been set, Django will show an error with the following hint:\nhint=(\n\t'If you want to create a recursive relationship, '\n\t'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\nBut 'symmetrical' and 'through' are m2m keyword arguments, not ForeignKey.\nThis was probably a small mistake where the developer thought ManyToManyField but typed ForeignKey instead. And the symmetrical=False is an outdated requirement to recursive relationships with intermediary model to self, not required since 3.0. I'll provide a PR with a proposed correction shortly after.\nEdit: fixed description.\n", "patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1309,7 +1309,7 @@ def _check_relationship_model(self, from_model=None, **kwargs):\n                              \"through_fields keyword argument.\") % (self, from_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n@@ -1329,7 +1329,7 @@ def _check_relationship_model(self, from_model=None, **kwargs):\n                             \"through_fields keyword argument.\" % (self, to_model_name),\n                             hint=(\n                                 'If you want to create a recursive relationship, '\n-                                'use ForeignKey(\"%s\", symmetrical=False, through=\"%s\").'\n+                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                             ) % (\n                                 RECURSIVE_RELATIONSHIP_CONSTANT,\n                                 relationship_model_name,\n"}}
{"instance_id": "django__django-15388", "found_files": ["django/template/autoreload.py", "django/utils/autoreload.py", "django/utils/_os.py"], "found_modules": ["django/template/autoreload.py:watch_for_template_changes", "django/utils/autoreload.py:BaseReloader", "django/utils/_os.py:to_path", "django/template/autoreload.py:get_template_directories"], "found_entities": ["django/template/autoreload.py:watch_for_template_changes", "django/utils/autoreload.py:BaseReloader.run", "django/utils/_os.py:to_path", "django/template/autoreload.py:get_template_directories", "django/utils/autoreload.py:BaseReloader.watch_dir"], "raw_output_loc": ["```\ndjango/template/autoreload.py\nline: 44\nfunction: watch_for_template_changes\n\nsettings.py\nline: 57\nfunction: TEMPLATES[0]['DIRS']\n\ndjango/utils/_os.py\nline: 53\nfunction: to_path\n```", "```\ndjango/utils/autoreload.py\nline: 334\nfunction: BaseReloader.run\n\npython3.11/site-packages/django/template/autoreload.py\nline: 43-46\nfunction: watch_for_template_changes\n\npython3.11/site-packages/django/template/autoreload.py\nline: 12-32\nfunction: get_template_directories\n\npython3.11/site-packages/django/utils/autoreload.py\nline: 276-288\nfunction: BaseReloader.watch_dir\n```"], "meta_data": {"repo": "django/django", "base_commit": "c5cd8783825b5f6384417dac5f3889b4210b7d08", "problem_statement": "Dev Server fails to restart after adding BASE_DIR to TEMPLATES[0]['DIRS'] in settings\nDescription\n\t\nRepro steps:\n$ pip install -U django\n$ django-admin startproject <name>\nOpen settings.py, copy the BASE_DIR variable from line 16 and paste it into the empty DIRS list on line 57\n$ ./manage.py runserver\nBack in your IDE, save a file and watch the dev server *NOT* restart.\nBack in settings.py, remove BASE_DIR from the templates DIRS list. Manually CTRL-C your dev server (as it won't restart on its own when you save), restart the dev server. Now return to your settings.py file, re-save it, and notice the development server once again detects changes and restarts.\nThis bug prevents the dev server from restarting no matter where you make changes - it is not just scoped to edits to settings.py.\n", "patch": "diff --git a/django/template/autoreload.py b/django/template/autoreload.py\n--- a/django/template/autoreload.py\n+++ b/django/template/autoreload.py\n@@ -48,6 +48,8 @@ def watch_for_template_changes(sender, **kwargs):\n \n @receiver(file_changed, dispatch_uid='template_loaders_file_changed')\n def template_changed(sender, file_path, **kwargs):\n+    if file_path.suffix == '.py':\n+        return\n     for template_dir in get_template_directories():\n         if template_dir in file_path.parents:\n             reset_loaders()\n"}}
{"instance_id": "mwaskom__seaborn-3407", "found_files": ["seaborn/axisgrid.py"], "found_modules": ["seaborn/axisgrid.py:PairGrid", "seaborn/axisgrid.py:pairplot"], "found_entities": ["seaborn/axisgrid.py:PairGrid.map_diag", "seaborn/axisgrid.py:pairplot"], "raw_output_loc": ["```\nseaborn/axisgrid.py\nline: 1490\nclass: PairGrid\nfunction: PairGrid.map_diag\n\nseaborn/axisgrid.py\nline: 2144\nfunction: pairplot\n```", "```\nseaborn/axisgrid.py\nline: 1490\nclass: PairGrid\nfunction: PairGrid.map_diag\n\nseaborn/axisgrid.py\nline: 2144\nfunction: pairplot\n```"], "meta_data": {"repo": "mwaskom/seaborn", "base_commit": "515286e02be3e4c0ff2ef4addb34a53c4a676ee4", "problem_statement": "pairplot raises KeyError with MultiIndex DataFrame\nWhen trying to pairplot a MultiIndex DataFrame, `pairplot` raises a `KeyError`:\r\n\r\nMRE:\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport seaborn as sns\r\n\r\n\r\ndata = {\r\n    (\"A\", \"1\"): np.random.rand(100),\r\n    (\"A\", \"2\"): np.random.rand(100),\r\n    (\"B\", \"1\"): np.random.rand(100),\r\n    (\"B\", \"2\"): np.random.rand(100),\r\n}\r\ndf = pd.DataFrame(data)\r\nsns.pairplot(df)\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n[c:\\Users\\KLuu\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py](file:///C:/Users/KLuu/anaconda3/lib/site-packages/seaborn/axisgrid.py) in pairplot(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, corner, dropna, plot_kws, diag_kws, grid_kws, size)\r\n   2142     diag_kws.setdefault(\"legend\", False)\r\n   2143     if diag_kind == \"hist\":\r\n-> 2144         grid.map_diag(histplot, **diag_kws)\r\n   2145     elif diag_kind == \"kde\":\r\n   2146         diag_kws.setdefault(\"fill\", True)\r\n\r\n[c:\\Users\\KLuu\\anaconda3\\lib\\site-packages\\seaborn\\axisgrid.py](file:///C:/Users/KLuu/anaconda3/lib/site-packages/seaborn/axisgrid.py) in map_diag(self, func, **kwargs)\r\n   1488                 plt.sca(ax)\r\n   1489 \r\n-> 1490             vector = self.data[var]\r\n   1491             if self._hue_var is not None:\r\n   1492                 hue = self.data[self._hue_var]\r\n\r\n[c:\\Users\\KLuu\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py](file:///C:/Users/KLuu/anaconda3/lib/site-packages/pandas/core/frame.py) in __getitem__(self, key)\r\n   3765             if is_iterator(key):\r\n   3766                 key = list(key)\r\n-> 3767             indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\r\n   3768 \r\n   3769         # take() does not accept boolean indexers\r\n\r\n[c:\\Users\\KLuu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py](file:///C:/Users/KLuu/anaconda3/lib/site-packages/pandas/core/indexes/multi.py) in _get_indexer_strict(self, key, axis_name)\r\n   2534             indexer = self._get_indexer_level_0(keyarr)\r\n   2535 \r\n-> 2536             self._raise_if_missing(key, indexer, axis_name)\r\n   2537             return self[indexer], indexer\r\n   2538 \r\n\r\n[c:\\Users\\KLuu\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\multi.py](file:///C:/Users/KLuu/anaconda3/lib/site-packages/pandas/core/indexes/multi.py) in _raise_if_missing(self, key, indexer, axis_name)\r\n   2552                 cmask = check == -1\r\n   2553                 if cmask.any():\r\n-> 2554                     raise KeyError(f\"{keyarr[cmask]} not in index\")\r\n   2555                 # We get here when levels still contain values which are not\r\n   2556                 # actually in Index anymore\r\n\r\nKeyError: \"['1'] not in index\"\r\n```\r\n\r\nA workaround is to \"flatten\" the columns:\r\n\r\n```python\r\ndf.columns = [\"\".join(column) for column in df.columns]\r\n```\n", "patch": "diff --git a/seaborn/axisgrid.py b/seaborn/axisgrid.py\n--- a/seaborn/axisgrid.py\n+++ b/seaborn/axisgrid.py\n@@ -1472,8 +1472,8 @@ def map_diag(self, func, **kwargs):\n                 for ax in diag_axes[1:]:\n                     share_axis(diag_axes[0], ax, \"y\")\n \n-            self.diag_vars = np.array(diag_vars, np.object_)\n-            self.diag_axes = np.array(diag_axes, np.object_)\n+            self.diag_vars = diag_vars\n+            self.diag_axes = diag_axes\n \n         if \"hue\" not in signature(func).parameters:\n             return self._map_diag_iter_hue(func, **kwargs)\n"}}
{"instance_id": "pydata__xarray-4248", "found_files": ["xarray/core/dataset.py", "xarray/core/formatting.py"], "found_modules": ["xarray/core/dataset.py:Dataset", "xarray/core/formatting.py:summarize_variable", "xarray/core/formatting.py:inline_variable_array_repr", "xarray/core/formatting.py:coords_repr", "xarray/core/formatting.py:_mapping_repr", "xarray/core/formatting.py:dataset_repr"], "found_entities": ["xarray/core/dataset.py:Dataset.__repr__", "xarray/core/formatting.py:summarize_variable", "xarray/core/formatting.py:inline_variable_array_repr", "xarray/core/formatting.py:coords_repr", "xarray/core/formatting.py:_mapping_repr", "xarray/core/formatting.py:dataset_repr"], "raw_output_loc": ["```\nxarray/core/dataset.py:Dataset.__repr__\nfunction: Dataset.__repr__\n```", "```\nxarray/core/formatting.py\nline: 271\nfunction: summarize_variable\n\nxarray/core/formatting.py\nline: 256\nfunction: inline_variable_array_repr\n\nxarray/core/formatting.py\nline: 386\nfunction: coords_repr\n\nxarray/core/formatting.py\nline: 365\nfunction: _mapping_repr\n\nxarray/core/formatting.py\nline: 495\nfunction: dataset_repr\n```"], "meta_data": {"repo": "pydata/xarray", "base_commit": "98dc1f4ea18738492e074e9e51ddfed5cd30ab94", "problem_statement": "Feature request: show units in dataset overview\nHere's a hypothetical dataset:\r\n\r\n```\r\n<xarray.Dataset>\r\nDimensions:  (time: 3, x: 988, y: 822)\r\nCoordinates:\r\n  * x         (x) float64 ...\r\n  * y         (y) float64 ...\r\n  * time      (time) datetime64[ns] ...\r\nData variables:\r\n    rainfall  (time, y, x) float32 ...\r\n    max_temp  (time, y, x) float32 ...\r\n```\r\n\r\nIt would be really nice if the units of the coordinates and of the data variables were shown in the `Dataset` repr, for example as:\r\n\r\n```\r\n<xarray.Dataset>\r\nDimensions:  (time: 3, x: 988, y: 822)\r\nCoordinates:\r\n  * x, in metres         (x)            float64 ...\r\n  * y, in metres         (y)            float64 ...\r\n  * time                 (time)         datetime64[ns] ...\r\nData variables:\r\n    rainfall, in mm      (time, y, x)   float32 ...\r\n    max_temp, in deg C   (time, y, x)   float32 ...\r\n```\n", "patch": "diff --git a/xarray/core/formatting.py b/xarray/core/formatting.py\n--- a/xarray/core/formatting.py\n+++ b/xarray/core/formatting.py\n@@ -261,6 +261,8 @@ def inline_variable_array_repr(var, max_width):\n         return inline_dask_repr(var.data)\n     elif isinstance(var._data, sparse_array_type):\n         return inline_sparse_repr(var.data)\n+    elif hasattr(var._data, \"_repr_inline_\"):\n+        return var._data._repr_inline_(max_width)\n     elif hasattr(var._data, \"__array_function__\"):\n         return maybe_truncate(repr(var._data).replace(\"\\n\", \" \"), max_width)\n     else:\n"}}
{"instance_id": "django__django-13658", "found_files": ["django/core/management/__init__.py", "django/core/management/base.py"], "found_modules": ["django/core/management/__init__.py:ManagementUtility", "django/core/management/base.py:CommandParser"], "found_entities": ["django/core/management/__init__.py:ManagementUtility.execute"], "raw_output_loc": ["```\ndjango/core/management/__init__.py\nline: 347\nclass: ManagementUtility\nfunction: ManagementUtility.execute\n\n```", "```\ndjango/core/management/__init__.py\nline: 188\nline: 190\nline: 191\nclass: ManagementUtility\nfunction: ManagementUtility.__init__\n\ndjango/core/management/__init__.py\nline: 347\nline: 348\nclass: ManagementUtility\nfunction: ManagementUtility.execute\n\ndjango/core/management/base.py\nline: 51\nclass: CommandParser\nfunction: CommandParser.__init__\n```"], "meta_data": {"repo": "django/django", "base_commit": "0773837e15bb632afffb6848a58c59a791008fa1", "problem_statement": "ManagementUtility instantiates CommandParser without passing already-computed prog argument\nDescription\n\t\nManagementUtility \u200bgoes to the trouble to parse the program name from the argv it's passed rather than from sys.argv: \n\tdef __init__(self, argv=None):\n\t\tself.argv = argv or sys.argv[:]\n\t\tself.prog_name = os.path.basename(self.argv[0])\n\t\tif self.prog_name == '__main__.py':\n\t\t\tself.prog_name = 'python -m django'\nBut then when it needs to parse --pythonpath and --settings, it \u200buses the program name from sys.argv: \n\t\tparser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\nAbove \"%(prog)s\" \u200brefers to sys.argv[0]. Instead, it should refer to self.prog_name. This can fixed as follows:\n\t\tparser = CommandParser(\n\t\t\tprog=self.prog_name,\n\t\t\tusage='%(prog)s subcommand [options] [args]',\n\t\t\tadd_help=False,\n\t\t\tallow_abbrev=False)\nI'm aware that execute_from_command_line is a private API, but it'd be really convenient for me if it worked properly in my weird embedded environment where sys.argv[0] is \u200bincorrectly None. If passing my own argv to execute_from_command_line avoided all the ensuing exceptions, I wouldn't have to modify sys.argv[0] globally as I'm doing in the meantime.\n", "patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -344,7 +344,12 @@ def execute(self):\n         # Preprocess options to extract --settings and --pythonpath.\n         # These options could affect the commands that are available, so they\n         # must be processed early.\n-        parser = CommandParser(usage='%(prog)s subcommand [options] [args]', add_help=False, allow_abbrev=False)\n+        parser = CommandParser(\n+            prog=self.prog_name,\n+            usage='%(prog)s subcommand [options] [args]',\n+            add_help=False,\n+            allow_abbrev=False,\n+        )\n         parser.add_argument('--settings')\n         parser.add_argument('--pythonpath')\n         parser.add_argument('args', nargs='*')  # catch-all\n"}}
{"instance_id": "django__django-15789", "found_files": ["django/utils/html.py"], "found_modules": ["django/utils/html.py:json_script"], "found_entities": ["django/utils/html.py:json_script"], "raw_output_loc": ["```\ndjango/utils/html.py\nline: 62\nfunction: json_script\n\ncore/serializers/json.py\nline: 77\nclass: DjangoJSONEncoder\nfunction: DjangoJSONEncoder.default\n\ntemplate/defaultfilters.py\nline: 85\nfunction: json_script\n```", "```\ndjango/utils/html.py\nline: 62\nfunction: json_script\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "d4d5427571b4bf3a21c902276c2a00215c2a37cc", "problem_statement": "Add an encoder parameter to django.utils.html.json_script().\nDescription\n\t\nI have a use case where I want to customize the JSON encoding of some values to output to the template layer. It looks like django.utils.html.json_script is a good utility for that, however the JSON encoder is hardcoded to DjangoJSONEncoder. I think it would be nice to be able to pass a custom encoder class.\nBy the way, django.utils.html.json_script is not documented (only its template filter counterpart is), would it be a good thing to add to the docs?\n", "patch": "diff --git a/django/utils/html.py b/django/utils/html.py\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -59,7 +59,7 @@ def escapejs(value):\n }\n \n \n-def json_script(value, element_id=None):\n+def json_script(value, element_id=None, encoder=None):\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -67,7 +67,9 @@ def json_script(value, element_id=None):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n \n-    json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n+    json_str = json.dumps(value, cls=encoder or DjangoJSONEncoder).translate(\n+        _json_script_escapes\n+    )\n     if element_id:\n         template = '<script id=\"{}\" type=\"application/json\">{}</script>'\n         args = (element_id, mark_safe(json_str))\n"}}
{"instance_id": "django__django-12286", "found_files": ["django/core/checks/translation.py", "django/utils/translation/trans_real.py", "django/utils/translation/__init__.py"], "found_modules": ["django/core/checks/translation.py:check_language_settings_consistent", "django/utils/translation/trans_real.py:get_supported_language_variant", "django/utils/translation/trans_real.py:DjangoTranslation", "django/utils/translation/trans_real.py:get_language_from_request", "django/utils/translation/__init__.py:to_language"], "found_entities": ["django/core/checks/translation.py:check_language_settings_consistent", "django/utils/translation/trans_real.py:get_supported_language_variant", "django/utils/translation/trans_real.py:DjangoTranslation._add_fallback", "django/utils/translation/trans_real.py:get_language_from_request", "django/utils/translation/__init__.py:to_language"], "raw_output_loc": ["```\ndjango/core/checks/translation.py\nline: 58\nline: 59\nline: 60\nfunction: check_language_settings_consistent\n\ndjango/utils/translation/trans_real.py\nline: 395\nline: 414\nline: 415\nfunction: get_supported_language_variant\n\ndjango/utils/translation/trans_real.py\nline: 156\nline: 157\nline: 158\nfunction: DjangoTranslation._add_fallback\n\ndjango/utils/translation/trans_real.py\nline: 446\nline: 451\nfunction: get_language_from_request\n\ndjango/utils/translation/__init__.py\nline: 263\nline: 264\nfunction: to_language\n```", "```\ndjango/core/checks/translation.py\nline: 56\nline: 57\nline: 58\nline: 59\nline: 60\nfunction: check_language_settings_consistent\n\ndjango/utils/translation/trans_real.py\nline: 394\nline: 395\nline: 396\nline: 397\nline: 398\nfunction: get_supported_language_variant\n```"], "meta_data": {"repo": "django/django", "base_commit": "979f61abd322507aafced9627702362e541ec34e", "problem_statement": "translation.E004 shouldn't be raised on sublanguages when a base language is available.\nDescription\n\t\nAccording to Django documentation:\nIf a base language is available but the sublanguage specified is not, Django uses the base language. For example, if a user specifies de-at (Austrian German) but Django only has de available, Django uses de.\nHowever, when using Django 3.0.2, if my settings.py has\nLANGUAGE_CODE = \"de-at\"\nI get this error message:\nSystemCheckError: System check identified some issues:\nERRORS:\n?: (translation.E004) You have provided a value for the LANGUAGE_CODE setting that is not in the LANGUAGES setting.\nIf using\nLANGUAGE_CODE = \"es-ar\"\nDjango works fine (es-ar is one of the translations provided out of the box).\n", "patch": "diff --git a/django/core/checks/translation.py b/django/core/checks/translation.py\n--- a/django/core/checks/translation.py\n+++ b/django/core/checks/translation.py\n@@ -1,4 +1,5 @@\n from django.conf import settings\n+from django.utils.translation import get_supported_language_variant\n from django.utils.translation.trans_real import language_code_re\n \n from . import Error, Tags, register\n@@ -55,7 +56,9 @@ def check_setting_languages_bidi(app_configs, **kwargs):\n @register(Tags.translation)\n def check_language_settings_consistent(app_configs, **kwargs):\n     \"\"\"Error if language settings are not consistent with each other.\"\"\"\n-    available_tags = {i for i, _ in settings.LANGUAGES} | {'en-us'}\n-    if settings.LANGUAGE_CODE not in available_tags:\n+    try:\n+        get_supported_language_variant(settings.LANGUAGE_CODE)\n+    except LookupError:\n         return [E004]\n-    return []\n+    else:\n+        return []\n"}}
{"instance_id": "django__django-17051", "found_files": ["django/db/models/query.py"], "found_modules": ["django/db/models/query.py:QuerySet"], "found_entities": ["django/db/models/query.py:QuerySet._batched_insert"], "raw_output_loc": ["```\ndjango/db/models/query.py\nline: 1840\nfunction: QuerySet._batched_insert\n\n```", "```\ndjango/db/models/query.py\nline: 1840\nfunction: QuerySet._batched_insert\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "b7a17b0ea0a2061bae752a3a2292007d41825814", "problem_statement": "Allow returning IDs in QuerySet.bulk_create() when updating conflicts.\nDescription\n\t\nCurrently, when using bulk_create with a conflict handling flag turned on (e.g. ignore_conflicts or update_conflicts), the primary keys are not set in the returned queryset, as documented in bulk_create.\nWhile I understand using ignore_conflicts can lead to PostgreSQL not returning the IDs when a row is ignored (see \u200bthis SO thread), I don't understand why we don't return the IDs in the case of update_conflicts.\nFor instance:\nMyModel.objects.bulk_create([MyModel(...)], update_conflicts=True, update_fields=[...], unique_fields=[...])\ngenerates a query without a RETURNING my_model.id part:\nINSERT INTO \"my_model\" (...)\nVALUES (...)\n\tON CONFLICT(...) DO UPDATE ...\nIf I append the RETURNING my_model.id clause, the query is indeed valid and the ID is returned (checked with PostgreSQL).\nI investigated a bit and \u200bthis in Django source is where the returning_fields gets removed.\nI believe we could discriminate the cases differently so as to keep those returning_fields in the case of update_conflicts.\nThis would be highly helpful when using bulk_create as a bulk upsert feature.\n", "patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1837,12 +1837,17 @@ def _batched_insert(\n         inserted_rows = []\n         bulk_return = connection.features.can_return_rows_from_bulk_insert\n         for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n-            if bulk_return and on_conflict is None:\n+            if bulk_return and (\n+                on_conflict is None or on_conflict == OnConflict.UPDATE\n+            ):\n                 inserted_rows.extend(\n                     self._insert(\n                         item,\n                         fields=fields,\n                         using=self.db,\n+                        on_conflict=on_conflict,\n+                        update_fields=update_fields,\n+                        unique_fields=unique_fields,\n                         returning_fields=self.model._meta.db_returning_fields,\n                     )\n                 )\n"}}
{"instance_id": "sphinx-doc__sphinx-8721", "found_files": ["sphinx/ext/viewcode.py", "sphinx/application.py", "sphinx/builders/epub3.py", "sphinx/cmd/make_mode.py"], "found_modules": ["sphinx/ext/viewcode.py:collect_pages", "sphinx/ext/viewcode.py:doctree_read", "sphinx/application.py:Sphinx", "sphinx/ext/viewcode.py:setup", "sphinx/builders/epub3.py:Epub3Builder"], "found_entities": ["sphinx/ext/viewcode.py:collect_pages", "sphinx/ext/viewcode.py:doctree_read", "sphinx/application.py:Sphinx.build", "sphinx/ext/viewcode.py:setup", "sphinx/builders/epub3.py:Epub3Builder.handle_finish"], "raw_output_loc": ["```\nsphinx/ext/viewcode.py\nline: 181\nfunction: collect_pages\n```", "```\nsphinx/ext/viewcode.py\nline: 59\nline: 60\nfunction: doctree_read\n\nsphinx/application.py\nline: 341\nfunction: Sphinx.build\n\nsphinx/builders/epub3.py\nline: 64\nclass: Epub3Builder\nfunction: handle_finish\n\nsphinx/cmd/make_mode.py\nline: 28\nfunction: BUILDERS\n\nsphinx/ext/viewcode.py\nline: 281\nfunction: setup\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "82ef497a8c88f0f6e50d84520e7276bfbf65025d", "problem_statement": "viewcode creates pages for epub even if `viewcode_enable_epub=False` on `make html epub`\n**Describe the bug**\r\nviewcode creates pages for epub even if `viewcode_enable_epub=False` on `make html epub`\r\n\r\n**To Reproduce**\r\n```\r\n$ make html epub\r\n```\r\n\r\n**Expected behavior**\r\nmodule pages should not be created for epub by default.\r\n\r\n**Your project**\r\nNo\r\n\r\n**Screenshots**\r\nNo\r\n\r\n**Environment info**\r\n- OS: Mac\r\n- Python version: 3.9.1\r\n- Sphinx version: HEAD of 3.x\r\n- Sphinx extensions:  sphinx.ext.viewcode\r\n- Extra tools: No\r\n\r\n**Additional context**\r\nNo\r\n\n", "patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,10 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+    if app.builder.name == \"singlehtml\":\n+        return\n+    if app.builder.name.startswith(\"epub\") and not env.config.viewcode_enable_epub:\n+        return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri\n \n"}}
{"instance_id": "sympy__sympy-23262", "found_files": ["sympy/utilities/lambdify.py", "sympy/printing/pycode.py", "sympy/printing/str.py", "sympy/printing/codeprinter.py"], "found_modules": ["sympy/utilities/lambdify.py:lambdify", "sympy/printing/str.py:StrPrinter", "sympy/utilities/lambdify.py:_recursive_to_string", "sympy/utilities/lambdify.py:_import", "sympy/utilities/lambdify.py:_EvaluatorPrinter", "sympy/printing/codeprinter.py:CodePrinter"], "found_entities": ["sympy/utilities/lambdify.py:lambdify", "sympy/printing/str.py:StrPrinter._print_tuple", "sympy/utilities/lambdify.py:_recursive_to_string", "sympy/utilities/lambdify.py:_import", "sympy/utilities/lambdify.py:_EvaluatorPrinter.doprint", "sympy/printing/codeprinter.py:CodePrinter._print_Mul"], "raw_output_loc": ["```\nsympy/utilities/lambdify.py\nline: 874\nfunction: _recursive_to_string\n\nsympy/printing/str.py\nline: 868\nfunction: StrPrinter._print_tuple\n\nsympy/printing/pycode.py\nline: 529\nclass: PythonCodePrinter\nfunction: PythonCodePrinter._print_tuple\n\nsympy/utilities/lambdify.py\nline: 161\nclass: _EvaluatorPrinter\nfunction: _EvaluatorPrinter.doprint\n\nsympy/printing/codeprinter.py\nline: 529\nclass: CodePrinter\nfunction: CodePrinter._print_tuple\n```", "```\nsympy/printing/pycode.py\nclass: PythonCodePrinter\nfunction: PythonCodePrinter._print_Tuple\n\nsympy/utilities/lambdify.py\nfunction: lambdify\n\nsympy/printing/pycode.py\nclass: PythonCodePrinter\nfunction: PythonCodePrinter._print_Tuple\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "fdc707f73a65a429935c01532cd3970d3355eab6", "problem_statement": "Python code printer not respecting tuple with one element\nHi,\r\n\r\nThanks for the recent updates in SymPy! I'm trying to update my code to use SymPy 1.10 but ran into an issue with the Python code printer. MWE:\r\n\r\n\r\n```python\r\nimport inspect\r\nfrom sympy import lambdify\r\n\r\ninspect.getsource(lambdify([], tuple([1])))\r\n```\r\nSymPy 1.9 and under outputs:\r\n```\r\n'def _lambdifygenerated():\\n    return (1,)\\n'\r\n```\r\n\r\nBut SymPy 1.10 gives\r\n\r\n```\r\n'def _lambdifygenerated():\\n    return (1)\\n'\r\n```\r\nNote the missing comma after `1` that causes an integer to be returned instead of a tuple. \r\n\r\nFor tuples with two or more elements, the generated code is correct:\r\n```python\r\ninspect.getsource(lambdify([], tuple([1, 2])))\r\n```\r\nIn SymPy  1.10 and under, outputs:\r\n\r\n```\r\n'def _lambdifygenerated():\\n    return (1, 2)\\n'\r\n```\r\nThis result is expected.\r\n\r\nNot sure if this is a regression. As this breaks my program which assumes the return type to always be a tuple, could you suggest a workaround from the code generation side? Thank you. \n", "patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -956,9 +956,9 @@ def _recursive_to_string(doprint, arg):\n         return doprint(arg)\n     elif iterable(arg):\n         if isinstance(arg, list):\n-            left, right = \"[]\"\n+            left, right = \"[\", \"]\"\n         elif isinstance(arg, tuple):\n-            left, right = \"()\"\n+            left, right = \"(\", \",)\"\n         else:\n             raise NotImplementedError(\"unhandled type: %s, %s\" % (type(arg), arg))\n         return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n"}}
{"instance_id": "scikit-learn__scikit-learn-13584", "found_files": ["sklearn/utils/_pprint.py", "sklearn/base.py", "sklearn/linear_model/logistic.py"], "found_modules": ["sklearn/utils/_pprint.py:_changed_params", "sklearn/utils/_pprint.py:_EstimatorPrettyPrinter", "sklearn/base.py:BaseEstimator", "sklearn/utils/_pprint.py:_safe_repr", "sklearn/linear_model/logistic.py:LogisticRegressionCV"], "found_entities": ["sklearn/utils/_pprint.py:_changed_params", "sklearn/utils/_pprint.py:_EstimatorPrettyPrinter._pprint_estimator", "sklearn/base.py:BaseEstimator.__repr__", "sklearn/utils/_pprint.py:_safe_repr"], "raw_output_loc": ["```\nsklearn/utils/_pprint.py\nline: 98\nfunction: _changed_params\n\nsklearn/utils/_pprint.py\nline: 179\nfunction: _EstimatorPrettyPrinter._pprint_estimator\n\nsklearn/base.py\nline: 247\nfunction: BaseEstimator.__repr__\n```", "```\nsklearn/utils/_pprint.py\nline: 98\nline: 99\nfunction: _changed_params\n\nsklearn/linear_model/logistic.py\nline: 1934\nclass: LogisticRegressionCV\nfunction: LogisticRegressionCV.__init__\n\nsklearn/utils/_pprint.py\nline: 179\nfunction: _EstimatorPrettyPrinter._pprint_estimator\n\nsklearn/utils/_pprint.py\nline: 413\nfunction: _safe_repr\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "0e3c1879b06d839171b7d0a607d71bbb19a966a9", "problem_statement": "bug in print_changed_only in new repr: vector values\n```python\r\nimport sklearn\r\nimport numpy as np\r\nfrom sklearn.linear_model import LogisticRegressionCV\r\nsklearn.set_config(print_changed_only=True)\r\nprint(LogisticRegressionCV(Cs=np.array([0.1, 1])))\r\n```\r\n> ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\r\n\r\nping @NicolasHug \r\n\n", "patch": "diff --git a/sklearn/utils/_pprint.py b/sklearn/utils/_pprint.py\n--- a/sklearn/utils/_pprint.py\n+++ b/sklearn/utils/_pprint.py\n@@ -95,7 +95,7 @@ def _changed_params(estimator):\n     init_params = signature(init_func).parameters\n     init_params = {name: param.default for name, param in init_params.items()}\n     for k, v in params.items():\n-        if (v != init_params[k] and\n+        if (repr(v) != repr(init_params[k]) and\n                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n             filtered_params[k] = v\n     return filtered_params\n"}}
{"instance_id": "matplotlib__matplotlib-26011", "found_files": ["lib/matplotlib/axes/_base.py", "lib/matplotlib/axis.py", "lib/matplotlib/cbook.py"], "found_modules": ["lib/matplotlib/axes/_base.py:_AxesBase", "lib/matplotlib/axis.py:Axis", "lib/matplotlib/cbook.py:CallbackRegistry"], "found_entities": ["lib/matplotlib/axes/_base.py:_AxesBase.set_xlim", "lib/matplotlib/axis.py:Axis._set_lim", "lib/matplotlib/axis.py:Axis._get_shared_axes", "lib/matplotlib/cbook.py:CallbackRegistry.process", "lib/matplotlib/axes/_base.py:_AxesBase._process_unit_info"], "raw_output_loc": ["```\nlib/matplotlib/axes/_base.py\nline: 3570\nclass: _AxesBase\nfunction: _AxesBase.set_xlim\n\nlib/matplotlib/axis.py\nline: 1180\nclass: Axis\nfunction: Axis._set_lim\n```", "```\nlib/matplotlib/axes/_base.py\nline: 3570\nclass: _AxesBase\nfunction: _AxesBase.set_xlim\n\nlib/matplotlib/axis.py\nline: 1241\nclass: Axis\nfunction: Axis._set_lim\n\nlib/matplotlib/cbook.py\nline: 1\nfunction: CallbackRegistry.process\n\nlib/matplotlib/axes/_base.py\nline: 3646\nclass: _AxesBase\nfunction: _AxesBase._process_unit_info\n\nlib/matplotlib/axis.py\nline: 724\nclass: Axis\nfunction: Axis._get_shared_axes\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "00afcc0c6d4d2e4390338127f05b8f4fdb4e7087", "problem_statement": "xlim_changed not emitted on shared axis\n<!--To help us understand and resolve your issue, please fill out the form to the best of your ability.-->\r\n<!--You can feel free to delete the sections that do not apply.-->\r\n\r\n### Bug report\r\n\r\n**Bug summary**\r\n\r\nWhen an axis is shared with another its registered \"xlim_changed\" callbacks does not get called when the change is induced by a shared axis (via sharex=). \r\n\r\nIn _base.py the set_xlim for sibling axis are called with emit=False:\r\n\r\n```\r\nmatplotlib/lib/matplotlib/axes/_base.py:\r\n\r\n/.../\r\ndef set_xlim(...)\r\n/.../\r\n        if emit:\r\n            self.callbacks.process('xlim_changed', self)\r\n            # Call all of the other x-axes that are shared with this one\r\n            for other in self._shared_x_axes.get_siblings(self):\r\n                if other is not self:\r\n                    other.set_xlim(self.viewLim.intervalx,\r\n                                   emit=False, auto=auto)\r\n```\r\n\r\nI'm very new to matplotlib, so perhaps there is a good reason for this? emit=False seems to disable both continued \"inheritance\" of axis (why?) and triggering of change callbacks (looking at the code above).\r\n\r\nIt seems like one would at least want to trigger the xlim_changed callbacks as they would be intended to react to any change in axis limits.\r\n\r\nEdit: Setting emit=True seems to introduce a recursion issue (not sure why but as inheritance seems to be passed along anyway it doesn't really matter). Moving the callback call to outside of the \"if emit:\"-statement seems to solve the issue as far as I can see when trying it out. Any reason to keep it inside the if-statement? \r\n\n", "patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -1241,11 +1241,13 @@ def _set_lim(self, v0, v1, *, emit=True, auto):\n             self.axes.callbacks.process(f\"{name}lim_changed\", self.axes)\n             # Call all of the other axes that are shared with this one\n             for other in self._get_shared_axes():\n-                if other is not self.axes:\n-                    other._axis_map[name]._set_lim(\n-                        v0, v1, emit=False, auto=auto)\n-                    if other.figure != self.figure:\n-                        other.figure.canvas.draw_idle()\n+                if other is self.axes:\n+                    continue\n+                other._axis_map[name]._set_lim(v0, v1, emit=False, auto=auto)\n+                if emit:\n+                    other.callbacks.process(f\"{name}lim_changed\", other)\n+                if other.figure != self.figure:\n+                    other.figure.canvas.draw_idle()\n \n         self.stale = True\n         return v0, v1\n"}}
{"instance_id": "sympy__sympy-13471", "found_files": ["sympy/core/numbers.py", "sympy/core/basic.py"], "found_modules": ["sympy/core/numbers.py:Float", "sympy/core/basic.py:Basic"], "found_entities": ["sympy/core/numbers.py:Float.__new__", "sympy/core/numbers.py:Float.__getstate__", "sympy/core/basic.py:Basic.__setstate__"], "raw_output_loc": ["```\nsympy/core/numbers.py\nline: 1045\nfunction: Float.__new__\n\nsympy/core/numbers.py\nline: 1041-1046\nfunction: Float.__new__\n\nsympy/core/numbers.py\nline: 1040-1047\nfunction: Float.__new__\n\nsympy/core/numbers.py\nline: 1045\nfunction: Float.__new__\n\nsympy/core/numbers.py\nline: 1045\nfunction: Float.__new__\n```", "```\nsympy/core/numbers.py\nline: 1045\nclass: Float\nfunction: Float.__new__\n\nsympy/core/numbers.py\nline: 1088\nfunction: Float.__getstate__\n\nsympy/core/basic.py\nline: 115\nfunction: Basic.__setstate__\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "3546ac7ed78e1780c1a76929864bb33330055740", "problem_statement": "Python 2->3 pickle fails with float-containing expressions\nDumping a pickled sympy expression containing a float in Python 2, then loading it in Python 3 generates an error.\r\n\r\nHere is a minimum working example, verified with sympy git commit 3546ac7 (master at time of writing), Python 2.7 and Python 3.6:\r\n\r\n```python\r\npython2 -c 'import pickle; import sympy; x = sympy.symbols(\"x\"); print pickle.dumps(x + 1.0, 2)' | python3 -c 'import pickle; import sys; print(pickle.loads(sys.stdin.buffer.read()))'\r\n```\r\n\r\nand the result:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/alex/git/VU/sympy/sympy/core/numbers.py\", line 1045, in __new__\r\n    num[1] = long(num[1], 16)\r\nValueError: invalid literal for int() with base 16: '1L'\r\n```\n", "patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1042,6 +1042,11 @@ def __new__(cls, num, dps=None, prec=None, precision=None):\n                 # it's a hexadecimal (coming from a pickled object)\n                 # assume that it is in standard form\n                 num = list(num)\n+                # If we're loading an object pickled in Python 2 into\n+                # Python 3, we may need to strip a tailing 'L' because\n+                # of a shim for int on Python 3, see issue #13470.\n+                if num[1].endswith('L'):\n+                    num[1] = num[1][:-1]\n                 num[1] = long(num[1], 16)\n                 _mpf_ = tuple(num)\n             else:\n"}}
{"instance_id": "django__django-15996", "found_files": ["django/db/migrations/serializer.py"], "found_modules": ["django/db/migrations/serializer.py:EnumSerializer"], "found_entities": ["django/db/migrations/serializer.py:EnumSerializer.serialize"], "raw_output_loc": ["```\ndjango/db/migrations/serializer.py\nline: 124\nclass: EnumSerializer\nfunction: EnumSerializer.serialize\n```", "```\ndjango/db/migrations/serializer.py\nline: 124\nclass: EnumSerializer\nfunction: EnumSerializer.serialize\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "b30c0081d4d8a31ab7dc7f72a4c7099af606ef29", "problem_statement": "Support for serialization of combination of Enum flags.\nDescription\n\t \n\t\t(last modified by Willem Van Onsem)\n\t \nIf we work with a field:\nregex_flags = models.IntegerField(default=re.UNICODE | re.IGNORECASE)\nThis is turned into a migration with:\ndefault=re.RegexFlag[None]\nThis is due to the fact that the EnumSerializer aims to work with the .name of the item, but if there is no single item for the given value, then there is no such name.\nIn that case, we can use enum._decompose to obtain a list of names, and create an expression to create the enum value by \"ORing\" the items together.\n", "patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -16,7 +16,7 @@\n from django.db.migrations.operations.base import Operation\n from django.db.migrations.utils import COMPILED_REGEX_TYPE, RegexObject\n from django.utils.functional import LazyObject, Promise\n-from django.utils.version import get_docs_version\n+from django.utils.version import PY311, get_docs_version\n \n \n class BaseSerializer:\n@@ -125,8 +125,21 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n+        if issubclass(enum_class, enum.Flag):\n+            if PY311:\n+                members = list(self.value)\n+            else:\n+                members, _ = enum._decompose(enum_class, self.value)\n+                members = reversed(members)\n+        else:\n+            members = (self.value,)\n         return (\n-            \"%s.%s[%r]\" % (module, enum_class.__qualname__, self.value.name),\n+            \" | \".join(\n+                [\n+                    f\"{module}.{enum_class.__qualname__}[{item.name!r}]\"\n+                    for item in members\n+                ]\n+            ),\n             {\"import %s\" % module},\n         )\n \n"}}
{"instance_id": "pylint-dev__pylint-6506", "found_files": ["pylint/config/config_initialization.py", "pylint/__init__.py", "pylint/lint/run.py", "pylint/config/exceptions.py"], "found_modules": ["pylint/__init__.py:run_pylint", "pylint/config/config_initialization.py:_config_initialization", "pylint/config/exceptions.py:_UnrecognizedOptionError", "pylint/lint/run.py:Run"], "found_entities": ["pylint/__init__.py:run_pylint", "pylint/config/config_initialization.py:_config_initialization"], "raw_output_loc": ["```\npylint/__init__.py\nline: 24\nfunction: run_pylint\n\npylint/config/config_initialization.py\nline: 85\nfunction: _config_initialization\n\npylint/config/exceptions.py\nline: 17\nclass: _UnrecognizedOptionError\nfunction: _UnrecognizedOptionError.__init__\n```", "```\npylint/config/config_initialization.py\nline: 83\nline: 84\nline: 85\nfunction: _config_initialization\n\npylint/lint/run.py\nline: 135\nline: 136\nfunction: Run.__init__\n\npylint/__init__.py\nline: 24\nline: 25\nfunction: run_pylint\n```"], "meta_data": {"repo": "pylint-dev/pylint", "base_commit": "0a4204fd7555cfedd43f43017c94d24ef48244a5", "problem_statement": "Traceback printed for unrecognized option\n### Bug description\n\nA traceback is printed when an unrecognized option is passed to pylint.\n\n### Configuration\n\n_No response_\n\n### Command used\n\n```shell\npylint -Q\n```\n\n\n### Pylint output\n\n```shell\n************* Module Command line\r\nCommand line:1:0: E0015: Unrecognized option found: Q (unrecognized-option)\r\nTraceback (most recent call last):\r\n  File \"/Users/markbyrne/venv310/bin/pylint\", line 33, in <module>\r\n    sys.exit(load_entry_point('pylint', 'console_scripts', 'pylint')())\r\n  File \"/Users/markbyrne/programming/pylint/pylint/__init__.py\", line 24, in run_pylint\r\n    PylintRun(argv or sys.argv[1:])\r\n  File \"/Users/markbyrne/programming/pylint/pylint/lint/run.py\", line 135, in __init__\r\n    args = _config_initialization(\r\n  File \"/Users/markbyrne/programming/pylint/pylint/config/config_initialization.py\", line 85, in _config_initialization\r\n    raise _UnrecognizedOptionError(options=unrecognized_options)\r\npylint.config.exceptions._UnrecognizedOptionError\n```\n\n\n### Expected behavior\n\nThe top part of the current output is handy:\r\n`Command line:1:0: E0015: Unrecognized option found: Q (unrecognized-option)`\r\n\r\nThe traceback I don't think is expected & not user-friendly.\r\nA usage tip, for example:\r\n```python\r\nmypy -Q\r\nusage: mypy [-h] [-v] [-V] [more options; see below]\r\n            [-m MODULE] [-p PACKAGE] [-c PROGRAM_TEXT] [files ...]\r\nmypy: error: unrecognized arguments: -Q\r\n```\n\n### Pylint version\n\n```shell\npylint 2.14.0-dev0\r\nastroid 2.11.3\r\nPython 3.10.0b2 (v3.10.0b2:317314165a, May 31 2021, 10:02:22) [Clang 12.0.5 (clang-1205.0.22.9)]\n```\n\n\n### OS / Environment\n\n_No response_\n\n### Additional dependencies\n\n_No response_\n", "patch": "diff --git a/pylint/config/config_initialization.py b/pylint/config/config_initialization.py\n--- a/pylint/config/config_initialization.py\n+++ b/pylint/config/config_initialization.py\n@@ -81,8 +81,7 @@ def _config_initialization(\n             unrecognized_options.append(opt[1:])\n     if unrecognized_options:\n         msg = \", \".join(unrecognized_options)\n-        linter.add_message(\"unrecognized-option\", line=0, args=msg)\n-        raise _UnrecognizedOptionError(options=unrecognized_options)\n+        linter._arg_parser.error(f\"Unrecognized option found: {msg}\")\n \n     # Set the current module to configuration as we don't know where\n     # the --load-plugins key is coming from\n"}}
{"instance_id": "pytest-dev__pytest-8906", "found_files": ["src/_pytest/outcomes.py", "src/_pytest/mark/structures.py", "src/_pytest/skipping.py", "src/_pytest/runner.py"], "found_modules": ["src/_pytest/outcomes.py:skip", "src/_pytest/mark/structures.py:store_mark", "src/_pytest/skipping.py:evaluate_skip_marks", "src/_pytest/outcomes.py:Skipped", "src/_pytest/runner.py:pytest_runtest_makereport", "src/_pytest/outcomes.py:importorskip", "src/_pytest/runner.py:pytest_make_collect_report"], "found_entities": ["src/_pytest/outcomes.py:skip", "src/_pytest/mark/structures.py:store_mark", "src/_pytest/skipping.py:evaluate_skip_marks", "src/_pytest/outcomes.py:importorskip", "src/_pytest/runner.py:pytest_runtest_makereport", "src/_pytest/runner.py:pytest_make_collect_report"], "raw_output_loc": ["```\nsrc/_pytest/outcomes.py\nline: 124\nfunction: skip\n\nsrc/_pytest/skipping.py\nline: 167\nfunction: evaluate_skip_marks\n\nsrc/_pytest/mark/structures.py\nline: 392\nfunction: store_mark\n\nsrc/_pytest/runner.py\nline: 366\nfunction: pytest_runtest_makereport\n\nsrc/_pytest/runner.py\nline: 370\nfunction: pytest_make_collect_report\n```", "```\nsrc/_pytest/outcomes.py\nline: 124\nfunction: skip\n\nsrc/_pytest/outcomes.py\nline: 51\nclass: Skipped\nfunction: Skipped.__init__\n\nsrc/_pytest/mark/structures.py\nline: 392\nfunction: store_mark\n\nsrc/_pytest/outcomes.py\nline: 180\nfunction: importorskip\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "69356d20cfee9a81972dcbf93d8caf9eabe113e8", "problem_statement": "Improve handling of skip for module level\nThis is potentially about updating docs, updating error messages or introducing a new API.\r\n\r\nConsider the following scenario:\r\n\r\n`pos_only.py` is using Python 3,8 syntax:\r\n```python\r\ndef foo(a, /, b):\r\n    return a + b\r\n```\r\n\r\nIt should not be tested under Python 3.6 and 3.7.\r\nThis is a proper way to skip the test in Python older than 3.8:\r\n```python\r\nfrom pytest import raises, skip\r\nimport sys\r\nif sys.version_info < (3, 8):\r\n    skip(msg=\"Requires Python >= 3.8\", allow_module_level=True)\r\n\r\n# import must be after the module level skip:\r\nfrom pos_only import *\r\n\r\ndef test_foo():\r\n    assert foo(10, 20) == 30\r\n    assert foo(10, b=20) == 30\r\n    with raises(TypeError):\r\n        assert foo(a=10, b=20)\r\n```\r\n\r\nMy actual test involves parameterize and a 3.8 only class, so skipping the test itself is not sufficient because the 3.8 class was used in the parameterization.\r\n\r\nA naive user will try to initially skip the module like:\r\n\r\n```python\r\nif sys.version_info < (3, 8):\r\n    skip(msg=\"Requires Python >= 3.8\")\r\n```\r\nThis issues this error:\r\n\r\n>Using pytest.skip outside of a test is not allowed. To decorate a test function, use the @pytest.mark.skip or @pytest.mark.skipif decorators instead, and to skip a module use `pytestmark = pytest.mark.{skip,skipif}.\r\n\r\nThe proposed solution `pytestmark = pytest.mark.{skip,skipif}`, does not work  in my case: pytest continues to process the file and fail when it hits the 3.8 syntax (when running with an older version of Python).\r\n\r\nThe correct solution, to use skip as a function is actively discouraged by the error message.\r\n\r\nThis area feels a bit unpolished.\r\nA few ideas to improve:\r\n\r\n1. Explain skip with  `allow_module_level` in the error message. this seems in conflict with the spirit of the message.\r\n2. Create an alternative API to skip a module to make things easier: `skip_module(\"reason\")`, which can call `_skip(msg=msg, allow_module_level=True)`.\r\n\r\n\n", "patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -608,10 +608,10 @@ def _importtestmodule(self):\n             if e.allow_module_level:\n                 raise\n             raise self.CollectError(\n-                \"Using pytest.skip outside of a test is not allowed. \"\n-                \"To decorate a test function, use the @pytest.mark.skip \"\n-                \"or @pytest.mark.skipif decorators instead, and to skip a \"\n-                \"module use `pytestmark = pytest.mark.{skip,skipif}.\"\n+                \"Using pytest.skip outside of a test will skip the entire module. \"\n+                \"If that's your intention, pass `allow_module_level=True`. \"\n+                \"If you want to skip a specific test or an entire class, \"\n+                \"use the @pytest.mark.skip or @pytest.mark.skipif decorators.\"\n             ) from e\n         self.config.pluginmanager.consider_module(mod)\n         return mod\n"}}
{"instance_id": "django__django-11422", "found_files": ["django/utils/autoreload.py", "django/core/management/commands/runserver.py"], "found_modules": ["django/utils/autoreload.py:BaseReloader", "django/utils/autoreload.py:iter_modules_and_files", "django/core/management/commands/runserver.py:Command", "django/utils/autoreload.py:StatReloader"], "found_entities": ["django/utils/autoreload.py:BaseReloader.watched_files", "django/utils/autoreload.py:iter_modules_and_files", "django/core/management/commands/runserver.py:Command.inner_run", "django/core/management/commands/runserver.py:Command.run", "django/utils/autoreload.py:StatReloader.snapshot_files"], "raw_output_loc": ["```\ndjango/utils/autoreload.py\nline: 244\nfunction: BaseReloader.watched_files\n\nmanage.py\nfunction: main\n```", "```\ndjango/utils/autoreload.py\nline: 239\nfunction: BaseReloader.watched_files\n\ncore/management/__init__.py\nline: 15\nfunction: execute_from_command_line\n\ndjango/core/management/commands/runserver.py\nline: 110\nfunction: Command.run\n\ndjango/utils/autoreload.py\nline: 110\nfunction: iter_modules_and_files\n\ndjango/utils/autoreload.py\nline: 323\nclass: StatReloader\nfunction: StatReloader.snapshot_files\n```"], "meta_data": {"repo": "django/django", "base_commit": "df46b329e0900e9e4dc1d60816c1dce6dfc1094e", "problem_statement": "Autoreloader with StatReloader doesn't track changes in manage.py.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nThis is a bit convoluted, but here we go.\nEnvironment (OSX 10.11):\n$ python -V\nPython 3.6.2\n$ pip -V\npip 19.1.1\n$ pip install Django==2.2.1\nSteps to reproduce:\nRun a server python manage.py runserver\nEdit the manage.py file, e.g. add print(): \ndef main():\n\tprint('sth')\n\tos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ticket_30479.settings')\n\t...\nUnder 2.1.8 (and prior), this will trigger the auto-reloading mechanism. Under 2.2.1, it won't. As far as I can tell from the django.utils.autoreload log lines, it never sees the manage.py itself.\n", "patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -114,7 +114,15 @@ def iter_modules_and_files(modules, extra_files):\n         # During debugging (with PyDev) the 'typing.io' and 'typing.re' objects\n         # are added to sys.modules, however they are types not modules and so\n         # cause issues here.\n-        if not isinstance(module, ModuleType) or getattr(module, '__spec__', None) is None:\n+        if not isinstance(module, ModuleType):\n+            continue\n+        if module.__name__ == '__main__':\n+            # __main__ (usually manage.py) doesn't always have a __spec__ set.\n+            # Handle this by falling back to using __file__, resolved below.\n+            # See https://docs.python.org/reference/import.html#main-spec\n+            sys_file_paths.append(module.__file__)\n+            continue\n+        if getattr(module, '__spec__', None) is None:\n             continue\n         spec = module.__spec__\n         # Modules could be loaded from places without a concrete location. If\n"}}
{"instance_id": "sympy__sympy-15346", "found_files": ["sympy/simplify/trigsimp.py", "sympy/functions/elementary/trigonometric.py", "sympy/core/numbers.py", "sympy/simplify/fu.py"], "found_modules": ["sympy/simplify/trigsimp.py:_futrig", "sympy/simplify/trigsimp.py:trigsimp", "sympy/functions/elementary/trigonometric.py:sin", "sympy/functions/elementary/trigonometric.py:cos", "sympy/simplify/fu.py:fu"], "found_entities": ["sympy/simplify/trigsimp.py:_futrig", "sympy/simplify/trigsimp.py:trigsimp", "sympy/functions/elementary/trigonometric.py:sin.eval", "sympy/functions/elementary/trigonometric.py:cos.eval", "sympy/simplify/fu.py:fu"], "raw_output_loc": ["```\nsympy/simplify/trigsimp.py:_futrig\nfunction: _futrig\n\nsympy/simplify/fu.py:fu\nfunction: fu\n\nsympy/functions/elementary/trigonometric.py:sin.eval\nfunction: sin.eval\n\nsympy/functions/elementary/trigonometric.py:cos.eval\nfunction: cos.eval\n\nsympy/core/numbers.py:Rational\nclass: Rational\n```", "```\nsympy/simplify/trigsimp.py\nfunction: trigsimp\n\nsympy/functions/elementary/trigonometric.py\nclass: sin\nfunction: sin.eval\n\nsympy/functions/elementary/trigonometric.py\nclass: cos\nfunction: cos.eval\n\nsympy/core/numbers.py\nclass: Rational\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "9ef28fba5b4d6d0168237c9c005a550e6dc27d81", "problem_statement": "can't simplify sin/cos with Rational?\nlatest cloned sympy, python 3 on windows\r\nfirstly, cos, sin with symbols can be simplified; rational number can be simplified\r\n```python\r\nfrom sympy import *\r\n\r\nx, y = symbols('x, y', real=True)\r\nr = sin(x)*sin(y) + cos(x)*cos(y)\r\nprint(r)\r\nprint(r.simplify())\r\nprint()\r\n\r\nr = Rational(1, 50) - Rational(1, 25)\r\nprint(r)\r\nprint(r.simplify())\r\nprint()\r\n```\r\nsays\r\n```cmd\r\nsin(x)*sin(y) + cos(x)*cos(y)\r\ncos(x - y)\r\n\r\n-1/50\r\n-1/50\r\n```\r\n\r\nbut\r\n```python\r\nt1 = Matrix([sin(Rational(1, 50)), cos(Rational(1, 50)), 0])\r\nt2 = Matrix([sin(Rational(1, 25)), cos(Rational(1, 25)), 0])\r\nr = t1.dot(t2)\r\nprint(r)\r\nprint(r.simplify())\r\nprint()\r\n\r\nr = sin(Rational(1, 50))*sin(Rational(1, 25)) + cos(Rational(1, 50))*cos(Rational(1, 25))\r\nprint(r)\r\nprint(r.simplify())\r\nprint()\r\n\r\nprint(acos(r))\r\nprint(acos(r).simplify())\r\nprint()\r\n```\r\nsays\r\n```cmd\r\nsin(1/50)*sin(1/25) + cos(1/50)*cos(1/25)\r\nsin(1/50)*sin(1/25) + cos(1/50)*cos(1/25)\r\n\r\nsin(1/50)*sin(1/25) + cos(1/50)*cos(1/25)\r\nsin(1/50)*sin(1/25) + cos(1/50)*cos(1/25)\r\n\r\nacos(sin(1/50)*sin(1/25) + cos(1/50)*cos(1/25))\r\nacos(sin(1/50)*sin(1/25) + cos(1/50)*cos(1/25))\r\n```\r\n\r\n\n", "patch": "diff --git a/sympy/simplify/trigsimp.py b/sympy/simplify/trigsimp.py\n--- a/sympy/simplify/trigsimp.py\n+++ b/sympy/simplify/trigsimp.py\n@@ -1143,8 +1143,8 @@ def _futrig(e, **kwargs):\n         lambda x: _eapply(factor, x, trigs),\n         TR14,  # factored powers of identities\n         [identity, lambda x: _eapply(_mexpand, x, trigs)],\n-        TRmorrie,\n         TR10i,  # sin-cos products > sin-cos of sums\n+        TRmorrie,\n         [identity, TR8],  # sin-cos products -> sin-cos of sums\n         [identity, lambda x: TR2i(TR2(x))],  # tan -> sin-cos -> tan\n         [\n"}}
{"instance_id": "sympy__sympy-18698", "found_files": ["sympy/polys/polytools.py"], "found_modules": ["sympy/polys/polytools.py:_symbolic_factor_list", "sympy/polys/polytools.py:_sorted_factors", "sympy/polys/polytools.py:_generic_factor_list", "sympy/polys/polytools.py:sqf_list", "sympy/polys/polytools.py:Poly"], "found_entities": ["sympy/polys/polytools.py:_symbolic_factor_list", "sympy/polys/polytools.py:_sorted_factors", "sympy/polys/polytools.py:_generic_factor_list", "sympy/polys/polytools.py:sqf_list", "sympy/polys/polytools.py:Poly.sqf_list"], "raw_output_loc": ["```\nsympy/polys/polytools.py:_symbolic_factor_list\nline: 5941\nline: 5942\nline: 5947\nfunction: _symbolic_factor_list\n\nsympy/polys/polytools.py:_generic_factor_list\nline: 5993\nline: 5994\nfunction: _generic_factor_list\n\nsympy/polys/polytools.py:sqf_list\nline: 6204\nfunction: sqf_list\n\nsympy/polys/polytools.py:Poly.sqf_list\nline: 3210\nfunction: Poly.sqf_list\n\nsympy/polys/polytools.py:_sorted_factors\nline: 5877\nfunction: _sorted_factors\n```", "```\nsympy/polys/polytools.py\nline: 5920\nline: 5940\nline: 5952\nfunction: _symbolic_factor_list\n\nsympy/polys/polytools.py\nline: 5877\nline: 5890\nfunction: _sorted_factors\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "3dff1b98a78f28c953ae2140b69356b8391e399c", "problem_statement": "sqf and sqf_list output is not consistant\nThe example below is wrong in the sense that we should have (x*_2 - 5_x + 6, 3) and not 2 factors of multiplicity 3.\n\n```\n>  sqf_list(  (x**2 + 1)  * (x - 1)**2 * (x - 2)**3 * (x - 3)**3  )\n\n>  (1, [(x**2 + 1, 1), (x - 1, 2), (x - 3, 3), (x - 2, 3)])\n```\n\nwhereas below is correct --- one factor of multiplicity 2\n\n```\n>  sqf_list( x**5 - 2*x**4 - 2*x**3 + 4*x**2 + x - 2 )\n\n>  (1, [(x - 2, 1), (x**2 - 1, 2)])\n```\n\n", "patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -2,7 +2,8 @@\n \n from __future__ import print_function, division\n \n-from functools import wraps\n+from functools import wraps, reduce\n+from operator import mul\n \n from sympy.core import (\n     S, Basic, Expr, I, Integer, Add, Mul, Dummy, Tuple\n@@ -5905,10 +5906,7 @@ def _symbolic_factor_list(expr, opt, method):\n         if arg.is_Number:\n             coeff *= arg\n             continue\n-        if arg.is_Mul:\n-            args.extend(arg.args)\n-            continue\n-        if arg.is_Pow:\n+        elif arg.is_Pow:\n             base, exp = arg.args\n             if base.is_Number and exp.is_Number:\n                 coeff *= arg\n@@ -5949,6 +5947,9 @@ def _symbolic_factor_list(expr, opt, method):\n                         other.append((f, k))\n \n                 factors.append((_factors_product(other), exp))\n+    if method == 'sqf':\n+        factors = [(reduce(mul, (f for f, _ in factors if _ == k)), k)\n+                   for k in set(i for _, i in factors)]\n \n     return coeff, factors\n \n"}}
{"instance_id": "django__django-15781", "found_files": ["django/core/management/base.py"], "found_modules": ["django/core/management/base.py:BaseCommand", "django/core/management/base.py:DjangoHelpFormatter"], "found_entities": ["django/core/management/base.py:BaseCommand.create_parser", "django/core/management/base.py:DjangoHelpFormatter.add_usage", "django/core/management/base.py:DjangoHelpFormatter.add_arguments"], "raw_output_loc": ["```\ndjango/core/management/base.py:BaseCommand.create_parser\nline: 291\nfunction: BaseCommand.create_parser\n\n```", "```\ndjango/core/management/base.py\nclass: DjangoHelpFormatter\nfunction: DjangoHelpFormatter.add_usage\nfunction: DjangoHelpFormatter.add_arguments\n\nargparse/__init__.py\nclass: HelpFormatter\nfunction: HelpFormatter.format_help\n```"], "meta_data": {"repo": "django/django", "base_commit": "8d160f154f0240a423e83ffe0690e472f837373c", "problem_statement": "Customizable management command formatters.\nDescription\n\t\nWith code like:\nclass Command(BaseCommand):\n\thelp = '''\n\tImport a contract from tzkt.\n\tExample usage:\n\t\t./manage.py tzkt_import 'Tezos Mainnet' KT1HTDtMBRCKoNHjfWEEvXneGQpCfPAt6BRe\n\t'''\nHelp output is:\n$ ./manage.py help tzkt_import\nusage: manage.py tzkt_import [-h] [--api API] [--version] [-v {0,1,2,3}] [--settings SETTINGS]\n\t\t\t\t\t\t\t [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n\t\t\t\t\t\t\t [--skip-checks]\n\t\t\t\t\t\t\t blockchain target\nImport a contract from tzkt Example usage: ./manage.py tzkt_import 'Tezos Mainnet'\nKT1HTDtMBRCKoNHjfWEEvXneGQpCfPAt6BRe\npositional arguments:\n blockchain\t\t\tName of the blockchain to import into\n target\t\t\t\tId of the contract to import\nWhen that was expected:\n$ ./manage.py help tzkt_import\nusage: manage.py tzkt_import [-h] [--api API] [--version] [-v {0,1,2,3}] [--settings SETTINGS]\n\t\t\t\t\t\t\t [--pythonpath PYTHONPATH] [--traceback] [--no-color] [--force-color]\n\t\t\t\t\t\t\t [--skip-checks]\n\t\t\t\t\t\t\t blockchain target\nImport a contract from tzkt \nExample usage: \n\t./manage.py tzkt_import 'Tezos Mainnet' KT1HTDtMBRCKoNHjfWEEvXneGQpCfPAt6BRe\npositional arguments:\n blockchain\t\t\tName of the blockchain to import into\n target\t\t\t\tId of the contract to import\n", "patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -286,10 +286,10 @@ def create_parser(self, prog_name, subcommand, **kwargs):\n         Create and return the ``ArgumentParser`` which will be used to\n         parse the arguments to this command.\n         \"\"\"\n+        kwargs.setdefault(\"formatter_class\", DjangoHelpFormatter)\n         parser = CommandParser(\n             prog=\"%s %s\" % (os.path.basename(prog_name), subcommand),\n             description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n             missing_args_message=getattr(self, \"missing_args_message\", None),\n             called_from_command_line=getattr(self, \"_called_from_command_line\", None),\n             **kwargs,\n"}}
{"instance_id": "scikit-learn__scikit-learn-13496", "found_files": ["sklearn/ensemble/iforest.py", "sklearn/ensemble/bagging.py", "sklearn/ensemble/forest.py"], "found_modules": ["sklearn/ensemble/iforest.py:IsolationForest", "sklearn/ensemble/bagging.py:BaseBagging", "sklearn/ensemble/forest.py:RandomForestClassifier"], "found_entities": [], "raw_output_loc": ["```\nsklearn/ensemble/iforest.py\nline: 167\nclass: IsolationForest\nfunction: IsolationForest.__init__\n\nsklearn/ensemble/iforest.py\nline: 29\nclass: IsolationForest\nfunction: IsolationForest\n\ntests/test_iforest.py\nfunction: test_warm_start\n\ndoc/modules/ensemble.rst\nfunction: IsolationForest example\n```", "```\nsklearn/ensemble/iforest.py\nline: 167\nclass: IsolationForest\nfunction: IsolationForest.__init__\n\nsklearn/ensemble/bagging.py\nline: 191\nclass: BaseBagging\nfunction: BaseBagging.__init__\n\nsklearn/ensemble/forest.py\nline: 993\nclass: RandomForestClassifier\nfunction: RandomForestClassifier.__init__\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "3aefc834dce72e850bff48689bea3c7dff5f3fad", "problem_statement": "Expose warm_start in Isolation forest\nIt seems to me that `sklearn.ensemble.IsolationForest` supports incremental addition of new trees with the `warm_start` parameter of its parent class, `sklearn.ensemble.BaseBagging`.\r\n\r\nEven though this parameter is not exposed in `__init__()` , it gets inherited from `BaseBagging` and one can use it by changing it to `True` after initialization. To make it work, you have to also increment `n_estimators` on every iteration. \r\n\r\nIt took me a while to notice that it actually works, and I had to inspect the source code of both `IsolationForest` and `BaseBagging`. Also, it looks to me that the behavior is in-line with `sklearn.ensemble.BaseForest` that is behind e.g. `sklearn.ensemble.RandomForestClassifier`.\r\n\r\nTo make it more easier to use, I'd suggest to:\r\n* expose `warm_start` in `IsolationForest.__init__()`, default `False`;\r\n* document it in the same way as it is documented for `RandomForestClassifier`, i.e. say:\r\n```py\r\n    warm_start : bool, optional (default=False)\r\n        When set to ``True``, reuse the solution of the previous call to fit\r\n        and add more estimators to the ensemble, otherwise, just fit a whole\r\n        new forest. See :term:`the Glossary <warm_start>`.\r\n```\r\n* add a test to make sure it works properly;\r\n* possibly also mention in the \"IsolationForest example\" documentation entry;\r\n\n", "patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -120,6 +120,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n     verbose : int, optional (default=0)\n         Controls the verbosity of the tree building process.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+        .. versionadded:: 0.21\n \n     Attributes\n     ----------\n@@ -173,7 +179,8 @@ def __init__(self,\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -185,6 +192,7 @@ def __init__(self,\n             n_estimators=n_estimators,\n             max_samples=max_samples,\n             max_features=max_features,\n+            warm_start=warm_start,\n             n_jobs=n_jobs,\n             random_state=random_state,\n             verbose=verbose)\n"}}
{"instance_id": "sympy__sympy-20442", "found_files": ["sympy/physics/units/util.py", "sympy/physics/units/unitsystem.py", "sympy/physics/units/dimensions.py", "sympy/physics/units/quantities.py"], "found_modules": ["sympy/physics/units/util.py:convert_to", "sympy/physics/units/util.py:_get_conversion_matrix_for_expr", "sympy/physics/units/unitsystem.py:UnitSystem", "sympy/physics/units/dimensions.py:DimensionSystem", "sympy/physics/units/quantities.py:Quantity"], "found_entities": ["sympy/physics/units/util.py:convert_to", "sympy/physics/units/util.py:_get_conversion_matrix_for_expr", "sympy/physics/units/dimensions.py:DimensionSystem.get_dimensional_dependencies", "sympy/physics/units/unitsystem.py:UnitSystem.get_dimensional_expr", "sympy/physics/units/unitsystem.py:UnitSystem.get_quantity_scale_factor", "sympy/physics/units/quantities.py:Quantity.convert_to"], "raw_output_loc": ["```\nsympy/physics/units/util.py\nline: 104\nfunction: _get_conversion_matrix_for_expr\n\nsympy/physics/units/util.py\nline: 37\nfunction: convert_to\n\nsympy/physics/units/unitsystem.py\nline: 141\nfunction: UnitSystem.get_dimensional_expr\n\nsympy/physics/units/dimensions.py\nline: 457\nfunction: DimensionSystem.get_dimensional_dependencies\n\nsympy/physics/units/quantities.py\nline: 188\nfunction: Quantity.convert_to\n```", "```\nsympy/physics/units/util.py:convert_to\nline: 104\nfunction: _get_conversion_matrix_for_expr\n\nsympy/physics/units/util.py:_get_conversion_matrix_for_expr\nline: 33\nfunction: _get_conversion_matrix_for_expr\n\nsympy/physics/units/unitsystem.py:UnitSystem\nline: 30\nfunction: UnitSystem.get_quantity_scale_factor\n\nsympy/physics/units/dimensions.py:Dimension\nline: 19\nfunction: DimensionSystem.get_dimensional_dependencies\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "1abbc0ac3e552cb184317194e5d5c5b9dd8fb640", "problem_statement": "convert_to seems to combine orthogonal units\nTested in sympy 1.4, not presently in a position to install 1.5+.\r\nSimple example. Consider `J = kg*m**2/s**2 => J*s = kg*m**2/s`. The convert_to behavior is odd:\r\n```\r\n>>>convert_to(joule*second,joule)\r\n    joule**(7/9)\r\n```\r\nI would expect the unchanged original expression back, an expression in terms of base units, or an error. It appears that convert_to can only readily handle conversions where the full unit expression is valid.\r\n\r\nNote that the following three related examples give sensible results:\r\n```\r\n>>>convert_to(joule*second,joule*second)\r\n    joule*second\r\n```\r\n```\r\n>>>convert_to(J*s, kg*m**2/s)\r\n    kg*m**2/s\r\n```\r\n```\r\n>>>convert_to(J*s,mins)\r\n    J*mins/60\r\n```\n", "patch": "diff --git a/sympy/physics/units/util.py b/sympy/physics/units/util.py\n--- a/sympy/physics/units/util.py\n+++ b/sympy/physics/units/util.py\n@@ -4,6 +4,7 @@\n \n from sympy import Add, Mul, Pow, Tuple, sympify\n from sympy.core.compatibility import reduce, Iterable, ordered\n+from sympy.matrices.common import NonInvertibleMatrixError\n from sympy.physics.units.dimensions import Dimension\n from sympy.physics.units.prefixes import Prefix\n from sympy.physics.units.quantities import Quantity\n@@ -30,7 +31,11 @@ def _get_conversion_matrix_for_expr(expr, target_units, unit_system):\n     camat = Matrix([[dimension_system.get_dimensional_dependencies(i, mark_dimensionless=True).get(j, 0) for i in target_dims] for j in canon_dim_units])\n     exprmat = Matrix([dim_dependencies.get(k, 0) for k in canon_dim_units])\n \n-    res_exponents = camat.solve_least_squares(exprmat, method=None)\n+    try:\n+        res_exponents = camat.solve(exprmat)\n+    except NonInvertibleMatrixError:\n+        return None\n+\n     return res_exponents\n \n \n"}}
{"instance_id": "sympy__sympy-13177", "found_files": ["sympy/core/mod.py", "sympy/core/power.py", "sympy/core/numbers.py"], "found_modules": ["sympy/core/mod.py:Mod.eval", "sympy/core/mod.py:Mod", "sympy/core/numbers.py:Integer"], "found_entities": ["sympy/core/mod.py:Mod.eval.doit", "sympy/core/mod.py:Mod.eval", "sympy/core/numbers.py:Integer._eval_is_odd"], "raw_output_loc": ["```\nsympy/core/mod.py\nline: 41\nline: 42\nline: 43\nclass: Mod\nfunction: Mod.eval\n```", "```\nsympy/core/mod.py\nline: 41\nline: 42\nline: 43\nclass: Mod\nfunction: Mod.eval\n\nsympy/core/power.py\nline: 183\nclass: Pow\nfunction: Pow.is_Pow\n\nsympy/core/numbers.py\nline: 2161\nfunction: Integer._eval_is_odd\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "662cfb818e865f580e18b59efbb3540c34232beb", "problem_statement": "Mod(x**2, x) is not (always) 0\nWhen the base is not an integer, `x**2 % x` is not 0. The base is not tested to be an integer in Mod's eval logic:\r\n\r\n```\r\nif (p == q or p == -q or\r\n        p.is_Pow and p.exp.is_Integer and p.base == q or\r\n        p.is_integer and q == 1):\r\n    return S.Zero\r\n```\r\n\r\nso\r\n\r\n```\r\n>>> Mod(x**2, x)\r\n0\r\n```\r\nbut\r\n```\r\n>>> x = S(1.5)\r\n>>> Mod(x**2, x)\r\n0.75\r\n```\n", "patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -39,7 +39,8 @@ def doit(p, q):\n             if p.is_infinite or q.is_infinite or p is nan or q is nan:\n                 return nan\n             if (p == q or p == -q or\n-                    p.is_Pow and p.exp.is_Integer and p.base == q or\n+                    p.is_Pow and p.exp.is_integer and p.base == q and q.is_integer\n+                    and p.exp.is_positive or\n                     p.is_integer and q == 1):\n                 return S.Zero\n \n"}}
{"instance_id": "sympy__sympy-13971", "found_files": ["sympy/printing/latex.py", "sympy/printing/pretty/pretty.py", "sympy/series/sequences.py"], "found_modules": ["sympy/printing/latex.py:LatexPrinter", "sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/printing/latex.py:latex", "sympy/printing/pretty/pretty.py:pretty_print", "sympy/series/sequences.py:SeqFormula"], "found_entities": ["sympy/printing/latex.py:LatexPrinter._print_SeqFormula", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_SeqFormula", "sympy/printing/latex.py:latex", "sympy/printing/pretty/pretty.py:pretty_print", "sympy/series/sequences.py:SeqFormula.__new__"], "raw_output_loc": ["```\nsympy/printing/latex.py\nline: 1658\nline: 1660\nfunction: LatexPrinter._print_SeqFormula\n\nsympy/printing/pretty/pretty.py\nline: 1778\nfunction: PrettyPrinter._print_SeqFormula\n\nsympy/series/sequences.py\nline: 602\nclass: SeqFormula\nfunction: SeqFormula.__new__\n\nsympy/printing/latex.py\nline: 2089\nfunction: latex\n\nsympy/printing/pretty/pretty.py\nline: 2259\nfunction: pretty_print\n```", "```\nsympy/printing/latex.py\nline: 1648\nline: 1658\nline: 1660\nclass: LatexPrinter\nfunction: LatexPrinter._print_SeqFormula\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "84c125972ad535b2dfb245f8d311d347b45e5b8a", "problem_statement": "Display of SeqFormula()\n```\r\nimport sympy as sp\r\nk, m, n = sp.symbols('k m n', integer=True)\r\nsp.init_printing()\r\n\r\nsp.SeqFormula(n**2, (n,0,sp.oo))\r\n```\r\n\r\nThe Jupyter rendering of this command backslash-escapes the brackets producing:\r\n\r\n`\\left\\[0, 1, 4, 9, \\ldots\\right\\]`\r\n\r\nCopying this output to a markdown cell this does not render properly.  Whereas:\r\n\r\n`[0, 1, 4, 9, \\ldots ]`\r\n\r\ndoes render just fine.  \r\n\r\nSo - sequence output should not backslash-escape square brackets, or, `\\]` should instead render?\n", "patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -1657,9 +1657,9 @@ def _print_SeqFormula(self, s):\n         else:\n             printset = tuple(s)\n \n-        return (r\"\\left\\[\"\n+        return (r\"\\left[\"\n               + r\", \".join(self._print(el) for el in printset)\n-              + r\"\\right\\]\")\n+              + r\"\\right]\")\n \n     _print_SeqPer = _print_SeqFormula\n     _print_SeqAdd = _print_SeqFormula\n"}}
{"instance_id": "sympy__sympy-24102", "found_files": ["sympy/parsing/mathematica.py"], "found_modules": ["sympy/parsing/mathematica.py:MathematicaParser", "sympy/parsing/mathematica.py:parse_mathematica", "sympy/parsing/mathematica.py:mathematica"], "found_entities": ["sympy/parsing/mathematica.py:MathematicaParser._get_tokenizer", "sympy/parsing/mathematica.py:MathematicaParser._from_mathematica_to_tokens", "sympy/parsing/mathematica.py:parse_mathematica", "sympy/parsing/mathematica.py:MathematicaParser._from_tokens_to_fullformlist", "sympy/parsing/mathematica.py:mathematica", "sympy/parsing/mathematica.py:MathematicaParser._from_fullformlist_to_sympy"], "raw_output_loc": ["```\nsympy/parsing/mathematica.py\nline: 589\nclass: MathematicaParser\nfunction: _literal\n\nsympy/parsing/mathematica.py\nline: 605\nclass: MathematicaParser\nfunction: _get_tokenizer\n\nsympy/parsing/mathematica.py\nline: 622\nclass: MathematicaParser\nfunction: _from_mathematica_to_tokens\n\nsympy/parsing/mathematica.py\nline: 688\nclass: MathematicaParser\nfunction: _from_tokens_to_fullformlist\n\nsympy/parsing/mathematica.py\nline: 1060\nclass: MathematicaParser\nfunction: _from_fullformlist_to_sympy\n```", "```\nsympy/parsing/mathematica.py\nline: 589\nclass: MathematicaParser\nfunction: MathematicaParser._get_tokenizer\n\nsympy/parsing/mathematica.py\nline: 31\nfunction: parse_mathematica\n\nsympy/parsing/mathematica.py\nline: 18\nfunction: mathematica\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "58598660a3f6ab3d918781c4988c2e4b2bdd9297", "problem_statement": "Cannot parse Greek characters (and possibly others) in parse_mathematica\nThe old Mathematica parser `mathematica` in the package `sympy.parsing.mathematica` was able to parse e.g. Greek characters. Hence the following example works fine:\r\n```\r\nfrom sympy.parsing.mathematica import mathematica\r\nmathematica('\u03bb')\r\nOut[]: \r\n\u03bb\r\n```\r\n\r\nAs of SymPy v. 1.11, the `mathematica` function is deprecated, and is replaced by `parse_mathematica`. This function, however, seems unable to handle the simple example above:\r\n```\r\nfrom sympy.parsing.mathematica import parse_mathematica\r\nparse_mathematica('\u03bb')\r\nTraceback (most recent call last):\r\n...\r\nFile \"<string>\", line unknown\r\nSyntaxError: unable to create a single AST for the expression\r\n```\r\n\r\nThis appears to be due to a bug in `parse_mathematica`, which is why I have opened this issue.\r\n\r\nThanks in advance!\nCannot parse Greek characters (and possibly others) in parse_mathematica\nThe old Mathematica parser `mathematica` in the package `sympy.parsing.mathematica` was able to parse e.g. Greek characters. Hence the following example works fine:\r\n```\r\nfrom sympy.parsing.mathematica import mathematica\r\nmathematica('\u03bb')\r\nOut[]: \r\n\u03bb\r\n```\r\n\r\nAs of SymPy v. 1.11, the `mathematica` function is deprecated, and is replaced by `parse_mathematica`. This function, however, seems unable to handle the simple example above:\r\n```\r\nfrom sympy.parsing.mathematica import parse_mathematica\r\nparse_mathematica('\u03bb')\r\nTraceback (most recent call last):\r\n...\r\nFile \"<string>\", line unknown\r\nSyntaxError: unable to create a single AST for the expression\r\n```\r\n\r\nThis appears to be due to a bug in `parse_mathematica`, which is why I have opened this issue.\r\n\r\nThanks in advance!\n", "patch": "diff --git a/sympy/parsing/mathematica.py b/sympy/parsing/mathematica.py\n--- a/sympy/parsing/mathematica.py\n+++ b/sympy/parsing/mathematica.py\n@@ -654,7 +654,7 @@ def _from_mathematica_to_tokens(self, code: str):\n             code_splits[i] = code_split\n \n         # Tokenize the input strings with a regular expression:\n-        token_lists = [tokenizer.findall(i) if isinstance(i, str) else [i] for i in code_splits]\n+        token_lists = [tokenizer.findall(i) if isinstance(i, str) and i.isascii() else [i] for i in code_splits]\n         tokens = [j for i in token_lists for j in i]\n \n         # Remove newlines at the beginning\n"}}
{"instance_id": "django__django-15252", "found_files": ["django/db/migrations/recorder.py", "django/db/migrations/executor.py", "django/db/utils.py"], "found_modules": ["django/db/migrations/recorder.py:MigrationRecorder", "django/db/migrations/executor.py:MigrationExecutor", "django/db/utils.py:ConnectionRouter", "django/db/migrations/executor.py:MigrationExecutor.detect_soft_applied"], "found_entities": ["django/db/migrations/recorder.py:MigrationRecorder.ensure_schema", "django/db/migrations/recorder.py:MigrationRecorder.record_applied", "django/db/migrations/recorder.py:MigrationRecorder.record_unapplied", "django/db/migrations/executor.py:MigrationExecutor.migrate", "django/db/utils.py:ConnectionRouter.allow_migrate", "django/db/migrations/executor.py:MigrationExecutor.detect_soft_applied.should_skip_detecting_model", "django/db/migrations/executor.py:MigrationExecutor.detect_soft_applied"], "raw_output_loc": ["```\ndjango/db/migrations/recorder.py\nline: 59\nclass: MigrationRecorder\nfunction: MigrationRecorder.ensure_schema\n\ndjango/db/migrations/executor.py\nline: 100\nclass: MigrationExecutor\nfunction: MigrationExecutor.migrate\n\ndjango/db/migrations/recorder.py\nline: 84\nclass: MigrationRecorder\nfunction: MigrationRecorder.record_applied\n\ndjango/db/migrations/recorder.py\nline: 89\nclass: MigrationRecorder\nfunction: MigrationRecorder.record_unapplied\n\ndjango/db/migrations/executor.py\nline: 303\nclass: MigrationExecutor\nfunction: MigrationExecutor.detect_soft_applied\n```", "```\ndjango/db/migrations/recorder.py\nline: 59\nline: 66\nclass: MigrationRecorder\nfunction: MigrationRecorder.ensure_schema\n\ndjango/db/migrations/recorder.py\nline: 84\nline: 87\nclass: MigrationRecorder\nfunction: MigrationRecorder.record_applied\n\ndjango/db/migrations/recorder.py\nline: 89\nline: 92\nclass: MigrationRecorder\nfunction: MigrationRecorder.record_unapplied\n\ndjango/db/utils.py\nline: 272\nline: 284\nfunction: ConnectionRouter.allow_migrate\n```"], "meta_data": {"repo": "django/django", "base_commit": "361bb8f786f112ee275be136795c0b1ecefff928", "problem_statement": "MigrationRecorder does not obey db_router allow_migrate rules\nDescription\n\t\nHi,\nWe have a multi-db setup. We have one connection that is for the django project, and several connections that talk to other dbs for information (ie models with managed = False). Django should only create tables in the first connection, never in any of the other connections. We have a simple router that does the following: \nclass Router(object):\n\tdef allow_migrate(self, db, model):\n\t\tif db == 'default':\n\t\t\treturn True\n\t\treturn False\nCurrent Behaviour\nWe run our functional tests and the migrate command is called against each connection when the test databases are created (see django/test/runner.py, setup_databases, line 300-ish, which calls django/db/backends/creation.py, create_test_db, line 377-ish)\nWhen this migrate runs, it tries to apply our migrations, which tries to record that a migration has been applied (see django/db/migrations/executor.py, apply_migration, which has several calls to self.recorder.record_applied). \nThe first thing that record_applied does is a call to self.ensure_schema() (see django/db/migrations/recorder.py, record_applied, lien 66-ish). \nensure_schema checks to see if the Migration model is in the tables in the connection. If it does not find the table then it tries to create the table. \nI believe that this is incorrect behaviour when a db_router has been provided. If using the router above, my expectation would be that the table is not created on any connection other than the 'default' connection. Looking at the other methods on the MigrationRecorder, I would expect that there will be similar issues with applied_migrations and record_unapplied.\n", "patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -96,8 +96,12 @@ def migrate(self, targets, plan=None, state=None, fake=False, fake_initial=False\n         (un)applied and in a second step run all the database operations.\n         \"\"\"\n         # The django_migrations table must be present to record applied\n-        # migrations.\n-        self.recorder.ensure_schema()\n+        # migrations, but don't create it if there are no migrations to apply.\n+        if plan == []:\n+            if not self.recorder.has_table():\n+                return self._create_project_state(with_applied_migrations=False)\n+        else:\n+            self.recorder.ensure_schema()\n \n         if plan is None:\n             plan = self.migration_plan(targets)\n"}}
{"instance_id": "sympy__sympy-18189", "found_files": ["sympy/solvers/diophantine.py", "sympy/utilities/iterables.py"], "found_modules": ["sympy/solvers/diophantine.py:diophantine", "sympy/utilities/iterables.py:signed_permutations", "sympy/utilities/iterables.py:permute_signs"], "found_entities": ["sympy/solvers/diophantine.py:diophantine", "sympy/utilities/iterables.py:signed_permutations", "sympy/utilities/iterables.py:permute_signs"], "raw_output_loc": ["```\nsympy/solvers/diophantine.py\nline: 174\nline: 184\nfunction: diophantine\n\nsympy/utilities/iterables.py\nline: 2615\nfunction: signed_permutations\n```", "```\nsympy/solvers/diophantine.py\nline: 174\nline: 182\nline: 184\nline: 206\nline: 326\nfunction: diophantine\n\nsympy/utilities/iterables.py\nline: 2600\nfunction: permute_signs\nline: 2616\nfunction: signed_permutations\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "1923822ddf8265199dbd9ef9ce09641d3fd042b9", "problem_statement": "diophantine: incomplete results depending on syms order with permute=True\n```\r\nIn [10]: diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(m,n), permute=True)\r\nOut[10]: {(-3, -2), (-3, 2), (-2, -3), (-2, 3), (2, -3), (2, 3), (3, -2), (3, 2)}\r\n\r\nIn [11]: diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(n,m), permute=True)\r\nOut[11]: {(3, 2)}\r\n```\r\n\ndiophantine: incomplete results depending on syms order with permute=True\n```\r\nIn [10]: diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(m,n), permute=True)\r\nOut[10]: {(-3, -2), (-3, 2), (-2, -3), (-2, 3), (2, -3), (2, 3), (3, -2), (3, 2)}\r\n\r\nIn [11]: diophantine(n**4 + m**4 - 2**4 - 3**4, syms=(n,m), permute=True)\r\nOut[11]: {(3, 2)}\r\n```\r\n\n", "patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -182,7 +182,7 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n             if syms != var:\n                 dict_sym_index = dict(zip(syms, range(len(syms))))\n                 return {tuple([t[dict_sym_index[i]] for i in var])\n-                            for t in diophantine(eq, param)}\n+                            for t in diophantine(eq, param, permute=permute)}\n         n, d = eq.as_numer_denom()\n         if n.is_number:\n             return set()\n"}}
{"instance_id": "matplotlib__matplotlib-24149", "found_files": ["lib/matplotlib/cbook/__init__.py", "lib/matplotlib/axes/_axes.py", "lib/matplotlib/patches.py", "lib/matplotlib/collections.py"], "found_modules": ["lib/matplotlib/cbook/__init__.py:_safe_first_finite", "lib/matplotlib/axes/_axes.py:Axes", "lib/matplotlib/patches.py:Rectangle"], "found_entities": ["lib/matplotlib/cbook/__init__.py:_safe_first_finite", "lib/matplotlib/axes/_axes.py:Axes._convert_dx", "lib/matplotlib/axes/_axes.py:Axes.bar"], "raw_output_loc": ["```\nlib/matplotlib/cbook/__init__.py\nline: 1749\nfunction: _safe_first_finite\n\nlib/matplotlib/axes/_axes.py\nline: 2182\nfunction: Axes._convert_dx\n\nlib/matplotlib/axes/_axes.py\nline: 2373\nfunction: Axes.bar\n\nlib/matplotlib/patches.py\nfunction: Rectangle\n\nlib/matplotlib/collections.py\nfunction: BarCollection\n```", "```\nlib/matplotlib/cbook/__init__.py\nline: 1749\nfunction: _safe_first_finite\n\nlib/matplotlib/axes/_axes.py\nline: 2182\nclass: Axes\nfunction: Axes._convert_dx\n\nlib/matplotlib/axes/_axes.py\nline: 2373\nclass: Axes\nfunction: Axes.bar\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "af39f1edffcd828f05cfdd04f2e59506bb4a27bc", "problem_statement": "[Bug]: ax.bar raises for all-nan data on matplotlib 3.6.1 \n### Bug summary\n\n`ax.bar` raises an exception in 3.6.1 when passed only nan data. This irrevocably breaks seaborn's histogram function (which draws and then removes a \"phantom\" bar to trip the color cycle).\n\n### Code for reproduction\n\n```python\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nf, ax = plt.subplots()\r\nax.bar([np.nan], [np.nan])\n```\n\n\n### Actual outcome\n\n```python-traceback\r\n---------------------------------------------------------------------------\r\nStopIteration                             Traceback (most recent call last)\r\nCell In [1], line 4\r\n      2 import matplotlib.pyplot as plt\r\n      3 f, ax = plt.subplots()\r\n----> 4 ax.bar([np.nan], [np.nan])[0].get_x()\r\n\r\nFile ~/miniconda/envs/py310/lib/python3.10/site-packages/matplotlib/__init__.py:1423, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs)\r\n   1420 @functools.wraps(func)\r\n   1421 def inner(ax, *args, data=None, **kwargs):\r\n   1422     if data is None:\r\n-> 1423         return func(ax, *map(sanitize_sequence, args), **kwargs)\r\n   1425     bound = new_sig.bind(ax, *args, **kwargs)\r\n   1426     auto_label = (bound.arguments.get(label_namer)\r\n   1427                   or bound.kwargs.get(label_namer))\r\n\r\nFile ~/miniconda/envs/py310/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2373, in Axes.bar(self, x, height, width, bottom, align, **kwargs)\r\n   2371 x0 = x\r\n   2372 x = np.asarray(self.convert_xunits(x))\r\n-> 2373 width = self._convert_dx(width, x0, x, self.convert_xunits)\r\n   2374 if xerr is not None:\r\n   2375     xerr = self._convert_dx(xerr, x0, x, self.convert_xunits)\r\n\r\nFile ~/miniconda/envs/py310/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2182, in Axes._convert_dx(dx, x0, xconv, convert)\r\n   2170 try:\r\n   2171     # attempt to add the width to x0; this works for\r\n   2172     # datetime+timedelta, for instance\r\n   (...)\r\n   2179     # removes the units from unit packages like `pint` that\r\n   2180     # wrap numpy arrays.\r\n   2181     try:\r\n-> 2182         x0 = cbook._safe_first_finite(x0)\r\n   2183     except (TypeError, IndexError, KeyError):\r\n   2184         pass\r\n\r\nFile ~/miniconda/envs/py310/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:1749, in _safe_first_finite(obj, skip_nonfinite)\r\n   1746     raise RuntimeError(\"matplotlib does not \"\r\n   1747                        \"support generators as input\")\r\n   1748 else:\r\n-> 1749     return next(val for val in obj if safe_isfinite(val))\r\n\r\nStopIteration: \r\n```\n\n### Expected outcome\n\nOn 3.6.0 this returns a `BarCollection` with one Rectangle, having `nan` for `x` and `height`.\n\n### Additional information\n\nI assume it's related to this bullet in the release notes:\r\n\r\n- Fix barplot being empty when first element is NaN\r\n\r\nBut I don't know the context for it to investigate further (could these link to PRs?)\r\n\r\nFurther debugging:\r\n\r\n```python\r\nax.bar([np.nan], [0])  # Raises\r\nax.bar([0], [np.nan])  # Works\r\n```\r\n\r\nSo it's about the x position specifically.\n\n### Operating system\n\nMacos\n\n### Matplotlib Version\n\n3.6.1\n\n### Matplotlib Backend\n\n_No response_\n\n### Python version\n\n_No response_\n\n### Jupyter version\n\n_No response_\n\n### Installation\n\npip\n", "patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2182,11 +2182,19 @@ def _convert_dx(dx, x0, xconv, convert):\n                 x0 = cbook._safe_first_finite(x0)\n             except (TypeError, IndexError, KeyError):\n                 pass\n+            except StopIteration:\n+                # this means we found no finite element, fall back to first\n+                # element unconditionally\n+                x0 = cbook.safe_first_element(x0)\n \n             try:\n                 x = cbook._safe_first_finite(xconv)\n             except (TypeError, IndexError, KeyError):\n                 x = xconv\n+            except StopIteration:\n+                # this means we found no finite element, fall back to first\n+                # element unconditionally\n+                x = cbook.safe_first_element(xconv)\n \n             delist = False\n             if not np.iterable(dx):\n"}}
{"instance_id": "django__django-15695", "found_files": ["django/db/migrations/operations/models.py", "django/db/backends/base/schema.py", "django/db/migrations/state.py"], "found_modules": ["django/db/migrations/operations/models.py:RenameIndex", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor", "django/db/migrations/state.py:ProjectState"], "found_entities": ["django/db/migrations/operations/models.py:RenameIndex.database_backwards", "django/db/migrations/operations/models.py:RenameIndex.database_forwards", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor.rename_index", "django/db/migrations/state.py:ProjectState.rename_index"], "raw_output_loc": ["```\ndjango/db/migrations/operations/models.py\nline: 968\nline: 979\nclass: RenameIndex\nfunction: RenameIndex.database_backwards\n\n```", "```\ndjango/db/migrations/operations/models.py\nline: 934\nline: 968\nclass: RenameIndex\nfunction: RenameIndex.database_forwards\nfunction: RenameIndex.database_backwards\n\ndjango/db/backends/base/schema.py\nline: 496\nfunction: BaseDatabaseSchemaEditor.rename_index\n\ndjango/db/migrations/state.py\nline: 220\nfunction: ProjectState.rename_index\n\ndjango/db/migrations/operations/models.py\nline: 971\nfunction: RenameIndex.database_backwards\n```"], "meta_data": {"repo": "django/django", "base_commit": "647480166bfe7532e8c471fef0146e3a17e6c0c9", "problem_statement": "RenameIndex() crashes when unnamed index is moving backward and forward.\nDescription\n\t\nRenameIndex() should restore the old auto-generated name when an unnamed index for unique_together is moving backward. Now re-applying RenameIndex() crashes. For example:\ntests/migrations/test_operations.py\ndiff --git a/tests/migrations/test_operations.py b/tests/migrations/test_operations.py\nindex cfd28b1b39..c0a55023bb 100644\n\t\t\t\t\t\n\t\t\t\t\t a\n\t\t\t\t \n\t\t\t\t\t\n\t\t\t\t\t b\n\t\t\t\t \n class OperationTests(OperationTestBase):\u00a0\n29882988\u00a0 \u00a0 \u00a0 \u00a0 with connection.schema_editor() as editor, self.assertNumQueries(0):\n29892989\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operation.database_backwards(app_label, editor, new_state, project_state)\n29902990\u00a0 \u00a0 \u00a0 \u00a0 self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n\u00a02991\u00a0 \u00a0 \u00a0 \u00a0 # Re-apply renaming.\n\u00a02992\u00a0 \u00a0 \u00a0 \u00a0 with connection.schema_editor() as editor:\n\u00a02993\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operation.database_forwards(app_label, editor, project_state, new_state)\n\u00a02994\u00a0 \u00a0 \u00a0 \u00a0 self.assertIndexNameExists(table_name, \"new_pony_test_idx\")\n29912995\u00a0 \u00a0 \u00a0 \u00a0 # Deconstruction.\n29922996\u00a0 \u00a0 \u00a0 \u00a0 definition = operation.deconstruct()\n29932997\u00a0 \u00a0 \u00a0 \u00a0 self.assertEqual(definition[0], \"RenameIndex\")\ncrashes on PostgreSQL:\ndjango.db.utils.ProgrammingError: relation \"new_pony_test_idx\" already exists\n", "patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -960,6 +960,9 @@ def database_forwards(self, app_label, schema_editor, from_state, to_state):\n         else:\n             from_model_state = from_state.models[app_label, self.model_name_lower]\n             old_index = from_model_state.get_index_by_name(self.old_name)\n+        # Don't alter when the index name is not changed.\n+        if old_index.name == self.new_name:\n+            return\n \n         to_model_state = to_state.models[app_label, self.model_name_lower]\n         new_index = to_model_state.get_index_by_name(self.new_name)\n"}}
{"instance_id": "django__django-16820", "found_files": ["django/db/models/options.py"], "found_modules": ["django/db/models/options.py:Options"], "found_entities": ["django/db/models/options.py:Options.contribute_to_class"], "raw_output_loc": ["```\ndjango/db/models/options.py\nline: 122\nclass: Options\nfunction: contribute_to_class\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/db/models/options.py\nline: 210\nfunction: Options.contribute_to_class\n\njango/db/backends/sqlite3/schema.py\nline: 277\nfunction: DatabaseSchemaEditor._remake_table\n\njango/db/models/indexes.py\nline: 13\nclass: Index\nfunction: Index.__init__\n\njango/db/migrations/operations/models.py\nline: 1524\nfunction: MigrationAutodetector.generate_removed_altered_index_together\n\njango/db/migrations/operations/models.py\nline: 1547\nfunction: MigrationAutodetector.generate_altered_index_together\n```"], "meta_data": {"repo": "django/django", "base_commit": "c61219a7ae051d2baab53f041e00592011fc550c", "problem_statement": "Squashing migrations with Meta.index_together -> indexes transition should remove deprecation warnings.\nDescription\n\t\nSquashing migrations with Meta.index_together -> Meta.indexes transition should remove deprecation warnings. As far as I'm aware, it's a 4.2 release blocker because you cannot get rid of the index_together deprecation warnings without rewriting migrations, see comment.\n", "patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -303,6 +303,71 @@ def reduce(self, operation, app_label):\n                         managers=self.managers,\n                     ),\n                 ]\n+        elif (\n+            isinstance(operation, IndexOperation)\n+            and self.name_lower == operation.model_name_lower\n+        ):\n+            if isinstance(operation, AddIndex):\n+                return [\n+                    CreateModel(\n+                        self.name,\n+                        fields=self.fields,\n+                        options={\n+                            **self.options,\n+                            \"indexes\": [\n+                                *self.options.get(\"indexes\", []),\n+                                operation.index,\n+                            ],\n+                        },\n+                        bases=self.bases,\n+                        managers=self.managers,\n+                    ),\n+                ]\n+            elif isinstance(operation, RemoveIndex):\n+                options_indexes = [\n+                    index\n+                    for index in self.options.get(\"indexes\", [])\n+                    if index.name != operation.name\n+                ]\n+                return [\n+                    CreateModel(\n+                        self.name,\n+                        fields=self.fields,\n+                        options={\n+                            **self.options,\n+                            \"indexes\": options_indexes,\n+                        },\n+                        bases=self.bases,\n+                        managers=self.managers,\n+                    ),\n+                ]\n+            elif isinstance(operation, RenameIndex) and operation.old_fields:\n+                options_index_together = {\n+                    fields\n+                    for fields in self.options.get(\"index_together\", [])\n+                    if fields != operation.old_fields\n+                }\n+                if options_index_together:\n+                    self.options[\"index_together\"] = options_index_together\n+                else:\n+                    self.options.pop(\"index_together\", None)\n+                return [\n+                    CreateModel(\n+                        self.name,\n+                        fields=self.fields,\n+                        options={\n+                            **self.options,\n+                            \"indexes\": [\n+                                *self.options.get(\"indexes\", []),\n+                                models.Index(\n+                                    fields=operation.old_fields, name=operation.new_name\n+                                ),\n+                            ],\n+                        },\n+                        bases=self.bases,\n+                        managers=self.managers,\n+                    ),\n+                ]\n         return super().reduce(operation, app_label)\n \n \n"}}
{"instance_id": "django__django-15851", "found_files": ["django/db/backends/postgresql/client.py"], "found_modules": ["django/db/backends/postgresql/client.py:DatabaseClient"], "found_entities": ["django/db/backends/postgresql/client.py:DatabaseClient.settings_to_cmd_args_env"], "raw_output_loc": ["```\ndjango/db/backends/postgresql/client.py\nline: 35\nline: 36\nline: 37\nclass: DatabaseClient\nfunction: DatabaseClient.settings_to_cmd_args_env\n```", "```\ndjango/db/backends/postgresql/client.py\nline: 36\nclass: DatabaseClient\nfunction: DatabaseClient.settings_to_cmd_args_env\n```"], "meta_data": {"repo": "django/django", "base_commit": "b4817d20b9e55df30be0b1b2ca8c8bb6d61aab07", "problem_statement": "dbshell additional parameters should be passed before dbname on PostgreSQL.\nDescription\n\t\npsql expects all options to proceed the database name, if provided. So, if doing something like `./manage.py dbshell -- -c \"select * from some_table;\" one will get this:\n$ ./manage.py dbshell -- -c \"select * from some_table;\"\npsql: warning: extra command-line argument \"-c\" ignored\npsql: warning: extra command-line argument \"select * from some_table;\" ignored\npsql (10.21)\nType \"help\" for help.\nsome_database=>\nIt appears the args list just need to be constructed in the proper order, leaving the database name for the end of the args list.\n", "patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,9 @@ def settings_to_cmd_args_env(cls, settings_dict, parameters):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n+        args.extend(parameters)\n         if dbname:\n             args += [dbname]\n-        args.extend(parameters)\n \n         env = {}\n         if passwd:\n"}}
{"instance_id": "django__django-11797", "found_files": ["django/db/models/sql/query.py", "django/db/models/sql/compiler.py", "django/db/models/query.py", "django/db/models/expressions.py"], "found_modules": ["django/db/models/sql/query.py:Query", "django/db/models/sql/compiler.py:SQLCompiler", "django/db/models/query.py:QuerySet", "django/db/models/expressions.py:Subquery"], "found_entities": ["django/db/models/sql/compiler.py:SQLCompiler.as_sql", "django/db/models/sql/query.py:Query.clone", "django/db/models/expressions.py:Subquery.get_group_by_cols", "django/db/models/query.py:QuerySet._filter_or_exclude", "django/db/models/sql/compiler.py:SQLCompiler.pre_sql_setup", "django/db/models/sql/query.py:Query.build_filter", "django/db/models/sql/query.py:Query.set_group_by", "django/db/models/query.py:QuerySet.annotate"], "raw_output_loc": ["```\ndjango/db/models/sql/compiler.py:SQLCompiler.as_sql\nline: 480\nfunction: SQLCompiler.pre_sql_setup\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ndjango/db/models/expressions.py:Subquery\nline: 1068\nfunction: Subquery.get_group_by_cols\n\ndjango/db/models/sql/query.py:Query.set_group_by\nline: 1911\nfunction: Query.set_group_by\n\ndjango/db/models/query.py:QuerySet.annotate\nline: 1076\nfunction: QuerySet.annotate\n```", "```\ndjango/db/models/sql/query.py\nline: 292\nfunction: Query.clone\n\nThis is the key location where the GROUP BY state is lost during query cloning. The clone() method needs to be modified to properly copy the group_by attribute to preserve the GROUP BY clause when filtering annotated queries.\n\nAdditional supporting locations that need to be considered for a complete fix:\n\ndjango/db/models/query.py\nline: 914\nfunction: QuerySet._filter_or_exclude\n\nThis is where the query cloning originates during filtering operations.\n\ndjango/db/models/sql/query.py\nline: 1199\nfunction: Query.build_filter\n\nThis method should also be reviewed to ensure it properly handles GROUP BY clauses when building filter conditions.\n```"], "meta_data": {"repo": "django/django", "base_commit": "3346b78a8a872286a245d1e77ef4718fc5e6be1a", "problem_statement": "Filtering on query result overrides GROUP BY of internal query\nDescription\n\t\nfrom django.contrib.auth import models\na = models.User.objects.filter(email__isnull=True).values('email').annotate(m=Max('id')).values('m')\nprint(a.query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\"\nprint(a[:1].query) # good\n# SELECT MAX(\"auth_user\".\"id\") AS \"m\" FROM \"auth_user\" WHERE \"auth_user\".\"email\" IS NULL GROUP BY \"auth_user\".\"email\" LIMIT 1\nb = models.User.objects.filter(id=a[:1])\nprint(b.query) # GROUP BY U0.\"id\" should be GROUP BY U0.\"email\"\n# SELECT ... FROM \"auth_user\" WHERE \"auth_user\".\"id\" = (SELECT U0.\"id\" FROM \"auth_user\" U0 WHERE U0.\"email\" IS NULL GROUP BY U0.\"id\" LIMIT 1)\n", "patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -262,9 +262,9 @@ def process_rhs(self, compiler, connection):\n         from django.db.models.sql.query import Query\n         if isinstance(self.rhs, Query):\n             if self.rhs.has_limit_one():\n-                # The subquery must select only the pk.\n-                self.rhs.clear_select_clause()\n-                self.rhs.add_fields(['pk'])\n+                if not self.rhs.has_select_fields:\n+                    self.rhs.clear_select_clause()\n+                    self.rhs.add_fields(['pk'])\n             else:\n                 raise ValueError(\n                     'The QuerySet value for an exact lookup must be limited to '\n"}}
{"instance_id": "django__django-15790", "found_files": ["django/core/checks/templates.py"], "found_modules": ["django/core/checks/templates.py:check_for_template_tags_with_the_same_name"], "found_entities": ["django/core/checks/templates.py:check_for_template_tags_with_the_same_name"], "raw_output_loc": ["```\ndjango/core/checks/templates.py\nline: 51\nfunction: check_for_template_tags_with_the_same_name\n\n```", "```\ndjango/core/checks/templates.py\nline: 51\nfunction: check_for_template_tags_with_the_same_name\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "c627226d05dd52aef59447dcfb29cec2c2b11b8a", "problem_statement": "check_for_template_tags_with_the_same_name with libraries in TEMPLATES\nDescription\n\t\nI didn't explore this thoroughly, but I think there might be an issue with the check_for_template_tags_with_the_same_name when you add a template tag library into TEMPLATES['OPTIONS']['librairies'].\nI'm getting an error like: \n(templates.E003) 'my_tags' is used for multiple template tag modules: 'someapp.templatetags.my_tags', 'someapp.templatetags.my_tags'\n", "patch": "diff --git a/django/core/checks/templates.py b/django/core/checks/templates.py\n--- a/django/core/checks/templates.py\n+++ b/django/core/checks/templates.py\n@@ -50,15 +50,15 @@ def check_string_if_invalid_is_string(app_configs, **kwargs):\n @register(Tags.templates)\n def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n     errors = []\n-    libraries = defaultdict(list)\n+    libraries = defaultdict(set)\n \n     for conf in settings.TEMPLATES:\n         custom_libraries = conf.get(\"OPTIONS\", {}).get(\"libraries\", {})\n         for module_name, module_path in custom_libraries.items():\n-            libraries[module_name].append(module_path)\n+            libraries[module_name].add(module_path)\n \n     for module_name, module_path in get_template_tag_modules():\n-        libraries[module_name].append(module_path)\n+        libraries[module_name].add(module_path)\n \n     for library_name, items in libraries.items():\n         if len(items) > 1:\n@@ -66,7 +66,7 @@ def check_for_template_tags_with_the_same_name(app_configs, **kwargs):\n                 Error(\n                     E003.msg.format(\n                         repr(library_name),\n-                        \", \".join(repr(item) for item in items),\n+                        \", \".join(repr(item) for item in sorted(items)),\n                     ),\n                     id=E003.id,\n                 )\n"}}
{"instance_id": "matplotlib__matplotlib-23299", "found_files": ["lib/matplotlib/pyplot.py", "lib/matplotlib/__init__.py", "lib/matplotlib/_pylab_helpers.py"], "found_modules": ["lib/matplotlib/pyplot.py:switch_backend", "lib/matplotlib/__init__.py:get_backend", "lib/matplotlib/pyplot.py:close", "lib/matplotlib/_pylab_helpers.py:Gcf", "lib/matplotlib/__init__.py:rc_context"], "found_entities": ["lib/matplotlib/pyplot.py:switch_backend", "lib/matplotlib/__init__.py:get_backend", "lib/matplotlib/pyplot.py:close", "lib/matplotlib/_pylab_helpers.py:Gcf.destroy_all", "lib/matplotlib/__init__.py:rc_context"], "raw_output_loc": ["```\nlib/matplotlib/pyplot.py:switch_backend\nline: 225\nfunction: switch_backend\n\nlib/matplotlib/pyplot.py:close\nline: 941\nfunction: close\n\nlib/matplotlib/_pylab_helpers.py:Gcf\nline: 90\nfunction: Gcf.destroy_all\n\nlib/matplotlib/__init__.py:get_backend\nline: 1178\nfunction: get_backend\n\nlib/matplotlib/__init__.py:rc_context\nline: 1096\nfunction: rc_context\n```", "```\nlib/matplotlib/__init__.py:get_backend\nline: 1178\nfunction: get_backend\n\nlib/matplotlib/pyplot.py:switch_backend\nline: 222\nline: 225\nfunction: switch_backend\n\nlib/matplotlib/pyplot.py:close\nline: 941\nfunction: close\n\nlib/matplotlib/_pylab_helpers.py:Gcf.destroy_all\nline: 88\nfunction: Gcf.destroy_all\n\nlib/matplotlib/__init__.py:rc_context\nline: 1090\nline: 1098\nfunction: rc_context\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "3eadeacc06c9f2ddcdac6ae39819faa9fbee9e39", "problem_statement": "[Bug]: get_backend() clears figures from Gcf.figs if they were created under rc_context\n### Bug summary\r\n\r\ncalling `matplotlib.get_backend()` removes all figures from `Gcf` if the *first* figure in `Gcf.figs` was created in an `rc_context`.\r\n\r\n### Code for reproduction\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib import get_backend, rc_context\r\n\r\n# fig1 = plt.figure()  # <- UNCOMMENT THIS LINE AND IT WILL WORK\r\n# plt.ion()            # <- ALTERNATIVELY, UNCOMMENT THIS LINE AND IT WILL ALSO WORK\r\nwith rc_context():\r\n    fig2 = plt.figure()\r\nbefore = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\r\nget_backend()\r\nafter = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\r\n\r\nassert before == after, '\\n' + before + '\\n' + after\r\n```\r\n\r\n\r\n### Actual outcome\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-1-fa4d099aa289> in <cell line: 11>()\r\n      9 after = f'{id(plt._pylab_helpers.Gcf)} {plt._pylab_helpers.Gcf.figs!r}'\r\n     10 \r\n---> 11 assert before == after, '\\n' + before + '\\n' + after\r\n     12 \r\n\r\nAssertionError: \r\n94453354309744 OrderedDict([(1, <matplotlib.backends.backend_qt.FigureManagerQT object at 0x7fb33e26c220>)])\r\n94453354309744 OrderedDict()\r\n```\r\n\r\n### Expected outcome\r\n\r\nThe figure should not be missing from `Gcf`.  Consequences of this are, e.g, `plt.close(fig2)` doesn't work because `Gcf.destroy_fig()` can't find it.\r\n\r\n### Additional information\r\n\r\n_No response_\r\n\r\n### Operating system\r\n\r\nXubuntu\r\n\r\n### Matplotlib Version\r\n\r\n3.5.2\r\n\r\n### Matplotlib Backend\r\n\r\nQtAgg\r\n\r\n### Python version\r\n\r\nPython 3.10.4\r\n\r\n### Jupyter version\r\n\r\nn/a\r\n\r\n### Installation\r\n\r\nconda\n", "patch": "diff --git a/lib/matplotlib/__init__.py b/lib/matplotlib/__init__.py\n--- a/lib/matplotlib/__init__.py\n+++ b/lib/matplotlib/__init__.py\n@@ -1059,6 +1059,8 @@ def rc_context(rc=None, fname=None):\n     \"\"\"\n     Return a context manager for temporarily changing rcParams.\n \n+    The :rc:`backend` will not be reset by the context manager.\n+\n     Parameters\n     ----------\n     rc : dict\n@@ -1087,7 +1089,8 @@ def rc_context(rc=None, fname=None):\n              plt.plot(x, y)  # uses 'print.rc'\n \n     \"\"\"\n-    orig = rcParams.copy()\n+    orig = dict(rcParams.copy())\n+    del orig['backend']\n     try:\n         if fname:\n             rc_file(fname)\n"}}
{"instance_id": "django__django-14855", "found_files": ["django/contrib/admin/helpers.py", "django/contrib/admin/options.py"], "found_modules": ["django/contrib/admin/helpers.py:AdminReadonlyField", "django/contrib/admin/options.py:ModelAdmin"], "found_entities": ["django/contrib/admin/helpers.py:AdminReadonlyField.get_admin_url", "django/contrib/admin/options.py:ModelAdmin.response_add"], "raw_output_loc": ["```\ndjango/contrib/admin/helpers.py\nline: 206\nclass: AdminReadonlyField\nfunction: AdminReadonlyField.get_admin_url\n\ndjango/contrib/admin/options.py\nline: 1191\nclass: ModelAdmin\nfunction: ModelAdmin.response_add\n```", "```\ndjango/contrib/admin/helpers.py\nline: 206\nclass: AdminReadonlyField\nfunction: AdminReadonlyField.get_admin_url\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "475cffd1d64c690cdad16ede4d5e81985738ceb4", "problem_statement": "Wrong URL generated by get_admin_url for readonly field in custom Admin Site\nDescription\n\t\nWhen a model containing a ForeignKey field is viewed (or edited) in a custom Admin Site, and that ForeignKey field is listed in readonly_fields, the url generated for the link is /admin/... instead of /custom-admin/....\nThis appears to be caused by the following line in django.contrib.admin.helpers get_admin_url:\nurl = reverse(url_name, args=[quote(remote_obj.pk)])\nOther parts of the admin use the current_app keyword parameter to identify the correct current name of the Admin Site. (See django.contrib.admin.options.ModelAdmin response_add as just one example)\nI have been able to correct this specific issue by replacing the above line with:\nurl = reverse(\n\turl_name,\n\targs=[quote(remote_obj.pk)],\n\tcurrent_app=self.model_admin.admin_site.name\n)\nHowever, I don't know if there are any side effects and I have not yet run the full suite of tests on this. Mostly looking for feedback whether I'm on the right track.\n", "patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,11 @@ def get_admin_url(self, remote_field, remote_obj):\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(\n+                url_name,\n+                args=[quote(remote_obj.pk)],\n+                current_app=self.model_admin.admin_site.name,\n+            )\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n"}}
{"instance_id": "django__django-11905", "found_files": ["django/db/models/lookups.py", "django/contrib/admin/utils.py"], "found_modules": ["django/db/models/lookups.py:IsNull", "django/contrib/admin/utils.py:prepare_lookup_value"], "found_entities": ["django/db/models/lookups.py:IsNull.as_sql", "django/contrib/admin/utils.py:prepare_lookup_value"], "raw_output_loc": ["```\ndjango/db/models/lookups.py\nline: 460\nline: 461\nline: 462\nline: 463\nline: 464\nline: 465\nline: 466\nline: 467\nline: 468\nline: 469\nline: 470\nline: 471\nclass: IsNull\nfunction: IsNull.as_sql\n```", "```\ndjango/contrib/admin/utils.py\nline: 60\nfunction: prepare_lookup_value\n```"], "meta_data": {"repo": "django/django", "base_commit": "2f72480fbd27896c986c45193e1603e35c0b19a7", "problem_statement": "Prevent using __isnull lookup with non-boolean value.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \n__isnull should not allow for non-boolean values. Using truthy/falsey doesn't promote INNER JOIN to an OUTER JOIN but works fine for a simple queries. Using non-boolean values is \u200bundocumented and untested. IMO we should raise an error for non-boolean values to avoid confusion and for consistency.\n", "patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -1,5 +1,6 @@\n import itertools\n import math\n+import warnings\n from copy import copy\n \n from django.core.exceptions import EmptyResultSet\n@@ -9,6 +10,7 @@\n )\n from django.db.models.query_utils import RegisterLookupMixin\n from django.utils.datastructures import OrderedSet\n+from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import cached_property\n \n \n@@ -463,6 +465,17 @@ class IsNull(BuiltinLookup):\n     prepare_rhs = False\n \n     def as_sql(self, compiler, connection):\n+        if not isinstance(self.rhs, bool):\n+            # When the deprecation ends, replace with:\n+            # raise ValueError(\n+            #     'The QuerySet value for an isnull lookup must be True or '\n+            #     'False.'\n+            # )\n+            warnings.warn(\n+                'Using a non-boolean value for an isnull lookup is '\n+                'deprecated, use True or False instead.',\n+                RemovedInDjango40Warning,\n+            )\n         sql, params = compiler.compile(self.lhs)\n         if self.rhs:\n             return \"%s IS NULL\" % sql, params\n"}}
{"instance_id": "pylint-dev__pylint-7114", "found_files": ["pylint/lint/pylinter.py", "pylint/config/config_initialization.py", "pylint/config/config_file_parser.py", "pylint/checkers/variables.py", "pylint/config/arguments_manager.py"], "found_modules": ["pylint/lint/pylinter.py:PyLinter", "pylint/config/config_initialization.py:_config_initialization", "pylint/config/config_file_parser.py:_ConfigurationFileParser", "pylint/checkers/variables.py:VariablesChecker", "pylint/config/arguments_manager.py:_ArgumentsManager"], "found_entities": ["pylint/lint/pylinter.py:PyLinter.check_single_file_item", "pylint/config/config_initialization.py:_config_initialization", "pylint/lint/pylinter.py:PyLinter._check_file", "pylint/config/config_file_parser.py:_ConfigurationFileParser.parse_config_file", "pylint/lint/pylinter.py:PyLinter._astroid_module_checker", "pylint/checkers/variables.py:VariablesChecker._check_module_attrs", "pylint/lint/pylinter.py:PyLinter.get_ast", "pylint/lint/pylinter.py:PyLinter.set_current_module", "pylint/lint/pylinter.py:PyLinter.check_astroid_module", "pylint/config/arguments_manager.py:_ArgumentsManager._parse_configuration_file"], "raw_output_loc": ["```\npylint/lint/pylinter.py\nline: 678\nfunction: PyLinter.check_single_file_item\n\npylint/lint/pylinter.py\nline: 679\nfunction: PyLinter._check_file\n\npylint/lint/pylinter.py\nline: 678\nfunction: PyLinter._astroid_module_checker\n\npylint/lint/pylinter.py\nline: 678\nfunction: PyLinter.get_ast\n\npylint/lint/pylinter.py\nline: 678\nfunction: PyLinter.check_astroid_module\n```", "```\npylint/config/config_initialization.py:_config_initialization\nline: 36-41\nfunction: _config_initialization\n\npylint/config/config_file_parser.py:_ConfigurationFileParser.parse_config_file\nline: 100-124\nfunction: _ConfigurationFileParser.parse_config_file\n\npylint/lint/pylinter.py:PyLinter.set_current_module\nline: 34\nfunction: PyLinter.set_current_module\n\npylint/checkers/variables.py:VariablesChecker._check_module_attrs\nline: 2622-2652\nfunction: VariablesChecker._check_module_attrs\n\npylint/config/arguments_manager.py:_ArgumentsManager._parse_configuration_file\nline: 57\nfunction: _ArgumentsManager._parse_configuration_file\n```"], "meta_data": {"repo": "pylint-dev/pylint", "base_commit": "397c1703e8ae6349d33f7b99f45b2ccaf581e666", "problem_statement": "Linting fails if module contains module of the same name\n### Steps to reproduce\r\n\r\nGiven multiple files:\r\n```\r\n.\r\n`-- a/\r\n    |-- a.py\r\n    `-- b.py\r\n```\r\nWhich are all empty, running `pylint a` fails:\r\n\r\n```\r\n$ pylint a\r\n************* Module a\r\na/__init__.py:1:0: F0010: error while code parsing: Unable to load file a/__init__.py:\r\n[Errno 2] No such file or directory: 'a/__init__.py' (parse-error)\r\n$\r\n```\r\n\r\nHowever, if I rename `a.py`, `pylint a` succeeds:\r\n\r\n```\r\n$ mv a/a.py a/c.py\r\n$ pylint a\r\n$\r\n```\r\nAlternatively, I can also `touch a/__init__.py`, but that shouldn't be necessary anymore.\r\n\r\n### Current behavior\r\n\r\nRunning `pylint a` if `a/a.py` is present fails while searching for an `__init__.py` file.\r\n\r\n### Expected behavior\r\n\r\nRunning `pylint a` if `a/a.py` is present should succeed.\r\n\r\n### pylint --version output\r\n\r\nResult of `pylint --version` output:\r\n\r\n```\r\npylint 3.0.0a3\r\nastroid 2.5.6\r\nPython 3.8.5 (default, Jan 27 2021, 15:41:15) \r\n[GCC 9.3.0]\r\n```\r\n\r\n### Additional info\r\n\r\nThis also has some side-effects in module resolution. For example, if I create another file `r.py`:\r\n\r\n```\r\n.\r\n|-- a\r\n|   |-- a.py\r\n|   `-- b.py\r\n`-- r.py\r\n```\r\n\r\nWith the content:\r\n\r\n```\r\nfrom a import b\r\n```\r\n\r\nRunning `pylint -E r` will run fine, but `pylint -E r a` will fail. Not just for module a, but for module r as well.\r\n\r\n```\r\n************* Module r\r\nr.py:1:0: E0611: No name 'b' in module 'a' (no-name-in-module)\r\n************* Module a\r\na/__init__.py:1:0: F0010: error while code parsing: Unable to load file a/__init__.py:\r\n[Errno 2] No such file or directory: 'a/__init__.py' (parse-error)\r\n```\r\n\r\nAgain, if I rename `a.py` to `c.py`, `pylint -E r a` will work perfectly.\n", "patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -82,8 +82,10 @@ def expand_modules(\n             continue\n         module_path = get_python_path(something)\n         additional_search_path = [\".\", module_path] + path\n-        if os.path.exists(something):\n-            # this is a file or a directory\n+        if os.path.isfile(something) or os.path.exists(\n+            os.path.join(something, \"__init__.py\")\n+        ):\n+            # this is a file or a directory with an explicit __init__.py\n             try:\n                 modname = \".\".join(\n                     modutils.modpath_from_file(something, path=additional_search_path)\n@@ -103,9 +105,7 @@ def expand_modules(\n                 )\n                 if filepath is None:\n                     continue\n-            except (ImportError, SyntaxError) as ex:\n-                # The SyntaxError is a Python bug and should be\n-                # removed once we move away from imp.find_module: https://bugs.python.org/issue10588\n+            except ImportError as ex:\n                 errors.append({\"key\": \"fatal\", \"mod\": modname, \"ex\": ex})\n                 continue\n         filepath = os.path.normpath(filepath)\n"}}
{"instance_id": "django__django-16046", "found_files": ["django/utils/numberformat.py", "django/contrib/admin/utils.py"], "found_modules": ["django/utils/numberformat.py:format", "django/contrib/admin/utils.py:display_for_field", "django/contrib/admin/utils.py:display_for_value"], "found_entities": ["django/utils/numberformat.py:format", "django/contrib/admin/utils.py:display_for_field", "django/contrib/admin/utils.py:display_for_value"], "raw_output_loc": ["```\ndjango/utils/numberformat.py\nline: 71\nfunction: format\n\ncore/utils/formats.py\nline: 188\nfunction: number_format\n\ndjango/contrib/admin/utils.py\nline: 426\nfunction: display_for_field\nline: 452\nfunction: display_for_value\n```", "```\ndjango/utils/numberformat.py\nline: 71\nfunction: format\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "ec13e801b820614ff374cb0046092caab8d67249", "problem_statement": "Fix numberformat.py \"string index out of range\" when null\nDescription\n\t\nWhen:\nif str_number[0] == \"-\"\nencounters a number field that's null when formatting for the admin list_display this causes an \nIndexError: string index out of range\nI can attach the proposed fix here, or open a pull request on GitHub if you like?\n", "patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -25,6 +25,8 @@ def format(\n         module in locale.localeconv() LC_NUMERIC grouping (e.g. (3, 2, 0)).\n     * thousand_sep: Thousand separator symbol (for example \",\")\n     \"\"\"\n+    if number is None or number == \"\":\n+        return mark_safe(number)\n     use_grouping = (\n         use_l10n or (use_l10n is None and settings.USE_L10N)\n     ) and settings.USE_THOUSAND_SEPARATOR\n"}}
{"instance_id": "sympy__sympy-16792", "found_files": ["sympy/utilities/codegen.py", "sympy/utilities/autowrap.py"], "found_modules": ["sympy/utilities/codegen.py:CodeGen", "sympy/utilities/autowrap.py:CythonCodeWrapper", "sympy/utilities/codegen.py:CCodeGen", "sympy/utilities/codegen.py:Argument", "sympy/utilities/codegen.py:InputArgument", "sympy/utilities/codegen.py:OutputArgument"], "found_entities": ["sympy/utilities/codegen.py:CodeGen.routine", "sympy/utilities/autowrap.py:CythonCodeWrapper.dump_pyx", "sympy/utilities/codegen.py:CCodeGen.get_prototype"], "raw_output_loc": ["```\nsympy/utilities/codegen.py:CodeGen.routine\nline: 656\nline: 706\nline: 710\nfunction: CodeGen.routine\n\nsympy/utilities/autowrap.py:CythonCodeWrapper.dump_pyx\nline: 364\nfunction: CythonCodeWrapper.dump_pyx\n\nsympy/utilities/codegen.py:Argument\nline: 373\nline: 396\nline: 442\nfunction: Argument\n\nsympy/utilities/codegen.py:InputArgument\nline: 373\nfunction: InputArgument\n\nsympy/utilities/codegen.py:OutputArgument\nline: 396\nfunction: OutputArgument\n```", "```\nsympy/utilities/codegen.py\nline: 913\nfunction: CCodeGen.get_prototype\n\nsympy/utilities/autowrap.py\nline: 346\nfunction: CythonCodeWrapper.dump_pyx\n\nsympy/utilities/codegen.py\nline: 396\nclass: OutputArgument\n\nsympy/utilities/codegen.py\nline: 442\nclass: InOutArgument\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "09786a173e7a0a488f46dd6000177c23e5d24eed", "problem_statement": "autowrap with cython backend fails when array arguments do not appear in wrapped expr\nWhen using the cython backend for autowrap, it appears that the code is not correctly generated when the function in question has array arguments that do not appear in the final expression. A minimal counterexample is:\r\n\r\n```python\r\nfrom sympy.utilities.autowrap import autowrap\r\nfrom sympy import MatrixSymbol\r\nimport numpy as np\r\n\r\nx = MatrixSymbol('x', 2, 1)\r\nexpr = 1.0\r\nf = autowrap(expr, args=(x,), backend='cython')\r\n\r\nf(np.array([[1.0, 2.0]]))\r\n```\r\n\r\nThis should of course return `1.0` but instead fails with:\r\n```python\r\nTypeError: only size-1 arrays can be converted to Python scalars\r\n```\r\n\r\nA little inspection reveals that this is because the corresponding C function is generated with an incorrect signature:\r\n\r\n```C\r\ndouble autofunc(double x) {\r\n\r\n   double autofunc_result;\r\n   autofunc_result = 1.0;\r\n   return autofunc_result;\r\n\r\n}\r\n```\r\n\r\n(`x` should be `double *`, not `double` in this case)\r\n\r\nI've found that this error won't occur so long as `expr` depends at least in part on each argument. For example this slight modification of the above counterexample works perfectly:\r\n\r\n```python\r\nfrom sympy.utilities.autowrap import autowrap\r\nfrom sympy import MatrixSymbol\r\nimport numpy as np\r\n\r\nx = MatrixSymbol('x', 2, 1)\r\n# now output depends on x\r\nexpr = x[0,0]\r\nf = autowrap(expr, args=(x,), backend='cython')\r\n\r\n# returns 1.0 as expected, without failure\r\nf(np.array([[1.0, 2.0]]))\r\n```\r\n\r\nThis may seem like a silly issue (\"why even have `x` as an argument if it doesn't appear in the expression you're trying to evaluate?\"). But of course in interfacing with external libraries (e.g. for numerical integration), one often needs functions to have a pre-defined signature regardless of whether a given argument contributes to the output.\r\n\r\nI think I've identified the problem in `codegen` and will suggest a PR shortly.\n", "patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -695,6 +695,11 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n         arg_list = []\n \n         # setup input argument list\n+\n+        # helper to get dimensions for data for array-like args\n+        def dimensions(s):\n+            return [(S.Zero, dim - 1) for dim in s.shape]\n+\n         array_symbols = {}\n         for array in expressions.atoms(Indexed) | local_expressions.atoms(Indexed):\n             array_symbols[array.base.label] = array\n@@ -703,11 +708,8 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n \n         for symbol in sorted(symbols, key=str):\n             if symbol in array_symbols:\n-                dims = []\n                 array = array_symbols[symbol]\n-                for dim in array.shape:\n-                    dims.append((S.Zero, dim - 1))\n-                metadata = {'dimensions': dims}\n+                metadata = {'dimensions': dimensions(array)}\n             else:\n                 metadata = {}\n \n@@ -739,7 +741,11 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n                 try:\n                     new_args.append(name_arg_dict[symbol])\n                 except KeyError:\n-                    new_args.append(InputArgument(symbol))\n+                    if isinstance(symbol, (IndexedBase, MatrixSymbol)):\n+                        metadata = {'dimensions': dimensions(symbol)}\n+                    else:\n+                        metadata = {}\n+                    new_args.append(InputArgument(symbol, **metadata))\n             arg_list = new_args\n \n         return Routine(name, arg_list, return_val, local_vars, global_vars)\n"}}
{"instance_id": "sympy__sympy-14817", "found_files": ["sympy/printing/pretty/pretty.py", "sympy/core/sympify.py", "sympy/matrices/expressions/matexpr.py", "sympy/matrices/expressions/matadd.py", "sympy/printing/pretty/stringpict.py"], "found_modules": ["sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/core/sympify.py:sympify", "sympy/matrices/expressions/matexpr.py:MatrixSymbol", "sympy/matrices/expressions/matadd.py:MatAdd", "sympy/printing/pretty/stringpict.py:prettyForm"], "found_entities": ["sympy/printing/pretty/pretty.py:PrettyPrinter._print_MatAdd", "sympy/core/sympify.py:sympify", "sympy/matrices/expressions/matexpr.py:MatrixSymbol.__new__", "sympy/matrices/expressions/matadd.py:MatAdd.__new__"], "raw_output_loc": ["```\nsympy/printing/pretty/pretty.py\nline: 828\nclass: PrettyPrinter\nfunction: PrettyPrinter._print_MatAdd\n\nsympy/core/sympify.py\nline: 370\nfunction: sympify\n\nsympy/matrices/expressions/matexpr.py\nline: 661\nclass: MatrixSymbol\nfunction: MatrixSymbol.__new__\n\nsympy/matrices/expressions/matadd.py\nline: 31\nclass: MatAdd\nfunction: MatAdd.__new__\n\nsympy/printing/pretty/stringpict.py\nline: 829\nfunction: prettyForm\n```", "```\nsympy/printing/pretty/pretty.py\nline: 828\nclass: PrettyPrinter\nfunction: PrettyPrinter._print_MatAdd\n\nsympy/core/sympify.py\nline: 370\nfunction: sympify\n\nsympy/matrices/expressions/matexpr.py\nline: 660\nclass: MatrixSymbol\nfunction: MatrixSymbol.__new__\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "0dbdc0ea83d339936da175f8c3a97d0d6bafb9f8", "problem_statement": "Error pretty printing MatAdd\n```py\r\n>>> pprint(MatrixSymbol('x', n, n) + MatrixSymbol('y*', n, n))\r\nTraceback (most recent call last):\r\n  File \"./sympy/core/sympify.py\", line 368, in sympify\r\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\r\n  File \"./sympy/parsing/sympy_parser.py\", line 950, in parse_expr\r\n    return eval_expr(code, local_dict, global_dict)\r\n  File \"./sympy/parsing/sympy_parser.py\", line 863, in eval_expr\r\n    code, global_dict, local_dict)  # take local objects in preference\r\n  File \"<string>\", line 1\r\n    Symbol ('y' )*\r\n                 ^\r\nSyntaxError: unexpected EOF while parsing\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"./sympy/printing/pretty/pretty.py\", line 2371, in pretty_print\r\n    use_unicode_sqrt_char=use_unicode_sqrt_char))\r\n  File \"./sympy/printing/pretty/pretty.py\", line 2331, in pretty\r\n    return pp.doprint(expr)\r\n  File \"./sympy/printing/pretty/pretty.py\", line 62, in doprint\r\n    return self._print(expr).render(**self._settings)\r\n  File \"./sympy/printing/printer.py\", line 274, in _print\r\n    return getattr(self, printmethod)(expr, *args, **kwargs)\r\n  File \"./sympy/printing/pretty/pretty.py\", line 828, in _print_MatAdd\r\n    if S(item.args[0]).is_negative:\r\n  File \"./sympy/core/sympify.py\", line 370, in sympify\r\n    raise SympifyError('could not parse %r' % a, exc)\r\nsympy.core.sympify.SympifyError: Sympify of expression 'could not parse 'y*'' failed, because of exception being raised:\r\nSyntaxError: unexpected EOF while parsing (<string>, line 1)\r\n```\r\n\r\nThe code shouldn't be using sympify to handle string arguments from MatrixSymbol.\r\n\r\nI don't even understand what the code is doing. Why does it omit the `+` when the first argument is negative? This seems to assume that the arguments of MatAdd have a certain form, and that they will always print a certain way if they are negative. \n", "patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -825,7 +825,8 @@ def _print_MatAdd(self, expr):\n             if s is None:\n                 s = pform     # First element\n             else:\n-                if S(item.args[0]).is_negative:\n+                coeff = item.as_coeff_mmul()[0]\n+                if _coeff_isneg(S(coeff)):\n                     s = prettyForm(*stringPict.next(s, ' '))\n                     pform = self._print(item)\n                 else:\n"}}
{"instance_id": "sympy__sympy-13043", "found_files": ["sympy/integrals/intpoly.py"], "found_modules": ["sympy/integrals/intpoly.py:decompose", "sympy/integrals/intpoly.py:polytope_integrate"], "found_entities": ["sympy/integrals/intpoly.py:decompose", "sympy/integrals/intpoly.py:polytope_integrate"], "raw_output_loc": ["```\nsympy/integrals/intpoly.py\nline: 596\nfunction: decompose\n\nsympy/integrals/intpoly.py\nline: 86\nfunction: polytope_integrate\n```", "```\nsympy/integrals/intpoly.py\nline: 596\nfunction: decompose\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "a3389a25ec84d36f5cf04a4f2562d820f131db64", "problem_statement": "decompose() function in intpoly returns a list of arbitrary order\nThe decompose() function, with separate=True, returns `list(poly_dict.values())`, which is ordered arbitrarily.  \r\n\r\nWhat is this used for? It should be sorted somehow, or returning a set (in which case, why not just use the returned dictionary and have the caller take the values). This is causing test failures for me after some changes to the core. \r\n\r\nCC @ArifAhmed1995 @certik \n", "patch": "diff --git a/sympy/integrals/intpoly.py b/sympy/integrals/intpoly.py\n--- a/sympy/integrals/intpoly.py\n+++ b/sympy/integrals/intpoly.py\n@@ -556,7 +556,7 @@ def decompose(expr, separate=False):\n     >>> decompose(x**2 + x*y + x + y + x**3*y**2 + y**5)\n     {1: x + y, 2: x**2 + x*y, 5: x**3*y**2 + y**5}\n     >>> decompose(x**2 + x*y + x + y + x**3*y**2 + y**5, True)\n-    [x, y, x**2, y**5, x*y, x**3*y**2]\n+    {x, x**2, y, y**5, x*y, x**3*y**2}\n     \"\"\"\n     expr = S(expr)\n     poly_dict = {}\n@@ -569,7 +569,7 @@ def decompose(expr, separate=False):\n             degrees = [(sum(degree_list(monom, *symbols)), monom)\n                        for monom in expr.args]\n             if separate:\n-                return [monom[1] for monom in degrees]\n+                return {monom[1] for monom in degrees}\n             else:\n                 for monom in degrees:\n                     degree, term = monom\n@@ -593,7 +593,7 @@ def decompose(expr, separate=False):\n         poly_dict[0] = expr\n \n     if separate:\n-        return list(poly_dict.values())\n+        return set(poly_dict.values())\n     return poly_dict\n \n \n"}}
{"instance_id": "pytest-dev__pytest-11143", "found_files": ["src/_pytest/assertion/rewrite.py"], "found_modules": ["src/_pytest/assertion/rewrite.py:AssertionRewriter", "src/_pytest/assertion/rewrite.py:_rewrite_test", "src/_pytest/assertion/rewrite.py:rewrite_asserts"], "found_entities": ["src/_pytest/assertion/rewrite.py:AssertionRewriter.is_rewrite_disabled", "src/_pytest/assertion/rewrite.py:AssertionRewriter.run", "src/_pytest/assertion/rewrite.py:_rewrite_test", "src/_pytest/assertion/rewrite.py:rewrite_asserts"], "raw_output_loc": ["```\nsrc/_pytest/assertion/rewrite.py\nline: 745\nclass: AssertionRewriter\nfunction: AssertionRewriter.is_rewrite_disabled\n\nsrc/_pytest/assertion/rewrite.py\nline: 660\nclass: AssertionRewriter\nfunction: AssertionRewriter.run\n```", "```\nsrc/_pytest/assertion/rewrite.py\nline: 668\nline: 669\nline: 670\nclass: AssertionRewriter\nfunction: AssertionRewriter.run\n\nsrc/_pytest/assertion/rewrite.py\nline: 745\nline: 746\nclass: AssertionRewriter\nfunction: AssertionRewriter.is_rewrite_disabled\n\nsrc/_pytest/assertion/rewrite.py\nline: 340\nline: 341\nfunction: _rewrite_test\n\nsrc/_pytest/assertion/rewrite.py\nline: 395\nline: 402\nfunction: rewrite_asserts\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "6995257cf470d2143ad1683824962de4071c0eb7", "problem_statement": "Rewrite fails when first expression of file is a number and mistaken as docstring \n<!--\r\nThanks for submitting an issue!\r\n\r\nQuick check-list while reporting bugs:\r\n-->\r\n\r\n- [x] a detailed description of the bug or problem you are having\r\n- [x] output of `pip list` from the virtual environment you are using\r\n- [x] pytest and operating system versions\r\n- [x] minimal example if possible\r\n```\r\nInstalling collected packages: zipp, six, PyYAML, python-dateutil, MarkupSafe, importlib-metadata, watchdog, tomli, soupsieve, pyyaml-env-tag, pycparser, pluggy, packaging, mergedeep, Markdown, jinja2, iniconfig, ghp-import, exceptiongroup, click, websockets, urllib3, tqdm, smmap, pytest, pyee, mkdocs, lxml, importlib-resources, idna, cssselect, charset-normalizer, cffi, certifi, beautifulsoup4, attrs, appdirs, w3lib, typing-extensions, texttable, requests, pyzstd, pytest-metadata, pyquery, pyppmd, pyppeteer, pynacl, pymdown-extensions, pycryptodomex, pybcj, pyasn1, py, psutil, parse, multivolumefile, mkdocs-autorefs, inflate64, gitdb, fake-useragent, cryptography, comtypes, bs4, brotli, bcrypt, allure-python-commons, xlwt, xlrd, rsa, requests-html, pywinauto, python-i18n, python-dotenv, pytest-rerunfailures, pytest-html, pytest-check, PySocks, py7zr, paramiko, mkdocstrings, loguru, GitPython, ftputil, crcmod, chardet, brotlicffi, allure-pytest\r\nSuccessfully installed GitPython-3.1.31 Markdown-3.3.7 MarkupSafe-2.1.3 PySocks-1.7.1 PyYAML-6.0 allure-pytest-2.13.2 allure-python-commons-2.13.2 appdirs-1.4.4 attrs-23.1.0 bcrypt-4.0.1 beautifulsoup4-4.12.2 brotli-1.0.9 brotlicffi-1.0.9.2 bs4-0.0.1 certifi-2023.5.7 cffi-1.15.1 chardet-5.1.0 charset-normalizer-3.1.0 click-8.1.3 comtypes-1.2.0 crcmod-1.7 cryptography-41.0.1 cssselect-1.2.0 exceptiongroup-1.1.1 fake-useragent-1.1.3 ftputil-5.0.4 ghp-import-2.1.0 gitdb-4.0.10 idna-3.4 importlib-metadata-6.7.0 importlib-resources-5.12.0 inflate64-0.3.1 iniconfig-2.0.0 jinja2-3.1.2 loguru-0.7.0 lxml-4.9.2 mergedeep-1.3.4 mkdocs-1.4.3 mkdocs-autorefs-0.4.1 mkdocstrings-0.22.0 multivolumefile-0.2.3 packaging-23.1 paramiko-3.2.0 parse-1.19.1 pluggy-1.2.0 psutil-5.9.5 py-1.11.0 py7zr-0.20.5 pyasn1-0.5.0 pybcj-1.0.1 pycparser-2.21 pycryptodomex-3.18.0 pyee-8.2.2 pymdown-extensions-10.0.1 pynacl-1.5.0 pyppeteer-1.0.2 pyppmd-1.0.0 pyquery-2.0.0 pytest-7.4.0 pytest-check-2.1.5 pytest-html-3.2.0 pytest-metadata-3.0.0 pytest-rerunfailures-11.1.2 python-dateutil-2.8.2 python-dotenv-1.0.0 python-i18n-0.3.9 pywinauto-0.6.6 pyyaml-env-tag-0.1 pyzstd-0.15.9 requests-2.31.0 requests-html-0.10.0 rsa-4.9 six-1.16.0 smmap-5.0.0 soupsieve-2.4.1 texttable-1.6.7 tomli-2.0.1 tqdm-4.65.0 typing-extensions-4.6.3 urllib3-1.26.16 w3lib-2.1.1 watchdog-3.0.0 websockets-10.4 xlrd-2.0.1 xlwt-1.3.0 zipp-3.15.0\r\n```\r\nuse `pytest -k xxx`\uff0c report an error\uff1a`TypeError: argument of type 'int' is not iterable`\r\n\r\nit seems a error in collecting testcase\r\n```\r\n==================================== ERRORS ====================================\r\n_ ERROR collecting testcases/\u57fa\u7ebf/\u4ee3\u7406\u7b56\u7565/SOCKS\u4e8c\u7ea7\u4ee3\u7406\u8fed\u4ee3\u4e8c/\u5728\u7ebf\u7528\u6237/\u5728\u7ebf\u7528\u6237\u66f4\u65b0/\u4e0a\u7ebf\u7528\u6237/test_socks_user_011.py _\r\n/usr/local/lib/python3.8/site-packages/_pytest/runner.py:341: in from_call\r\n    result: Optional[TResult] = func()\r\n/usr/local/lib/python3.8/site-packages/_pytest/runner.py:372: in <lambda>\r\n    call = CallInfo.from_call(lambda: list(collector.collect()), \"collect\")\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:531: in collect\r\n    self._inject_setup_module_fixture()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:545: in _inject_setup_module_fixture\r\n    self.obj, (\"setUpModule\", \"setup_module\")\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:310: in obj\r\n    self._obj = obj = self._getobj()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:528: in _getobj\r\n    return self._importtestmodule()\r\n/usr/local/lib/python3.8/site-packages/_pytest/python.py:617: in _importtestmodule\r\n    mod = import_path(self.path, mode=importmode, root=self.config.rootpath)\r\n/usr/local/lib/python3.8/site-packages/_pytest/pathlib.py:565: in import_path\r\n    importlib.import_module(module_name)\r\n/usr/local/lib/python3.8/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n<frozen importlib._bootstrap>:1014: in _gcd_import\r\n    ???\r\n<frozen importlib._bootstrap>:991: in _find_and_load\r\n    ???\r\n<frozen importlib._bootstrap>:975: in _find_and_load_unlocked\r\n    ???\r\n<frozen importlib._bootstrap>:671: in _load_unlocked\r\n    ???\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:169: in exec_module\r\n    source_stat, co = _rewrite_test(fn, self.config)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:352: in _rewrite_test\r\n    rewrite_asserts(tree, source, strfn, config)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:413: in rewrite_asserts\r\n    AssertionRewriter(module_path, config, source).run(mod)\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:695: in run\r\n    if self.is_rewrite_disabled(doc):\r\n/usr/local/lib/python3.8/site-packages/_pytest/assertion/rewrite.py:760: in is_rewrite_disabled\r\n    return \"PYTEST_DONT_REWRITE\" in docstring\r\nE   TypeError: argument of type 'int' is not iterable\r\n```\n", "patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -676,6 +676,7 @@ def run(self, mod: ast.Module) -> None:\n                 expect_docstring\n                 and isinstance(item, ast.Expr)\n                 and isinstance(item.value, ast.Constant)\n+                and isinstance(item.value.value, str)\n             ):\n                 doc = item.value.value\n                 if self.is_rewrite_disabled(doc):\n"}}
{"instance_id": "matplotlib__matplotlib-25433", "found_files": ["lib/matplotlib/widgets.py", "lib/matplotlib/backends/_backend_tk.py", "lib/matplotlib/pyplot.py", "lib/matplotlib/backend_bases.py"], "found_modules": ["lib/matplotlib/widgets.py:RangeSlider", "lib/matplotlib/backends/_backend_tk.py:FigureCanvasTk", "lib/matplotlib/pyplot.py:clf", "lib/matplotlib/backend_bases.py:FigureCanvasBase", "lib/matplotlib/pyplot.py:draw", "lib/matplotlib/widgets.py:Button"], "found_entities": ["lib/matplotlib/widgets.py:RangeSlider._update_val_from_pos", "lib/matplotlib/backends/_backend_tk.py:FigureCanvasTk.draw_idle", "lib/matplotlib/backend_bases.py:FigureCanvasBase.grab_mouse", "lib/matplotlib/widgets.py:RangeSlider.on_changed", "lib/matplotlib/pyplot.py:clf", "lib/matplotlib/pyplot.py:draw", "lib/matplotlib/backend_bases.py:FigureCanvasBase.release_mouse", "lib/matplotlib/widgets.py:Button.on_clicked"], "raw_output_loc": ["```\nlib/matplotlib/widgets.py:RangeSlider._update\nline: 852\nfunction: RangeSlider._update_val_from_pos\n\nlib/matplotlib/backend_bases.py:FigureCanvasBase.grab_mouse\nline: 2048\nfunction: FigureCanvasBase.grab_mouse\n\nlib/matplotlib/backend_bases.py:FigureCanvasBase.release_mouse\nline: 2059\nfunction: FigureCanvasBase.release_mouse\n\nlib/matplotlib/pyplot.py:clf\nline: 996\nfunction: clf\n\nlib/matplotlib/pyplot.py:draw\nline: 1016\nfunction: draw\n```", "```\nlib/matplotlib/backends/_backend_tk.py:FigureCanvasTk.draw_idle\nline: 1768\nfunction: FigureCanvasTk.draw_idle\n\nlib/matplotlib/widgets.py:RangeSlider.on_changed\nline: 971\nfunction: RangeSlider.on_changed\n\nlib/matplotlib/widgets.py:Button.on_clicked\nline: 243\nfunction: Button.on_clicked\n\nlib/matplotlib/pyplot.py:draw\nline: 999\nfunction: draw\n\nlib/matplotlib/pyplot.py:clf\nline: 994\nfunction: clf\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "7eafdd8af3c523c1c77b027d378fb337dd489f18", "problem_statement": "[Bug]: using clf and pyplot.draw in range slider on_changed callback blocks input to widgets\n### Bug summary\n\nWhen using clear figure, adding new widgets and then redrawing the current figure in the on_changed callback of a range slider the inputs to all the widgets in the figure are blocked. When doing the same in the button callback on_clicked, everything works fine.\n\n### Code for reproduction\n\n```python\nimport matplotlib.pyplot as pyplot\r\nimport matplotlib.widgets as widgets\r\n\r\ndef onchanged(values):\r\n    print(\"on changed\")\r\n    print(values)\r\n    pyplot.clf()\r\n    addElements()\r\n    pyplot.draw()\r\n\r\ndef onclick(e):\r\n    print(\"on click\")\r\n    pyplot.clf()\r\n    addElements()\r\n    pyplot.draw()\r\n\r\ndef addElements():\r\n    ax = pyplot.axes([0.1, 0.45, 0.8, 0.1])\r\n    global slider\r\n    slider = widgets.RangeSlider(ax, \"Test\", valmin=1, valmax=10, valinit=(1, 10))\r\n    slider.on_changed(onchanged)\r\n    ax = pyplot.axes([0.1, 0.30, 0.8, 0.1])\r\n    global button\r\n    button = widgets.Button(ax, \"Test\")\r\n    button.on_clicked(onclick)\r\n\r\naddElements()\r\n\r\npyplot.show()\n```\n\n\n### Actual outcome\n\nThe widgets can't receive any input from a mouse click, when redrawing in the on_changed callback of a range Slider. \r\nWhen using a button, there is no problem.\n\n### Expected outcome\n\nThe range slider callback on_changed behaves the same as the button callback on_clicked.\n\n### Additional information\n\nThe problem also occurred on Manjaro with:\r\n- Python version: 3.10.9\r\n- Matplotlib version: 3.6.2\r\n- Matplotlib backend: QtAgg\r\n- Installation of matplotlib via Linux package manager\r\n\n\n### Operating system\n\nWindows 10\n\n### Matplotlib Version\n\n3.6.2\n\n### Matplotlib Backend\n\nTkAgg\n\n### Python version\n\n3.11.0\n\n### Jupyter version\n\n_No response_\n\n### Installation\n\npip\n", "patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -931,6 +931,7 @@ def _break_share_link(ax, grouper):\n         self._axobservers.process(\"_axes_change_event\", self)\n         self.stale = True\n         self._localaxes.remove(ax)\n+        self.canvas.release_mouse(ax)\n \n         # Break link between any shared axes\n         for name in ax._axis_names:\n"}}
{"instance_id": "scikit-learn__scikit-learn-13241", "found_files": ["sklearn/decomposition/kernel_pca.py"], "found_modules": ["sklearn/decomposition/kernel_pca.py:KernelPCA"], "found_entities": ["sklearn/decomposition/kernel_pca.py:KernelPCA._fit_transform", "sklearn/decomposition/kernel_pca.py:KernelPCA.fit_transform", "sklearn/decomposition/kernel_pca.py:KernelPCA.fit"], "raw_output_loc": ["```\nsklearn/decomposition/kernel_pca.py\nline: 206\nline: 207\nline: 208\nline: 209\nline: 210\nfunction: KernelPCA._fit_transform\n\nsklearn/decomposition/kernel_pca.py\nline: 276\nline: 277\nline: 278\nfunction: KernelPCA.fit_transform\n\nsklearn/decomposition/kernel_pca.py\nline: 250\nline: 251\nline: 252\nline: 253\nfunction: KernelPCA.fit\n```", "```\nsklearn/decomposition/kernel_pca.py\nline: 214\nline: 215\nline: 216\nfunction: KernelPCA._fit_transform\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "f8b108d0c6f2f82b2dc4e32a6793f9d9ac9cf2f4", "problem_statement": "Differences among the results of KernelPCA with rbf kernel\nHi there,\r\nI met with a problem:\r\n\r\n#### Description\r\nWhen I run KernelPCA for dimension reduction for the same datasets, the results are different in signs.\r\n\r\n#### Steps/Code to Reproduce\r\nJust to reduce the dimension to 7 with rbf kernel:\r\npca = KernelPCA(n_components=7, kernel='rbf', copy_X=False, n_jobs=-1)\r\npca.fit_transform(X)\r\n\r\n#### Expected Results\r\nThe same result.\r\n\r\n#### Actual Results\r\nThe results are the same except for their signs:(\r\n[[-0.44457617 -0.18155886 -0.10873474  0.13548386 -0.1437174  -0.057469\t0.18124364]] \r\n\r\n[[ 0.44457617  0.18155886  0.10873474 -0.13548386 -0.1437174  -0.057469 -0.18124364]] \r\n\r\n[[-0.44457617 -0.18155886  0.10873474  0.13548386  0.1437174   0.057469  0.18124364]] \r\n\r\n#### Versions\r\n0.18.1\r\n\n", "patch": "diff --git a/sklearn/decomposition/kernel_pca.py b/sklearn/decomposition/kernel_pca.py\n--- a/sklearn/decomposition/kernel_pca.py\n+++ b/sklearn/decomposition/kernel_pca.py\n@@ -8,6 +8,7 @@\n from scipy.sparse.linalg import eigsh\n \n from ..utils import check_random_state\n+from ..utils.extmath import svd_flip\n from ..utils.validation import check_is_fitted, check_array\n from ..exceptions import NotFittedError\n from ..base import BaseEstimator, TransformerMixin, _UnstableOn32BitMixin\n@@ -210,6 +211,10 @@ def _fit_transform(self, K):\n                                                 maxiter=self.max_iter,\n                                                 v0=v0)\n \n+        # flip eigenvectors' sign to enforce deterministic output\n+        self.alphas_, _ = svd_flip(self.alphas_,\n+                                   np.empty_like(self.alphas_).T)\n+\n         # sort eigenvectors in descending order\n         indices = self.lambdas_.argsort()[::-1]\n         self.lambdas_ = self.lambdas_[indices]\n"}}
{"instance_id": "sympy__sympy-22714", "found_files": ["sympy/geometry/point.py", "sympy/parsing/sympy_parser.py", "sympy/core/sympify.py", "sympy/functions/elementary/complexes.py"], "found_modules": ["sympy/geometry/point.py:Point", "sympy/parsing/sympy_parser.py:parse_expr", "sympy/core/sympify.py:sympify", "sympy/functions/elementary/complexes.py:im", "sympy/geometry/point.py:Point2D"], "found_entities": ["sympy/geometry/point.py:Point.__new__", "sympy/parsing/sympy_parser.py:parse_expr", "sympy/core/sympify.py:sympify", "sympy/functions/elementary/complexes.py:im.eval", "sympy/geometry/point.py:Point2D.__new__"], "raw_output_loc": ["```\nsympy/geometry/point.py\nline: 156\nclass: Point\nfunction: Point.__new__\n\nsympy/functions/elementary/complexes.py\nline: 194\nclass: im\nfunction: im.eval\n\nsympy/parsing/sympy_parser.py\nline: 1044\nfunction: parse_expr\n\nsympy/core/sympify.py\nline: 97\nfunction: sympify\n\nsympy/geometry/point.py\nline: 912\nclass: Point2D\nfunction: Point2D.__new__\n```", "```\nsympy/geometry/point.py\nline: 156\nclass: Point\nfunction: Point.__new__\n\nsympy/parsing/sympy_parser.py\nline: 1090\nfunction: parse_expr\n\nsympy/core/sympify.py\nline: 472\nfunction: sympify\n\nsympy/geometry/point.py\nline: 912\nclass: Point2D\nfunction: Point2D.__new__\n\nsympy/geometry/point.py\nline: 153\nclass: Point\nfunction: Point.__new__\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "3ff4717b6aef6086e78f01cdfa06f64ae23aed7e", "problem_statement": "simpify gives `Imaginary coordinates are not permitted.` with evaluate(False)\n## Issue\r\n`with evaluate(False)` crashes unexpectedly with `Point2D`\r\n\r\n## Code\r\n```python\r\nimport sympy as sp\r\nwith sp.evaluate(False):\r\n  sp.S('Point2D(Integer(1),Integer(2))')\r\n```\r\n\r\n## Error\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/core/sympify.py\", line 472, in sympify\r\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/parsing/sympy_parser.py\", line 1026, in parse_expr\r\n    raise e from ValueError(f\"Error from parse_expr with transformed code: {code!r}\")\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/parsing/sympy_parser.py\", line 1017, in parse_expr\r\n    rv = eval_expr(code, local_dict, global_dict)\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/parsing/sympy_parser.py\", line 911, in eval_expr\r\n    expr = eval(\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/geometry/point.py\", line 912, in __new__\r\n    args = Point(*args, **kwargs)\r\n  File \"/home/avinash/.local/lib/python3.8/site-packages/sympy/geometry/point.py\", line 153, in __new__\r\n    raise ValueError('Imaginary coordinates are not permitted.')\r\nValueError: Imaginary coordinates are not permitted.\r\n```\r\n\r\nHowever, it works without `with evaluate(False)`. Both of following commands work\r\n```python\r\nsp.S('Point2D(Integer(1),Integer(2))')\r\nsp.S('Point2D(Integer(1),Integer(2))', evaluate=False)\r\n```\n", "patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,7 +152,7 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n+        if any(a.is_number and im(a).is_zero is False for a in coords):\n             raise ValueError('Imaginary coordinates are not permitted.')\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n"}}
{"instance_id": "matplotlib__matplotlib-23964", "found_files": ["lib/matplotlib/backends/backend_ps.py", "lib/matplotlib/text.py", "lib/matplotlib/_text_helpers.py"], "found_modules": ["lib/matplotlib/backends/backend_ps.py:RendererPS", "lib/matplotlib/text.py:Annotation", "lib/matplotlib/_text_helpers.py:layout", "lib/matplotlib/text.py:Text", "lib/matplotlib/backends/backend_ps.py:_log_if_debug_on", "lib/matplotlib/backends/backend_ps.py:FigureCanvasPS"], "found_entities": ["lib/matplotlib/backends/backend_ps.py:RendererPS.draw_text", "lib/matplotlib/text.py:Annotation.update_positions", "lib/matplotlib/_text_helpers.py:layout", "lib/matplotlib/text.py:Text.draw", "lib/matplotlib/backends/backend_ps.py:_log_if_debug_on.wrapper", "lib/matplotlib/backends/backend_ps.py:RendererPS._get_clip_cmd", "lib/matplotlib/backends/backend_ps.py:RendererPS.draw_gouraud_triangles", "lib/matplotlib/backends/backend_ps.py:RendererPS.draw_mathtext", "lib/matplotlib/backends/backend_ps.py:FigureCanvasPS._print_figure"], "raw_output_loc": ["```\nlib/matplotlib/backends/backend_ps.py\nline: 669\nline: 673\nclass: RendererPS\nfunction: RendererPS.draw_text\n\nlib/matplotlib/text.py\nline: 1995\nclass: Text\nfunction: Text.draw\n\nlib/matplotlib/backends/backend_ps.py\nline: 248\nclass: RendererPS\nfunction: RendererPS._get_clip_cmd\n\nlib/matplotlib/backends/backend_ps.py\nline: 736\nclass: RendererPS\nfunction: RendererPS.draw_mathtext\n\nlib/matplotlib/backends/backend_ps.py\nline: 2204\nclass: FigureCanvasPS\nfunction: FigureCanvasPS._print_figure\n```", "```\nlib/matplotlib/backends/backend_ps.py\nline: 669\nclass: RendererPS\nfunction: RendererPS.draw_text\n\nlib/matplotlib/_text_helpers.py\nline: 58\nfunction: layout\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "269c0b94b4fcf8b1135011c1556eac29dc09de15", "problem_statement": "[Bug]: Text label with empty line causes a \"TypeError: cannot unpack non-iterable NoneType object\" in PostScript backend\n### Bug summary\n\nWhen saving a figure with the PostScript backend, a\r\n> TypeError: cannot unpack non-iterable NoneType object\r\n\r\nhappens if the figure contains a multi-line text label with an empty line (see example).\n\n### Code for reproduction\n\n```python\nfrom matplotlib.figure import Figure\r\n\r\nfigure = Figure()\r\nax = figure.add_subplot(111)\r\n# ax.set_title('\\nLower title')  # this would cause an error as well\r\nax.annotate(text='\\nLower label', xy=(0, 0))\r\nfigure.savefig('figure.eps')\n```\n\n\n### Actual outcome\n\n$ ./venv/Scripts/python save_ps.py\r\nTraceback (most recent call last):\r\n  File \"C:\\temp\\matplotlib_save_ps\\save_ps.py\", line 7, in <module>\r\n    figure.savefig('figure.eps')\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\figure.py\", line 3272, in savefig\r\n    self.canvas.print_figure(fname, **kwargs)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2338, in print_figure\r\n    result = print_method(\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2204, in <lambda>\r\n    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 410, in wrapper\r\n    return func(*inner_args, **inner_kwargs)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backends\\backend_ps.py\", line 869, in _print_ps\r\n    printer(fmt, outfile, dpi=dpi, dsc_comments=dsc_comments,\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backends\\backend_ps.py\", line 927, in _print_figure\r\n    self.figure.draw(renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\artist.py\", line 74, in draw_wrapper\r\n    result = draw(artist, renderer, *args, **kwargs)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\figure.py\", line 3069, in draw\r\n    mimage._draw_list_compositing_images(\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\image.py\", line 131, in _draw_list_compositing_images\r\n    a.draw(renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3106, in draw\r\n    mimage._draw_list_compositing_images(\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\image.py\", line 131, in _draw_list_compositing_images\r\n    a.draw(renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\text.py\", line 1995, in draw\r\n    Text.draw(self, renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\r\n    return draw(artist, renderer)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\text.py\", line 736, in draw\r\n    textrenderer.draw_text(gc, x, y, clean_line,\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backends\\backend_ps.py\", line 248, in wrapper\r\n    return meth(self, *args, **kwargs)\r\n  File \"C:\\temp\\matplotlib_save_ps\\venv\\lib\\site-packages\\matplotlib\\backends\\backend_ps.py\", line 673, in draw_text\r\n    for ps_name, xs_names in stream:\r\nTypeError: cannot unpack non-iterable NoneType object\r\n\n\n### Expected outcome\n\nThe figure can be saved as `figure.eps` without error.\n\n### Additional information\n\n- seems to happen if a text label or title contains a linebreak with an empty line\r\n- works without error for other backends such as PNG, PDF, SVG, Qt\r\n- works with matplotlib<=3.5.3\r\n- adding `if curr_stream:` before line 669 of `backend_ps.py` seems to fix the bug \n\n### Operating system\n\nWindows\n\n### Matplotlib Version\n\n3.6.0\n\n### Matplotlib Backend\n\n_No response_\n\n### Python version\n\n3.9.13\n\n### Jupyter version\n\n_No response_\n\n### Installation\n\npip\n", "patch": "diff --git a/lib/matplotlib/backends/backend_ps.py b/lib/matplotlib/backends/backend_ps.py\n--- a/lib/matplotlib/backends/backend_ps.py\n+++ b/lib/matplotlib/backends/backend_ps.py\n@@ -665,8 +665,9 @@ def draw_text(self, gc, x, y, s, prop, angle, ismath=False, mtext=None):\n                 curr_stream[1].append(\n                     (item.x, item.ft_object.get_glyph_name(item.glyph_idx))\n                 )\n-            # append the last entry\n-            stream.append(curr_stream)\n+            # append the last entry if exists\n+            if curr_stream:\n+                stream.append(curr_stream)\n \n         self.set_color(*gc.get_rgb())\n \n"}}
{"instance_id": "django__django-11133", "found_files": ["django/http/response.py"], "found_modules": ["django/http/response.py:HttpResponseBase"], "found_entities": ["django/http/response.py:HttpResponseBase.make_bytes"], "raw_output_loc": ["```\ndjango/http/response.py\nline: 223\nclass: HttpResponseBase\nfunction: HttpResponseBase.make_bytes\n\n```", "```\ndjango/http/response.py\nline: 223\nline: 237\nclass: HttpResponseBase\nfunction: HttpResponseBase.make_bytes\n```"], "meta_data": {"repo": "django/django", "base_commit": "879cc3da6249e920b8d54518a0ae06de835d7373", "problem_statement": "HttpResponse doesn't handle memoryview objects\nDescription\n\t\nI am trying to write a BinaryField retrieved from the database into a HttpResponse. When the database is Sqlite this works correctly, but Postgresql returns the contents of the field as a memoryview object and it seems like current Django doesn't like this combination:\nfrom django.http import HttpResponse\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n# String content\nresponse = HttpResponse(\"My Content\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\nresponse.content\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n# Out: b'My Content'\n# This is correct\n# Bytes content\nresponse = HttpResponse(b\"My Content\")\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \nresponse.content\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n# Out: b'My Content'\n# This is also correct\n# memoryview content\nresponse = HttpResponse(memoryview(b\"My Content\"))\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \nresponse.content\n# Out: b'<memory at 0x7fcc47ab2648>'\n# This is not correct, I am expecting b'My Content'\n", "patch": "diff --git a/django/http/response.py b/django/http/response.py\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -229,7 +229,7 @@ def make_bytes(self, value):\n         # Handle string types -- we can't rely on force_bytes here because:\n         # - Python attempts str conversion first\n         # - when self._charset != 'utf-8' it re-encodes the content\n-        if isinstance(value, bytes):\n+        if isinstance(value, (bytes, memoryview)):\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n"}}
{"instance_id": "matplotlib__matplotlib-23913", "found_files": ["lib/matplotlib/legend.py"], "found_modules": ["lib/matplotlib/legend.py:Legend", "lib/matplotlib/legend.py:DraggableLegend"], "found_entities": ["lib/matplotlib/legend.py:Legend.set_draggable"], "raw_output_loc": ["```\nlib/matplotlib/legend.py\nline: 306\nclass: Legend\nfunction: Legend.__init__\n\nlib/matplotlib/legend.py\nline: 1079\nclass: Legend\nfunction: Legend.set_draggable\n```", "```\nlib/matplotlib/legend.py\nline: 306\nclass: Legend\nfunction: Legend.__init__\n\nlib/matplotlib/legend.py\nline: 1079\nclass: Legend\nfunction: Legend.set_draggable\n\nlib/matplotlib/legend.py\nline: 54\nclass: DraggableLegend\nfunction: DraggableLegend.__init__\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "5c4595267ccd3daf78f5fd05693b7ecbcd575c1e", "problem_statement": "legend draggable as keyword\n<!--To help us understand and resolve your issue, please fill out the form to the best of your ability.-->\r\n<!--You can feel free to delete the sections that do not apply.-->\r\n\r\n### Feature request\r\n\r\n**There is not keyword to make legend draggable at creation**\r\n\r\n<!--A short 1-2 sentences that succinctly describes the bug-->\r\n\r\nIs there a code reason why one can not add a \"draggable=True\" keyword to the __init__ function for Legend?  This would be more handy than having to call it after legend creation.  And, naively, it would seem simple to do.  But maybe there is a reason why it would not work?\n", "patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -286,6 +286,9 @@ def _update_bbox_to_anchor(self, loc_in_canvas):\n     The custom dictionary mapping instances or types to a legend\n     handler. This *handler_map* updates the default handler map\n     found at `matplotlib.legend.Legend.get_legend_handler_map`.\n+\n+draggable : bool, default: False\n+    Whether the legend can be dragged with the mouse.\n \"\"\")\n \n \n@@ -342,7 +345,8 @@ def __init__(\n         title_fontproperties=None,  # properties for the legend title\n         alignment=\"center\",       # control the alignment within the legend box\n         *,\n-        ncol=1  # synonym for ncols (backward compatibility)\n+        ncol=1,  # synonym for ncols (backward compatibility)\n+        draggable=False  # whether the legend can be dragged with the mouse\n     ):\n         \"\"\"\n         Parameters\n@@ -537,7 +541,9 @@ def val_or_rc(val, rc_name):\n             title_prop_fp.set_size(title_fontsize)\n \n         self.set_title(title, prop=title_prop_fp)\n+\n         self._draggable = None\n+        self.set_draggable(state=draggable)\n \n         # set the text color\n \n"}}
{"instance_id": "sympy__sympy-12236", "found_files": ["sympy/polys/partfrac.py", "sympy/solvers/solvers.py"], "found_modules": ["sympy/polys/partfrac.py:apart_undetermined_coeffs", "sympy/polys/partfrac.py:apart", "sympy/solvers/solvers.py:checksol", "sympy/solvers/solvers.py:solve", "sympy/polys/partfrac.py:apart_full_decomposition", "sympy/polys/partfrac.py:apart_list"], "found_entities": ["sympy/polys/partfrac.py:apart_undetermined_coeffs", "sympy/polys/partfrac.py:apart", "sympy/solvers/solvers.py:checksol", "sympy/solvers/solvers.py:solve", "sympy/polys/partfrac.py:apart_full_decomposition", "sympy/polys/partfrac.py:apart_list"], "raw_output_loc": ["```\nsympy/polys/partfrac.py:apart_undetermined_coeffs\nline: 178\nline: 179\nfunction: apart_undetermined_coeffs\n\nsympy/solvers/solvers.py:solve\nline: 181\nfunction: solve\n```", "```\nsympy/polys/partfrac.py:apart\nline: 137\nfunction: apart_undetermined_coeffs\n\nsympy/polys/partfrac.py:apart\nline: 139\nfunction: apart_full_decomposition\n\nsympy/polys/partfrac.py:apart_undetermined_coeffs\nline: 157\nfunction: factor_list\n\nsympy/polys/partfrac.py:apart_undetermined_coeffs\nline: 182\nfunction: solve\n\nsympy/polys/partfrac.py:apart_full_decomposition\nline: 210\nfunction: apart_list\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "d60497958f6dea7f5e25bc41e9107a6a63694d01", "problem_statement": "Wrong result with apart\n```\r\nPython 3.6.0 |Continuum Analytics, Inc.| (default, Dec 23 2016, 12:22:00) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 5.1.0 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\n\r\nIn [1]: from sympy import symbols\r\n\r\nIn [2]: a = symbols('a', real=True)\r\n\r\nIn [3]: t = symbols('t', real=True, negative=False)\r\n\r\nIn [4]: bug = a * (-t + (-t + 1) * (2 * t - 1)) / (2 * t - 1)\r\n\r\nIn [5]: bug.subs(a, 1)\r\nOut[5]: (-t + (-t + 1)*(2*t - 1))/(2*t - 1)\r\n\r\nIn [6]: bug.subs(a, 1).apart()\r\nOut[6]: -t + 1/2 - 1/(2*(2*t - 1))\r\n\r\nIn [7]: bug.subs(a, 1).apart(t)\r\nOut[7]: -t + 1/2 - 1/(2*(2*t - 1))\r\n\r\nIn [8]: bug.apart(t)\r\nOut[8]: -a*t\r\n\r\nIn [9]: import sympy; sympy.__version__\r\nOut[9]: '1.0'\r\n```\nWrong result with apart\n```\r\nPython 3.6.0 |Continuum Analytics, Inc.| (default, Dec 23 2016, 12:22:00) \r\nType \"copyright\", \"credits\" or \"license\" for more information.\r\n\r\nIPython 5.1.0 -- An enhanced Interactive Python.\r\n?         -> Introduction and overview of IPython's features.\r\n%quickref -> Quick reference.\r\nhelp      -> Python's own help system.\r\nobject?   -> Details about 'object', use 'object??' for extra details.\r\n\r\nIn [1]: from sympy import symbols\r\n\r\nIn [2]: a = symbols('a', real=True)\r\n\r\nIn [3]: t = symbols('t', real=True, negative=False)\r\n\r\nIn [4]: bug = a * (-t + (-t + 1) * (2 * t - 1)) / (2 * t - 1)\r\n\r\nIn [5]: bug.subs(a, 1)\r\nOut[5]: (-t + (-t + 1)*(2*t - 1))/(2*t - 1)\r\n\r\nIn [6]: bug.subs(a, 1).apart()\r\nOut[6]: -t + 1/2 - 1/(2*(2*t - 1))\r\n\r\nIn [7]: bug.subs(a, 1).apart(t)\r\nOut[7]: -t + 1/2 - 1/(2*(2*t - 1))\r\n\r\nIn [8]: bug.apart(t)\r\nOut[8]: -a*t\r\n\r\nIn [9]: import sympy; sympy.__version__\r\nOut[9]: '1.0'\r\n```\n", "patch": "diff --git a/sympy/polys/domains/polynomialring.py b/sympy/polys/domains/polynomialring.py\n--- a/sympy/polys/domains/polynomialring.py\n+++ b/sympy/polys/domains/polynomialring.py\n@@ -104,10 +104,10 @@ def from_PolynomialRing(K1, a, K0):\n \n     def from_FractionField(K1, a, K0):\n         \"\"\"Convert a rational function to ``dtype``. \"\"\"\n-        denom = K0.denom(a)\n+        q, r = K0.numer(a).div(K0.denom(a))\n \n-        if denom.is_ground:\n-            return K1.from_PolynomialRing(K0.numer(a)/denom, K0.field.ring.to_domain())\n+        if r.is_zero:\n+            return K1.from_PolynomialRing(q, K0.field.ring.to_domain())\n         else:\n             return None\n \n"}}
{"instance_id": "scikit-learn__scikit-learn-14092", "found_files": ["sklearn/neighbors/nca.py", "sklearn/utils/validation.py", "sklearn/model_selection/_search.py"], "found_modules": ["sklearn/neighbors/nca.py:NeighborhoodComponentsAnalysis", "sklearn/utils/validation.py:check_scalar", "sklearn/model_selection/_search.py:ParameterGrid", "sklearn/model_selection/_search.py:GridSearchCV"], "found_entities": ["sklearn/neighbors/nca.py:NeighborhoodComponentsAnalysis._validate_params", "sklearn/utils/validation.py:check_scalar", "sklearn/model_selection/_search.py:ParameterGrid.__iter__", "sklearn/model_selection/_search.py:ParameterGrid.__getitem__", "sklearn/model_selection/_search.py:GridSearchCV._run_search"], "raw_output_loc": ["```\nsklearn/neighbors/nca.py\nline: 302\nfunction: NeighborhoodComponentsAnalysis._validate_params\n\nsklearn/utils/validation.py\nline: 975\nfunction: check_scalar\n\nsklearn/model_selection/_search.py\nline: 1116\nfunction: GridSearchCV._run_search\n\nsklearn/model_selection/_search.py\nline: 128\nfunction: ParameterGrid.__iter__\n\nsklearn/model_selection/_search.py\nline: 175\nfunction: ParameterGrid.__getitem__\n```", "```\nsklearn/neighbors/nca.py\nline: 302\nclass: NeighborhoodComponentsAnalysis\nfunction: NeighborhoodComponentsAnalysis._validate_params\n\nsklearn/utils/validation.py\nline: 975\nfunction: check_scalar\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "df7dd8391148a873d157328a4f0328528a0c4ed9", "problem_statement": "NCA fails in GridSearch due to too strict parameter checks\nNCA checks its parameters to have a specific type, which can easily fail in a GridSearch due to how param grid is made.\r\n\r\nHere is an example:\r\n```python\r\nimport numpy as np\r\n\r\nfrom sklearn.pipeline import Pipeline\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.neighbors import NeighborhoodComponentsAnalysis\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\n\r\nX = np.random.random_sample((100, 10))\r\ny = np.random.randint(2, size=100)\r\n\r\nnca = NeighborhoodComponentsAnalysis()\r\nknn = KNeighborsClassifier()\r\n\r\npipe = Pipeline([('nca', nca),\r\n                 ('knn', knn)])\r\n                \r\nparams = {'nca__tol': [0.1, 0.5, 1],\r\n          'nca__n_components': np.arange(1, 10)}\r\n          \r\ngs = GridSearchCV(estimator=pipe, param_grid=params, error_score='raise')\r\ngs.fit(X,y)\r\n```\r\n\r\nThe issue is that for `tol`: 1 is not a float, and for  `n_components`: np.int64 is not int\r\n\r\nBefore proposing a fix for this specific situation, I'd like to have your general opinion about parameter checking.  \r\nI like this idea of common parameter checking tool introduced with the NCA PR. What do you think about extending it across the code-base (or at least for new or recent estimators) ?\r\n\r\nCurrently parameter checking is not always done or often partially done, and is quite redundant. For instance, here is the input validation of lda:\r\n```python\r\ndef _check_params(self):\r\n        \"\"\"Check model parameters.\"\"\"\r\n        if self.n_components <= 0:\r\n            raise ValueError(\"Invalid 'n_components' parameter: %r\"\r\n                             % self.n_components)\r\n\r\n        if self.total_samples <= 0:\r\n            raise ValueError(\"Invalid 'total_samples' parameter: %r\"\r\n                             % self.total_samples)\r\n\r\n        if self.learning_offset < 0:\r\n            raise ValueError(\"Invalid 'learning_offset' parameter: %r\"\r\n                             % self.learning_offset)\r\n\r\n        if self.learning_method not in (\"batch\", \"online\"):\r\n            raise ValueError(\"Invalid 'learning_method' parameter: %r\"\r\n                             % self.learning_method)\r\n```\r\nmost params aren't checked and for those who are there's a lot of duplicated code.\r\n\r\nA propose to be upgrade the new tool to be able to check open/closed intervals (currently only closed) and list membership.\r\n\r\nThe api would be something like that:\r\n```\r\ncheck_param(param, name, valid_options)\r\n```\r\nwhere valid_options would be a dict of `type: constraint`. e.g for the `beta_loss` param of `NMF`, it can be either a float or a string in a list, which would give\r\n```\r\nvalid_options = {numbers.Real: None,  # None for no constraint\r\n                 str: ['frobenius', 'kullback-leibler', 'itakura-saito']}\r\n```\r\nSometimes a parameter can only be positive or within a given interval, e.g. `l1_ratio` of `LogisticRegression` must be between 0 and 1, which would give\r\n```\r\nvalid_options = {numbers.Real: Interval(0, 1, closed='both')}\r\n```\r\npositivity of e.g. `max_iter` would be `numbers.Integral: Interval(left=1)`.\n", "patch": "diff --git a/sklearn/neighbors/nca.py b/sklearn/neighbors/nca.py\n--- a/sklearn/neighbors/nca.py\n+++ b/sklearn/neighbors/nca.py\n@@ -13,6 +13,7 @@\n import numpy as np\n import sys\n import time\n+import numbers\n from scipy.optimize import minimize\n from ..utils.extmath import softmax\n from ..metrics import pairwise_distances\n@@ -299,7 +300,8 @@ def _validate_params(self, X, y):\n \n         # Check the preferred dimensionality of the projected space\n         if self.n_components is not None:\n-            check_scalar(self.n_components, 'n_components', int, 1)\n+            check_scalar(\n+                self.n_components, 'n_components', numbers.Integral, 1)\n \n             if self.n_components > X.shape[1]:\n                 raise ValueError('The preferred dimensionality of the '\n@@ -318,9 +320,9 @@ def _validate_params(self, X, y):\n                                  .format(X.shape[1],\n                                          self.components_.shape[1]))\n \n-        check_scalar(self.max_iter, 'max_iter', int, 1)\n-        check_scalar(self.tol, 'tol', float, 0.)\n-        check_scalar(self.verbose, 'verbose', int, 0)\n+        check_scalar(self.max_iter, 'max_iter', numbers.Integral, 1)\n+        check_scalar(self.tol, 'tol', numbers.Real, 0.)\n+        check_scalar(self.verbose, 'verbose', numbers.Integral, 0)\n \n         if self.callback is not None:\n             if not callable(self.callback):\n"}}
{"instance_id": "matplotlib__matplotlib-24970", "found_files": ["lib/matplotlib/colors.py"], "found_modules": ["lib/matplotlib/colors.py:Colormap"], "found_entities": ["lib/matplotlib/colors.py:Colormap.__call__"], "raw_output_loc": ["```\nlib/matplotlib/colors.py\nline: 730\nline: 731\nline: 732\nclass: Colormap\nfunction: Colormap.__call__\n```", "```\nlib/matplotlib/colors.py\nline: 730\nline: 731\nline: 732\nclass: Colormap\nfunction: Colormap.__call__\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "a3011dfd1aaa2487cce8aa7369475533133ef777", "problem_statement": "[Bug]: NumPy 1.24 deprecation warnings\n### Bug summary\r\n\r\nStarting NumPy 1.24 I observe several deprecation warnings.\r\n\r\n\r\n### Code for reproduction\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\nplt.get_cmap()(np.empty((0, ), dtype=np.uint8))\r\n```\r\n\r\n\r\n### Actual outcome\r\n\r\n```\r\n/usr/lib/python3.10/site-packages/matplotlib/colors.py:730: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of 257 to uint8 will fail in the future.\r\nFor the old behavior, usually:\r\n    np.array(value).astype(dtype)`\r\nwill give the desired result (the cast overflows).\r\n  xa[xa > self.N - 1] = self._i_over\r\n/usr/lib/python3.10/site-packages/matplotlib/colors.py:731: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of 256 to uint8 will fail in the future.\r\nFor the old behavior, usually:\r\n    np.array(value).astype(dtype)`\r\nwill give the desired result (the cast overflows).\r\n  xa[xa < 0] = self._i_under\r\n/usr/lib/python3.10/site-packages/matplotlib/colors.py:732: DeprecationWarning: NumPy will stop allowing conversion of out-of-bound Python integers to integer arrays.  The conversion of 258 to uint8 will fail in the future.\r\nFor the old behavior, usually:\r\n    np.array(value).astype(dtype)`\r\nwill give the desired result (the cast overflows).\r\n  xa[mask_bad] = self._i_bad\r\n```\r\n\r\n### Expected outcome\r\n\r\nNo warnings.\r\n\r\n### Additional information\r\n\r\n_No response_\r\n\r\n### Operating system\r\n\r\nArchLinux\r\n\r\n### Matplotlib Version\r\n\r\n3.6.2\r\n\r\n### Matplotlib Backend\r\n\r\nQtAgg\r\n\r\n### Python version\r\n\r\nPython 3.10.9\r\n\r\n### Jupyter version\r\n\r\n_No response_\r\n\r\n### Installation\r\n\r\nLinux package manager\n", "patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -715,16 +715,17 @@ def __call__(self, X, alpha=None, bytes=False):\n         if not xa.dtype.isnative:\n             xa = xa.byteswap().newbyteorder()  # Native byteorder is faster.\n         if xa.dtype.kind == \"f\":\n-            with np.errstate(invalid=\"ignore\"):\n-                xa *= self.N\n-                # Negative values are out of range, but astype(int) would\n-                # truncate them towards zero.\n-                xa[xa < 0] = -1\n-                # xa == 1 (== N after multiplication) is not out of range.\n-                xa[xa == self.N] = self.N - 1\n-                # Avoid converting large positive values to negative integers.\n-                np.clip(xa, -1, self.N, out=xa)\n-                xa = xa.astype(int)\n+            xa *= self.N\n+            # Negative values are out of range, but astype(int) would\n+            # truncate them towards zero.\n+            xa[xa < 0] = -1\n+            # xa == 1 (== N after multiplication) is not out of range.\n+            xa[xa == self.N] = self.N - 1\n+            # Avoid converting large positive values to negative integers.\n+            np.clip(xa, -1, self.N, out=xa)\n+        with np.errstate(invalid=\"ignore\"):\n+            # We need this cast for unsigned ints as well as floats\n+            xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n         xa[xa > self.N - 1] = self._i_over\n"}}
{"instance_id": "django__django-11742", "found_files": ["django/db/models/fields/__init__.py"], "found_modules": ["django/db/models/fields/__init__.py:Field", "django/db/models/fields/__init__.py:CharField"], "found_entities": ["django/db/models/fields/__init__.py:Field._check_choices", "django/db/models/fields/__init__.py:CharField._check_max_length_attribute"], "raw_output_loc": ["```\ndjango/db/models/fields/__init__.py\nline: 960\nclass: CharField\nfunction: CharField._check_max_length_attribute\n\ndjango/db/models/fields/__init__.py\nline: 244\nclass: Field\nfunction: Field._check_choices\n```", "```\ndjango/db/models/fields/__init__.py\nline: 244\nclass: Field\nfunction: Field._check_choices\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "fee75d2aed4e58ada6567c464cfd22e89dc65f4a", "problem_statement": "Add check to ensure max_length fits longest choice.\nDescription\n\t\nThere is currently no check to ensure that Field.max_length is large enough to fit the longest value in Field.choices.\nThis would be very helpful as often this mistake is not noticed until an attempt is made to save a record with those values that are too long.\n", "patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -257,6 +257,7 @@ def is_value(value, accept_promise=True):\n                 )\n             ]\n \n+        choice_max_length = 0\n         # Expect [group_name, [value, display]]\n         for choices_group in self.choices:\n             try:\n@@ -270,16 +271,32 @@ def is_value(value, accept_promise=True):\n                     for value, human_name in group_choices\n                 ):\n                     break\n+                if self.max_length is not None and group_choices:\n+                    choice_max_length = max(\n+                        choice_max_length,\n+                        *(len(value) for value, _ in group_choices if isinstance(value, str)),\n+                    )\n             except (TypeError, ValueError):\n                 # No groups, choices in the form [value, display]\n                 value, human_name = group_name, group_choices\n                 if not is_value(value) or not is_value(human_name):\n                     break\n+                if self.max_length is not None and isinstance(value, str):\n+                    choice_max_length = max(choice_max_length, len(value))\n \n             # Special case: choices=['ab']\n             if isinstance(choices_group, str):\n                 break\n         else:\n+            if self.max_length is not None and choice_max_length > self.max_length:\n+                return [\n+                    checks.Error(\n+                        \"'max_length' is too small to fit the longest value \"\n+                        \"in 'choices' (%d characters).\" % choice_max_length,\n+                        obj=self,\n+                        id='fields.E009',\n+                    ),\n+                ]\n             return []\n \n         return [\n"}}
{"instance_id": "pytest-dev__pytest-8365", "found_files": ["src/_pytest/tmpdir.py", "src/_pytest/pathlib.py"], "found_modules": ["src/_pytest/tmpdir.py:get_user", "src/_pytest/tmpdir.py:TempPathFactory", "src/_pytest/pathlib.py:make_numbered_dir_with_cleanup", "src/_pytest/pathlib.py:make_numbered_dir"], "found_entities": ["src/_pytest/tmpdir.py:get_user", "src/_pytest/tmpdir.py:TempPathFactory.getbasetemp", "src/_pytest/pathlib.py:make_numbered_dir_with_cleanup", "src/_pytest/pathlib.py:make_numbered_dir"], "raw_output_loc": ["```\nsrc/_pytest/tmpdir.py\nline: 151\nfunction: get_user\n```", "```\nsrc/_pytest/tmpdir.py\nline: 114\nfunction: TempPathFactory.getbasetemp\n\nsrc/_pytest/tmpdir.py\nline: 157\nfunction: get_user\n\nsrc/_pytest/pathlib.py\nline: 361\nfunction: make_numbered_dir_with_cleanup\n\nsrc/_pytest/pathlib.py\nline: 223\nfunction: make_numbered_dir\n\nsrc/_pytest/pathlib.py\nline: 1266\nfunction: Path.mkdir\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "4964b468c83c06971eb743fbc57cc404f760c573", "problem_statement": "tmpdir creation fails when the username contains illegal characters for directory names\n`tmpdir`, `tmpdir_factory` and `tmp_path_factory` rely on `getpass.getuser()` for determining the `basetemp` directory. I found that the user name returned by `getpass.getuser()` may return characters that are not allowed for directory names. This may lead to errors while creating the temporary directory.\r\n\r\nThe situation in which I reproduced this issue was while being logged in through an ssh connection into my Windows 10 x64 Enterprise version (1909) using an OpenSSH_for_Windows_7.7p1 server. In this configuration the command `python -c \"import getpass; print(getpass.getuser())\"` returns my domain username e.g. `contoso\\john_doe` instead of `john_doe` as when logged in regularly using a local session.\r\n\r\nWhen trying to create a temp directory in pytest through e.g. `tmpdir_factory.mktemp('foobar')` this fails with the following error message:\r\n```\r\nself = WindowsPath('C:/Users/john_doe/AppData/Local/Temp/pytest-of-contoso/john_doe')\r\nmode = 511, parents = False, exist_ok = True\r\n\r\n    def mkdir(self, mode=0o777, parents=False, exist_ok=False):\r\n        \"\"\"\r\n        Create a new directory at this given path.\r\n        \"\"\"\r\n        if self._closed:\r\n            self._raise_closed()\r\n        try:\r\n>           self._accessor.mkdir(self, mode)\r\nE           FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\john_doe\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-contoso\\\\john_doe'\r\n\r\nC:\\Python38\\lib\\pathlib.py:1266: FileNotFoundError\r\n```\r\n\r\nI could also reproduce this without the complicated ssh/windows setup with pytest 6.2.2 using the following commands from a `cmd`:\r\n```bat\r\necho def test_tmpdir(tmpdir):>test_tmp.py\r\necho   pass>>test_tmp.py\r\nset LOGNAME=contoso\\john_doe\r\npy.test test_tmp.py\r\n```\r\n\r\nThanks for having a look at this!\n", "patch": "diff --git a/src/_pytest/tmpdir.py b/src/_pytest/tmpdir.py\n--- a/src/_pytest/tmpdir.py\n+++ b/src/_pytest/tmpdir.py\n@@ -115,7 +115,12 @@ def getbasetemp(self) -> Path:\n             # use a sub-directory in the temproot to speed-up\n             # make_numbered_dir() call\n             rootdir = temproot.joinpath(f\"pytest-of-{user}\")\n-            rootdir.mkdir(exist_ok=True)\n+            try:\n+                rootdir.mkdir(exist_ok=True)\n+            except OSError:\n+                # getuser() likely returned illegal characters for the platform, use unknown back off mechanism\n+                rootdir = temproot.joinpath(\"pytest-of-unknown\")\n+                rootdir.mkdir(exist_ok=True)\n             basetemp = make_numbered_dir_with_cleanup(\n                 prefix=\"pytest-\", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT\n             )\n"}}
{"instance_id": "sympy__sympy-21847", "found_files": ["sympy/polys/monomials.py"], "found_modules": ["sympy/polys/monomials.py:itermonomials"], "found_entities": ["sympy/polys/monomials.py:itermonomials"], "raw_output_loc": ["```\nsympy/polys/monomials.py\nline: 130\nfunction: itermonomials\n```", "```\nsympy/polys/monomials.py\nline: 130\nline: 142\nfunction: itermonomials\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "d9b18c518d64d0ebe8e35a98c2fb519938b9b151", "problem_statement": "itermonomials returns incorrect monomials when using min_degrees argument\n`itermonomials` returns incorrect monomials when using optional `min_degrees` argument\r\n\r\nFor example, the following code introduces three symbolic variables and generates monomials with max and min degree of 3:\r\n\r\n\r\n```\r\nimport sympy as sp\r\nfrom sympy.polys.orderings import monomial_key\r\n\r\nx1, x2, x3 = sp.symbols('x1, x2, x3')\r\nstates = [x1, x2, x3]\r\nmax_degrees = 3\r\nmin_degrees = 3\r\nmonomials = sorted(sp.itermonomials(states, max_degrees, min_degrees=min_degrees), \r\n                   key=monomial_key('grlex', states))\r\nprint(monomials)\r\n```\r\nThe code returns `[x3**3, x2**3, x1**3]`, when it _should_ also return monomials such as `x1*x2**2, x2*x3**2, etc...` that also have total degree of 3. This behaviour is inconsistent with the documentation that states that \r\n\r\n> A generator of all monomials `monom` is returned, such that either `min_degree <= total_degree(monom) <= max_degree`...\r\n\r\nThe monomials are also missing when `max_degrees` is increased above `min_degrees`.\n", "patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -127,7 +127,7 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -139,7 +139,7 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\n"}}
{"instance_id": "django__django-13660", "found_files": ["django/core/management/commands/shell.py"], "found_modules": ["django/core/management/commands/shell.py:Command"], "found_entities": ["django/core/management/commands/shell.py:Command.handle"], "raw_output_loc": ["```\ndjango/core/management/commands/shell.py\nline: 87\nclass: Command\nfunction: Command.handle\n```", "```\ndjango/core/management/commands/shell.py\nline: 87\nfunction: Command.handle\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "50c3ac6fa9b7c8a94a6d1dc87edf775e3bc4d575", "problem_statement": "shell command crashes when passing (with -c) the python code with functions.\nDescription\n\t\nThe examples below use Python 3.7 and Django 2.2.16, but I checked that the code is the same on master and works the same in Python 3.8.\nHere's how \u200bpython -c works:\n$ python -c <<EOF \" \nimport django\ndef f():\n\t\tprint(django.__version__)\nf()\"\nEOF\n2.2.16\nHere's how \u200bpython -m django shell -c works (paths shortened for clarify):\n$ python -m django shell -c <<EOF \"\nimport django\ndef f():\n\t\tprint(django.__version__)\nf()\"\nEOF\nTraceback (most recent call last):\n File \"{sys.base_prefix}/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n\t\"__main__\", mod_spec)\n File \"{sys.base_prefix}/lib/python3.7/runpy.py\", line 85, in _run_code\n\texec(code, run_globals)\n File \"{sys.prefix}/lib/python3.7/site-packages/django/__main__.py\", line 9, in <module>\n\tmanagement.execute_from_command_line()\n File \"{sys.prefix}/lib/python3.7/site-packages/django/core/management/__init__.py\", line 381, in execute_from_command_line\n\tutility.execute()\n File \"{sys.prefix}/lib/python3.7/site-packages/django/core/management/__init__.py\", line 375, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"{sys.prefix}/lib/python3.7/site-packages/django/core/management/base.py\", line 323, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"{sys.prefix}/lib/python3.7/site-packages/django/core/management/base.py\", line 364, in execute\n\toutput = self.handle(*args, **options)\n File \"{sys.prefix}/lib/python3.7/site-packages/django/core/management/commands/shell.py\", line 86, in handle\n\texec(options['command'])\n File \"<string>\", line 5, in <module>\n File \"<string>\", line 4, in f\nNameError: name 'django' is not defined\nThe problem is in the \u200busage of \u200bexec:\n\tdef handle(self, **options):\n\t\t# Execute the command and exit.\n\t\tif options['command']:\n\t\t\texec(options['command'])\n\t\t\treturn\n\t\t# Execute stdin if it has anything to read and exit.\n\t\t# Not supported on Windows due to select.select() limitations.\n\t\tif sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n\t\t\texec(sys.stdin.read())\n\t\t\treturn\nexec should be passed a dictionary containing a minimal set of globals. This can be done by just passing a new, empty dictionary as the second argument of exec.\n", "patch": "diff --git a/django/core/management/commands/shell.py b/django/core/management/commands/shell.py\n--- a/django/core/management/commands/shell.py\n+++ b/django/core/management/commands/shell.py\n@@ -84,13 +84,13 @@ def python(self, options):\n     def handle(self, **options):\n         # Execute the command and exit.\n         if options['command']:\n-            exec(options['command'])\n+            exec(options['command'], globals())\n             return\n \n         # Execute stdin if it has anything to read and exit.\n         # Not supported on Windows due to select.select() limitations.\n         if sys.platform != 'win32' and not sys.stdin.isatty() and select.select([sys.stdin], [], [], 0)[0]:\n-            exec(sys.stdin.read())\n+            exec(sys.stdin.read(), globals())\n             return\n \n         available_shells = [options['interface']] if options['interface'] else self.shells\n"}}
{"instance_id": "sympy__sympy-14774", "found_files": ["sympy/printing/latex.py"], "found_modules": ["sympy/printing/latex.py:LatexPrinter"], "found_entities": ["sympy/printing/latex.py:LatexPrinter._print_Function"], "raw_output_loc": ["```\nsympy/printing/latex.py\nline: 743\nclass: LatexPrinter\nfunction: LatexPrinter._print_Function\n```", "```\nsympy/printing/latex.py\nline: 743\nfunction: LatexPrinter._print_Function\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "8fc63c2d71752389a44367b8ef4aba8a91af6a45", "problem_statement": "Latex printer does not support full inverse trig function names for acsc and asec\nFor example\r\n`latex(asin(x), inv_trig_style=\"full\")` works as expected returning `'\\\\arcsin{\\\\left (x \\\\right )}'`\r\nBut `latex(acsc(x), inv_trig_style=\"full\")` gives `'\\\\operatorname{acsc}{\\\\left (x \\\\right )}'` instead of `'\\\\operatorname{arccsc}{\\\\left (x \\\\right )}'`\r\n\r\nA fix seems to be to change line 743 of sympy/printing/latex.py from\r\n`inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]` to\r\n`inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]`\n", "patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -740,7 +740,7 @@ def _print_Function(self, expr, exp=None):\n                 len(args) == 1 and \\\n                 not self._needs_function_brackets(expr.args[0])\n \n-            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acot\"]\n+            inv_trig_table = [\"asin\", \"acos\", \"atan\", \"acsc\", \"asec\", \"acot\"]\n \n             # If the function is an inverse trig function, handle the style\n             if func in inv_trig_table:\n"}}
{"instance_id": "django__django-13028", "found_files": ["django/db/models/sql/query.py"], "found_modules": ["django/db/models/sql/query.py:Query"], "found_entities": ["django/db/models/sql/query.py:Query.check_filterable"], "raw_output_loc": ["```\ndjango/db/models/sql/query.py\nline: 1131\nfunction: Query.check_filterable\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/db/models/sql/query.py\nline: 1127\nfunction: Query.check_filterable\n\nsrc/adminpricing/models.py\nline: [location of filterable field]\nclass: ProductMetaDataType\nfunction: [filterable field definition]\n```"], "meta_data": {"repo": "django/django", "base_commit": "78ad4b4b0201003792bfdbf1a7781cbc9ee03539", "problem_statement": "Queryset raises NotSupportedError when RHS has filterable=False attribute.\nDescription\n\t \n\t\t(last modified by Nicolas Baccelli)\n\t \nI'm migrating my app to django 3.0.7 and I hit a strange behavior using a model class with a field labeled filterable\nclass ProductMetaDataType(models.Model):\n\tlabel = models.CharField(max_length=255, unique=True, blank=False, null=False)\n\tfilterable = models.BooleanField(default=False, verbose_name=_(\"filterable\"))\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose_name = _(\"product meta data type\")\n\t\tverbose_name_plural = _(\"product meta data types\")\n\tdef __str__(self):\n\t\treturn self.label\nclass ProductMetaData(models.Model):\n\tid = models.BigAutoField(primary_key=True)\n\tproduct = models.ForeignKey(\n\t\tProduit, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tvalue = models.TextField(null=False, blank=False)\n\tmarketplace = models.ForeignKey(\n\t\tPlateforme, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tdate_created = models.DateTimeField(null=True, default=timezone.now)\n\tmetadata_type = models.ForeignKey(\n\t\tProductMetaDataType, null=False, blank=False, on_delete=models.CASCADE\n\t)\n\tclass Meta:\n\t\tapp_label = \"adminpricing\"\n\t\tverbose_name = _(\"product meta data\")\n\t\tverbose_name_plural = _(\"product meta datas\")\nError happened when filtering ProductMetaData with a metadata_type :\nProductMetaData.objects.filter(value=\"Dark Vador\", metadata_type=self.brand_metadata)\nError traceback :\nTraceback (most recent call last):\n File \"/backoffice/backoffice/adminpricing/tests/test_pw.py\", line 481, in test_checkpolicywarning_by_fields\n\tfor p in ProductMetaData.objects.filter(\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/manager.py\", line 82, in manager_method\n\treturn getattr(self.get_queryset(), name)(*args, **kwargs)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/query.py\", line 904, in filter\n\treturn self._filter_or_exclude(False, *args, **kwargs)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/query.py\", line 923, in _filter_or_exclude\n\tclone.query.add_q(Q(*args, **kwargs))\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1351, in add_q\n\tclause, _ = self._add_q(q_object, self.used_aliases)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1378, in _add_q\n\tchild_clause, needed_inner = self.build_filter(\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1264, in build_filter\n\tself.check_filterable(value)\n File \"/usr/local/lib/python3.8/site-packages/django/db/models/sql/query.py\", line 1131, in check_filterable\n\traise NotSupportedError(\ndjango.db.utils.NotSupportedError: ProductMetaDataType is disallowed in the filter clause.\nI changed label to filterable_test and it fixed this issue\nThis should be documented or fix.\n", "patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,7 +1124,10 @@ def check_related_objects(self, field, value, opts):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n-        if not getattr(expression, 'filterable', True):\n+        if (\n+            hasattr(expression, 'resolve_expression') and\n+            not getattr(expression, 'filterable', True)\n+        ):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n                 'clause.'\n"}}
{"instance_id": "django__django-14672", "found_files": ["django/db/models/fields/reverse_related.py"], "found_modules": ["django/db/models/fields/reverse_related.py:ManyToManyRel"], "found_entities": ["django/db/models/fields/reverse_related.py:ManyToManyRel.identity"], "raw_output_loc": ["```\ndjango/db/models/fields/reverse_related.py\nline: 313\nclass: ManyToManyRel\nfunction: ManyToManyRel.identity\n```", "```\ndjango/db/models/fields/reverse_related.py\nline: 310\nclass: ManyToManyRel\nfunction: ManyToManyRel.identity\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "00ea883ef56fb5e092cbe4a6f7ff2e7470886ac4", "problem_statement": "Missing call `make_hashable` on `through_fields` in `ManyToManyRel`\nDescription\n\t\nIn 3.2 identity property has been added to all ForeignObjectRel to make it possible to compare them. A hash is derived from said identity and it's possible because identity is a tuple. To make limit_choices_to hashable (one of this tuple elements), \u200bthere's a call to make_hashable.\nIt happens that through_fields can be a list. In such case, this make_hashable call is missing in \u200bManyToManyRel.\nFor some reason it only fails on checking proxy model. I think proxy models have 29 checks and normal ones 24, hence the issue, but that's just a guess.\nMinimal repro:\nclass Parent(models.Model):\n\tname = models.CharField(max_length=256)\nclass ProxyParent(Parent):\n\tclass Meta:\n\t\tproxy = True\nclass Child(models.Model):\n\tparent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n\tmany_to_many_field = models.ManyToManyField(\n\t\tto=Parent,\n\t\tthrough=\"ManyToManyModel\",\n\t\tthrough_fields=['child', 'parent'],\n\t\trelated_name=\"something\"\n\t)\nclass ManyToManyModel(models.Model):\n\tparent = models.ForeignKey(Parent, on_delete=models.CASCADE, related_name='+')\n\tchild = models.ForeignKey(Child, on_delete=models.CASCADE, related_name='+')\n\tsecond_child = models.ForeignKey(Child, on_delete=models.CASCADE, null=True, default=None)\nWhich will result in \n File \"manage.py\", line 23, in <module>\n\tmain()\n File \"manage.py\", line 19, in main\n\texecute_from_command_line(sys.argv)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/__init__.py\", line 419, in execute_from_command_line\n\tutility.execute()\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/__init__.py\", line 413, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 354, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 393, in execute\n\tself.check()\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 419, in check\n\tall_issues = checks.run_checks(\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/checks/registry.py\", line 76, in run_checks\n\tnew_errors = check(app_configs=app_configs, databases=databases)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/checks/model_checks.py\", line 34, in check_all_models\n\terrors.extend(model.check(**kwargs))\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/db/models/base.py\", line 1277, in check\n\t*cls._check_field_name_clashes(),\n File \"/home/tom/PycharmProjects/djangbroken_m2m_projectProject/venv/lib/python3.8/site-packages/django/db/models/base.py\", line 1465, in _check_field_name_clashes\n\tif f not in used_fields:\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/db/models/fields/reverse_related.py\", line 140, in __hash__\n\treturn hash(self.identity)\nTypeError: unhashable type: 'list'\nSolution: Add missing make_hashable call on self.through_fields in ManyToManyRel.\nMissing call `make_hashable` on `through_fields` in `ManyToManyRel`\nDescription\n\t\nIn 3.2 identity property has been added to all ForeignObjectRel to make it possible to compare them. A hash is derived from said identity and it's possible because identity is a tuple. To make limit_choices_to hashable (one of this tuple elements), \u200bthere's a call to make_hashable.\nIt happens that through_fields can be a list. In such case, this make_hashable call is missing in \u200bManyToManyRel.\nFor some reason it only fails on checking proxy model. I think proxy models have 29 checks and normal ones 24, hence the issue, but that's just a guess.\nMinimal repro:\nclass Parent(models.Model):\n\tname = models.CharField(max_length=256)\nclass ProxyParent(Parent):\n\tclass Meta:\n\t\tproxy = True\nclass Child(models.Model):\n\tparent = models.ForeignKey(Parent, on_delete=models.CASCADE)\n\tmany_to_many_field = models.ManyToManyField(\n\t\tto=Parent,\n\t\tthrough=\"ManyToManyModel\",\n\t\tthrough_fields=['child', 'parent'],\n\t\trelated_name=\"something\"\n\t)\nclass ManyToManyModel(models.Model):\n\tparent = models.ForeignKey(Parent, on_delete=models.CASCADE, related_name='+')\n\tchild = models.ForeignKey(Child, on_delete=models.CASCADE, related_name='+')\n\tsecond_child = models.ForeignKey(Child, on_delete=models.CASCADE, null=True, default=None)\nWhich will result in \n File \"manage.py\", line 23, in <module>\n\tmain()\n File \"manage.py\", line 19, in main\n\texecute_from_command_line(sys.argv)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/__init__.py\", line 419, in execute_from_command_line\n\tutility.execute()\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/__init__.py\", line 413, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 354, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 393, in execute\n\tself.check()\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/management/base.py\", line 419, in check\n\tall_issues = checks.run_checks(\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/checks/registry.py\", line 76, in run_checks\n\tnew_errors = check(app_configs=app_configs, databases=databases)\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/core/checks/model_checks.py\", line 34, in check_all_models\n\terrors.extend(model.check(**kwargs))\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/db/models/base.py\", line 1277, in check\n\t*cls._check_field_name_clashes(),\n File \"/home/tom/PycharmProjects/djangbroken_m2m_projectProject/venv/lib/python3.8/site-packages/django/db/models/base.py\", line 1465, in _check_field_name_clashes\n\tif f not in used_fields:\n File \"/home/tom/PycharmProjects/broken_m2m_project/venv/lib/python3.8/site-packages/django/db/models/fields/reverse_related.py\", line 140, in __hash__\n\treturn hash(self.identity)\nTypeError: unhashable type: 'list'\nSolution: Add missing make_hashable call on self.through_fields in ManyToManyRel.\n", "patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -310,7 +310,7 @@ def __init__(self, field, to, related_name=None, related_query_name=None,\n     def identity(self):\n         return super().identity + (\n             self.through,\n-            self.through_fields,\n+            make_hashable(self.through_fields),\n             self.db_constraint,\n         )\n \n"}}
{"instance_id": "matplotlib__matplotlib-26020", "found_files": ["lib/mpl_toolkits/axes_grid1/axes_grid.py", "lib/mpl_toolkits/axes_grid1/mpl_axes.py", "lib/matplotlib/projections/geo.py"], "found_modules": ["lib/mpl_toolkits/axes_grid1/axes_grid.py:_tick_only", "lib/mpl_toolkits/axes_grid1/mpl_axes.py:Axes", "lib/mpl_toolkits/axes_grid1/axes_grid.py:CbarAxesBase", "lib/matplotlib/projections/geo.py:GeoAxes", "lib/mpl_toolkits/axes_grid1/axes_grid.py:Grid"], "found_entities": ["lib/mpl_toolkits/axes_grid1/axes_grid.py:_tick_only", "lib/mpl_toolkits/axes_grid1/mpl_axes.py:Axes.axis", "lib/mpl_toolkits/axes_grid1/axes_grid.py:CbarAxesBase.colorbar", "lib/matplotlib/projections/geo.py:GeoAxes._init_axis", "lib/mpl_toolkits/axes_grid1/axes_grid.py:Grid.set_label_mode"], "raw_output_loc": ["```\nlib/mpl_toolkits/axes_grid1/axes_grid.py\nline: 16\nfunction: _tick_only\n\nlib/mpl_toolkits/axes_grid1/mpl_axes.py\nline: 44\nclass: Axes\nfunction: Axes.axis\n\nlib/matplotlib/projections/geo.py\nline: 15\nclass: GeoAxes\nfunction: GeoAxes._init_axis\n\nlib/mpl_toolkits/axes_grid1/axes_grid.py\nline: 389\nfunction: Grid.set_label_mode\n\nlib/mpl_toolkits/axes_grid1/axes_grid.py\nline: 618\nfunction: Grid.__init__\n```", "```\nlib/mpl_toolkits/axes_grid1/axes_grid.py\nline: 27\nfunction: _tick_only\n\nlib/mpl_toolkits/axes_grid1/mpl_axes.py\nline: 44\nfunction: Axes.axis\n\nlib/matplotlib/projections/geo.py\nfunction: GeoAxes\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "f6a781f77f5ddf1204c60ca7c544809407d4a807", "problem_statement": "Error creating AxisGrid with non-default axis class\n<!--To help us understand and resolve your issue, please fill out the form to the best of your ability.-->\r\n<!--You can feel free to delete the sections that do not apply.-->\r\n\r\n### Bug report\r\n\r\n**Bug summary**\r\n\r\nCreating `AxesGrid` using cartopy `GeoAxes` as `axis_class` raises `TypeError: 'method' object is not subscriptable`. Seems to be due to different behaviour of `axis` attr. for `mpl_toolkits.axes_grid1.mpl_axes.Axes` and other axes instances (like `GeoAxes`) where `axis` is only a callable. The error is raised in method `mpl_toolkits.axes_grid1.axes_grid._tick_only` when trying to access keys from `axis` attr.\r\n\r\n**Code for reproduction**\r\n\r\n<!--A minimum code snippet required to reproduce the bug.\r\nPlease make sure to minimize the number of dependencies required, and provide\r\nany necessary plotted data.\r\nAvoid using threads, as Matplotlib is (explicitly) not thread-safe.-->\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nfrom cartopy.crs import PlateCarree\r\nfrom cartopy.mpl.geoaxes import GeoAxes\r\nfrom mpl_toolkits.axes_grid1 import AxesGrid\r\n\r\nfig = plt.figure()\r\naxes_class = (GeoAxes, dict(map_projection=PlateCarree()))\r\ngr = AxesGrid(fig, 111, nrows_ncols=(1,1),\r\n              axes_class=axes_class)\r\n```\r\n\r\n**Actual outcome**\r\n\r\n<!--The output produced by the above code, which may be a screenshot, console output, etc.-->\r\n\r\n```\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/jonasg/stuff/bugreport_mpl_toolkits_AxesGrid.py\", line 16, in <module>\r\n    axes_class=axes_class)\r\n\r\n  File \"/home/jonasg/miniconda3/envs/pya/lib/python3.7/site-packages/mpl_toolkits/axes_grid1/axes_grid.py\", line 618, in __init__\r\n    self.set_label_mode(label_mode)\r\n\r\n  File \"/home/jonasg/miniconda3/envs/pya/lib/python3.7/site-packages/mpl_toolkits/axes_grid1/axes_grid.py\", line 389, in set_label_mode\r\n    _tick_only(ax, bottom_on=False, left_on=False)\r\n\r\n  File \"/home/jonasg/miniconda3/envs/pya/lib/python3.7/site-packages/mpl_toolkits/axes_grid1/axes_grid.py\", line 27, in _tick_only\r\n    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\r\n\r\nTypeError: 'method' object is not subscriptable\r\n```\r\n\r\n**Expected outcome**\r\n\r\n<!--A description of the expected outcome from the code snippet-->\r\n<!--If this used to work in an earlier version of Matplotlib, please note the version it used to work on-->\r\n\r\n**Matplotlib version**\r\n<!--Please specify your platform and versions of the relevant libraries you are using:-->\r\n  * Operating system: Ubuntu 18.04.4 LTS\r\n  * Matplotlib version: 3.1.2 (conda-forge)\r\n  * Matplotlib backend: Qt5Agg \r\n  * Python version: 3.7.6\r\n  * Jupyter version (if applicable):\r\n  * Other libraries: \r\n\r\n```\r\n# Name                    Version                   Build  Channel\r\n_libgcc_mutex             0.1                 conda_forge    conda-forge\r\n_openmp_mutex             4.5                       0_gnu    conda-forge\r\nalabaster                 0.7.12                   py37_0  \r\nantlr-python-runtime      4.7.2                 py37_1001    conda-forge\r\nargh                      0.26.2                   py37_0  \r\nastroid                   2.3.3                    py37_0  \r\natomicwrites              1.3.0                    py37_1  \r\nattrs                     19.3.0                     py_0    conda-forge\r\nautopep8                  1.4.4                      py_0  \r\nbabel                     2.8.0                      py_0  \r\nbackcall                  0.1.0                    py37_0  \r\nbasemap                   1.2.1            py37hd759880_1    conda-forge\r\nbleach                    3.1.0                    py37_0  \r\nbokeh                     1.4.0                    py37_0    conda-forge\r\nbzip2                     1.0.8                h516909a_2    conda-forge\r\nca-certificates           2019.11.28           hecc5488_0    conda-forge\r\ncartopy                   0.17.0          py37hd759880_1006    conda-forge\r\ncertifi                   2019.11.28               py37_0    conda-forge\r\ncf-units                  2.1.3            py37hc1659b7_0    conda-forge\r\ncf_units                  2.0.1           py37h3010b51_1002    conda-forge\r\ncffi                      1.13.2           py37h8022711_0    conda-forge\r\ncftime                    1.0.4.2          py37hc1659b7_0    conda-forge\r\nchardet                   3.0.4                 py37_1003    conda-forge\r\nclick                     7.0                        py_0    conda-forge\r\ncloudpickle               1.2.2                      py_1    conda-forge\r\ncryptography              2.8              py37h72c5cf5_1    conda-forge\r\ncurl                      7.65.3               hf8cf82a_0    conda-forge\r\ncycler                    0.10.0                     py_2    conda-forge\r\ncytoolz                   0.10.1           py37h516909a_0    conda-forge\r\ndask                      2.9.2                      py_0    conda-forge\r\ndask-core                 2.9.2                      py_0    conda-forge\r\ndbus                      1.13.6               he372182_0    conda-forge\r\ndecorator                 4.4.1                      py_0  \r\ndefusedxml                0.6.0                      py_0  \r\ndiff-match-patch          20181111                   py_0  \r\ndistributed               2.9.3                      py_0    conda-forge\r\ndocutils                  0.16                     py37_0  \r\nentrypoints               0.3                      py37_0  \r\nexpat                     2.2.5             he1b5a44_1004    conda-forge\r\nflake8                    3.7.9                    py37_0  \r\nfontconfig                2.13.1            h86ecdb6_1001    conda-forge\r\nfreetype                  2.10.0               he983fc9_1    conda-forge\r\nfsspec                    0.6.2                      py_0    conda-forge\r\nfuture                    0.18.2                   py37_0  \r\ngeonum                    1.4.4                      py_0    conda-forge\r\ngeos                      3.7.2                he1b5a44_2    conda-forge\r\ngettext                   0.19.8.1          hc5be6a0_1002    conda-forge\r\nglib                      2.58.3          py37h6f030ca_1002    conda-forge\r\ngmp                       6.1.2                h6c8ec71_1  \r\ngpxpy                     1.4.0                      py_0    conda-forge\r\ngst-plugins-base          1.14.5               h0935bb2_0    conda-forge\r\ngstreamer                 1.14.5               h36ae1b5_0    conda-forge\r\nhdf4                      4.2.13            hf30be14_1003    conda-forge\r\nhdf5                      1.10.5          nompi_h3c11f04_1104    conda-forge\r\nheapdict                  1.0.1                      py_0    conda-forge\r\nicu                       64.2                 he1b5a44_1    conda-forge\r\nidna                      2.8                   py37_1000    conda-forge\r\nimagesize                 1.2.0                      py_0  \r\nimportlib_metadata        1.4.0                    py37_0    conda-forge\r\nintervaltree              3.0.2                      py_0  \r\nipykernel                 5.1.4            py37h39e3cac_0  \r\nipython                   7.11.1           py37h39e3cac_0  \r\nipython_genutils          0.2.0                    py37_0  \r\niris                      2.2.0                 py37_1003    conda-forge\r\nisort                     4.3.21                   py37_0  \r\njedi                      0.14.1                   py37_0  \r\njeepney                   0.4.2                      py_0  \r\njinja2                    2.10.3                     py_0    conda-forge\r\njpeg                      9c                h14c3975_1001    conda-forge\r\njson5                     0.8.5                      py_0  \r\njsonschema                3.2.0                    py37_0  \r\njupyter_client            5.3.4                    py37_0  \r\njupyter_core              4.6.1                    py37_0  \r\njupyterlab                1.2.5              pyhf63ae98_0  \r\njupyterlab_server         1.0.6                      py_0  \r\nkeyring                   21.1.0                   py37_0  \r\nkiwisolver                1.1.0            py37hc9558a2_0    conda-forge\r\nkrb5                      1.16.4               h2fd8d38_0    conda-forge\r\nlatlon23                  1.0.7                      py_0    conda-forge\r\nlazy-object-proxy         1.4.3            py37h7b6447c_0  \r\nld_impl_linux-64          2.33.1               h53a641e_7    conda-forge\r\nlibblas                   3.8.0               14_openblas    conda-forge\r\nlibcblas                  3.8.0               14_openblas    conda-forge\r\nlibclang                  9.0.1           default_hde54327_0    conda-forge\r\nlibcurl                   7.65.3               hda55be3_0    conda-forge\r\nlibedit                   3.1.20170329      hf8c457e_1001    conda-forge\r\nlibffi                    3.2.1             he1b5a44_1006    conda-forge\r\nlibgcc-ng                 9.2.0                h24d8f2e_2    conda-forge\r\nlibgfortran-ng            7.3.0                hdf63c60_4    conda-forge\r\nlibgomp                   9.2.0                h24d8f2e_2    conda-forge\r\nlibiconv                  1.15              h516909a_1005    conda-forge\r\nliblapack                 3.8.0               14_openblas    conda-forge\r\nlibllvm9                  9.0.1                hc9558a2_0    conda-forge\r\nlibnetcdf                 4.7.3           nompi_h94020b1_100    conda-forge\r\nlibopenblas               0.3.7                h5ec1e0e_6    conda-forge\r\nlibpng                    1.6.37               hed695b0_0    conda-forge\r\nlibsodium                 1.0.16               h1bed415_0  \r\nlibspatialindex           1.9.3                he6710b0_0  \r\nlibssh2                   1.8.2                h22169c7_2    conda-forge\r\nlibstdcxx-ng              9.2.0                hdf63c60_2    conda-forge\r\nlibtiff                   4.1.0                hc3755c2_3    conda-forge\r\nlibuuid                   2.32.1            h14c3975_1000    conda-forge\r\nlibxcb                    1.13              h14c3975_1002    conda-forge\r\nlibxkbcommon              0.9.1                hebb1f50_0    conda-forge\r\nlibxml2                   2.9.10               hee79883_0    conda-forge\r\nlocket                    0.2.0                      py_2    conda-forge\r\nlz4-c                     1.8.3             he1b5a44_1001    conda-forge\r\nmarkupsafe                1.1.1            py37h516909a_0    conda-forge\r\nmatplotlib                3.1.2                    py37_1    conda-forge\r\nmatplotlib-base           3.1.2            py37h250f245_1    conda-forge\r\nmccabe                    0.6.1                    py37_1  \r\nmistune                   0.8.4            py37h7b6447c_0  \r\nmore-itertools            8.1.0                      py_0    conda-forge\r\nmsgpack-python            0.6.2            py37hc9558a2_0    conda-forge\r\nnbconvert                 5.6.1                    py37_0  \r\nnbformat                  5.0.4                      py_0  \r\nnbsphinx                  0.5.1                      py_0    conda-forge\r\nncurses                   6.1               hf484d3e_1002    conda-forge\r\nnetcdf4                   1.5.3           nompi_py37hd35fb8e_102    conda-forge\r\nnotebook                  6.0.3                    py37_0  \r\nnspr                      4.24                 he1b5a44_0    conda-forge\r\nnss                       3.47                 he751ad9_0    conda-forge\r\nnumpy                     1.17.5           py37h95a1406_0    conda-forge\r\nnumpydoc                  0.9.2                      py_0  \r\nolefile                   0.46                       py_0    conda-forge\r\nopenssl                   1.1.1d               h516909a_0    conda-forge\r\nowslib                    0.19.0                     py_2    conda-forge\r\npackaging                 20.0                       py_0    conda-forge\r\npandas                    0.25.3           py37hb3f55d8_0    conda-forge\r\npandoc                    2.2.3.2                       0  \r\npandocfilters             1.4.2                    py37_1  \r\nparso                     0.6.0                      py_0  \r\npartd                     1.1.0                      py_0    conda-forge\r\npathtools                 0.1.2                      py_1  \r\npatsy                     0.5.1                      py_0    conda-forge\r\npcre                      8.43                 he1b5a44_0    conda-forge\r\npexpect                   4.8.0                    py37_0  \r\npickleshare               0.7.5                    py37_0  \r\npillow                    7.0.0            py37hefe7db6_0    conda-forge\r\npip                       20.0.1                   py37_0    conda-forge\r\npluggy                    0.13.0                   py37_0    conda-forge\r\nproj4                     5.2.0             he1b5a44_1006    conda-forge\r\nprometheus_client         0.7.1                      py_0  \r\nprompt_toolkit            3.0.3                      py_0  \r\npsutil                    5.6.7            py37h516909a_0    conda-forge\r\npthread-stubs             0.4               h14c3975_1001    conda-forge\r\nptyprocess                0.6.0                    py37_0  \r\npy                        1.8.1                      py_0    conda-forge\r\npyaerocom                 0.9.0.dev5                dev_0    <develop>\r\npycodestyle               2.5.0                    py37_0  \r\npycparser                 2.19                     py37_1    conda-forge\r\npydocstyle                4.0.1                      py_0  \r\npyepsg                    0.4.0                      py_0    conda-forge\r\npyflakes                  2.1.1                    py37_0  \r\npygments                  2.5.2                      py_0  \r\npyinstrument              3.1.2                    pypi_0    pypi\r\npyinstrument-cext         0.2.2                    pypi_0    pypi\r\npykdtree                  1.3.1           py37hc1659b7_1002    conda-forge\r\npyke                      1.1.1                 py37_1001    conda-forge\r\npylint                    2.4.4                    py37_0  \r\npyopenssl                 19.1.0                   py37_0    conda-forge\r\npyparsing                 2.4.6                      py_0    conda-forge\r\npyproj                    1.9.6           py37h516909a_1002    conda-forge\r\npyqt                      5.12.3           py37hcca6a23_1    conda-forge\r\npyqt5-sip                 4.19.18                  pypi_0    pypi\r\npyqtwebengine             5.12.1                   pypi_0    pypi\r\npyrsistent                0.15.7           py37h7b6447c_0  \r\npyshp                     2.1.0                      py_0    conda-forge\r\npysocks                   1.7.1                    py37_0    conda-forge\r\npytest                    5.3.4                    py37_0    conda-forge\r\npython                    3.7.6                h357f687_2    conda-forge\r\npython-dateutil           2.8.1                      py_0    conda-forge\r\npython-jsonrpc-server     0.3.4                      py_0  \r\npython-language-server    0.31.7                   py37_0  \r\npytz                      2019.3                     py_0    conda-forge\r\npyxdg                     0.26                       py_0  \r\npyyaml                    5.3              py37h516909a_0    conda-forge\r\npyzmq                     18.1.0           py37he6710b0_0  \r\nqdarkstyle                2.8                        py_0  \r\nqt                        5.12.5               hd8c4c69_1    conda-forge\r\nqtawesome                 0.6.1                      py_0  \r\nqtconsole                 4.6.0                      py_1  \r\nqtpy                      1.9.0                      py_0  \r\nreadline                  8.0                  hf8c457e_0    conda-forge\r\nrequests                  2.22.0                   py37_1    conda-forge\r\nrope                      0.16.0                     py_0  \r\nrtree                     0.9.3                    py37_0  \r\nscipy                     1.4.1            py37h921218d_0    conda-forge\r\nseaborn                   0.9.0                      py_2    conda-forge\r\nsecretstorage             3.1.2                    py37_0  \r\nsend2trash                1.5.0                    py37_0  \r\nsetuptools                45.1.0                   py37_0    conda-forge\r\nshapely                   1.6.4           py37hec07ddf_1006    conda-forge\r\nsimplejson                3.17.0           py37h516909a_0    conda-forge\r\nsix                       1.14.0                   py37_0    conda-forge\r\nsnowballstemmer           2.0.0                      py_0  \r\nsortedcontainers          2.1.0                      py_0    conda-forge\r\nsphinx                    2.3.1                      py_0  \r\nsphinx-rtd-theme          0.4.3                    pypi_0    pypi\r\nsphinxcontrib-applehelp   1.0.1                      py_0  \r\nsphinxcontrib-devhelp     1.0.1                      py_0  \r\nsphinxcontrib-htmlhelp    1.0.2                      py_0  \r\nsphinxcontrib-jsmath      1.0.1                      py_0  \r\nsphinxcontrib-qthelp      1.0.2                      py_0  \r\nsphinxcontrib-serializinghtml 1.1.3                      py_0  \r\nspyder                    4.0.1                    py37_0  \r\nspyder-kernels            1.8.1                    py37_0  \r\nsqlite                    3.30.1               hcee41ef_0    conda-forge\r\nsrtm.py                   0.3.4                      py_0    conda-forge\r\nstatsmodels               0.11.0           py37h516909a_0    conda-forge\r\ntblib                     1.6.0                      py_0    conda-forge\r\nterminado                 0.8.3                    py37_0  \r\ntestpath                  0.4.4                      py_0  \r\ntk                        8.6.10               hed695b0_0    conda-forge\r\ntoolz                     0.10.0                     py_0    conda-forge\r\ntornado                   6.0.3            py37h516909a_0    conda-forge\r\ntqdm                      4.43.0                   pypi_0    pypi\r\ntraitlets                 4.3.3                    py37_0  \r\nudunits2                  2.2.27.6          h4e0c4b3_1001    conda-forge\r\nujson                     1.35             py37h14c3975_0  \r\nurllib3                   1.25.7                   py37_0    conda-forge\r\nwatchdog                  0.9.0                    py37_1  \r\nwcwidth                   0.1.8                      py_0    conda-forge\r\nwebencodings              0.5.1                    py37_1  \r\nwheel                     0.33.6                   py37_0    conda-forge\r\nwrapt                     1.11.2           py37h7b6447c_0  \r\nwurlitzer                 2.0.0                    py37_0  \r\nxarray                    0.14.1                     py_1    conda-forge\r\nxorg-libxau               1.0.9                h14c3975_0    conda-forge\r\nxorg-libxdmcp             1.1.3                h516909a_0    conda-forge\r\nxz                        5.2.4             h14c3975_1001    conda-forge\r\nyaml                      0.2.2                h516909a_1    conda-forge\r\nyapf                      0.28.0                     py_0  \r\nzeromq                    4.3.1                he6710b0_3  \r\nzict                      1.0.0                      py_0    conda-forge\r\nzipp                      2.0.0                      py_2    conda-forge\r\nzlib                      1.2.11            h516909a_1006    conda-forge\r\nzstd                      1.4.4                h3b9ef0a_1    conda-forge\r\n```\r\n\n", "patch": "diff --git a/lib/mpl_toolkits/axes_grid1/axes_grid.py b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n--- a/lib/mpl_toolkits/axes_grid1/axes_grid.py\n+++ b/lib/mpl_toolkits/axes_grid1/axes_grid.py\n@@ -1,5 +1,6 @@\n from numbers import Number\n import functools\n+from types import MethodType\n \n import numpy as np\n \n@@ -7,14 +8,20 @@\n from matplotlib.gridspec import SubplotSpec\n \n from .axes_divider import Size, SubplotDivider, Divider\n-from .mpl_axes import Axes\n+from .mpl_axes import Axes, SimpleAxisArtist\n \n \n def _tick_only(ax, bottom_on, left_on):\n     bottom_off = not bottom_on\n     left_off = not left_on\n-    ax.axis[\"bottom\"].toggle(ticklabels=bottom_off, label=bottom_off)\n-    ax.axis[\"left\"].toggle(ticklabels=left_off, label=left_off)\n+    if isinstance(ax.axis, MethodType):\n+        bottom = SimpleAxisArtist(ax.xaxis, 1, ax.spines[\"bottom\"])\n+        left = SimpleAxisArtist(ax.yaxis, 1, ax.spines[\"left\"])\n+    else:\n+        bottom = ax.axis[\"bottom\"]\n+        left = ax.axis[\"left\"]\n+    bottom.toggle(ticklabels=bottom_off, label=bottom_off)\n+    left.toggle(ticklabels=left_off, label=left_off)\n \n \n class CbarAxesBase:\n"}}
{"instance_id": "sympy__sympy-13480", "found_files": ["sympy/functions/elementary/hyperbolic.py"], "found_modules": ["sympy/functions/elementary/hyperbolic.py:coth"], "found_entities": ["sympy/functions/elementary/hyperbolic.py:coth.eval"], "raw_output_loc": ["```\nsympy/functions/elementary/hyperbolic.py\nline: 590\nclass: coth\nfunction: coth.eval\n```", "```\nsympy/functions/elementary/hyperbolic.py\nline: 590\nfunction: coth.eval\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "f57fe3f4b3f2cab225749e1b3b38ae1bf80b62f0", "problem_statement": ".subs on coth(log(tan(x))) errors for certain integral values\n    >>> from sympy import *\r\n    >>> x = Symbol('x')\r\n    >>> e = coth(log(tan(x)))\r\n    >>> print(e.subs(x, 2))\r\n    ...\r\n    File \"C:\\Users\\E\\Desktop\\sympy-master\\sympy\\functions\\elementary\\hyperbolic.py\", line 590, in eval\r\n        if cotm is S.ComplexInfinity:\r\n    NameError: name 'cotm' is not defined\r\n\r\nFails for 2, 3, 5, 6, 8, 9, 11, 12, 13, 15, 18, ... etc.\n", "patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,7 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n"}}
{"instance_id": "django__django-16910", "found_files": ["django/db/models/sql/query.py", "django/db/models/sql/compiler.py"], "found_modules": ["django/db/models/sql/query.py:Query", "django/db/models/sql/compiler.py:SQLCompiler"], "found_entities": ["django/db/models/sql/query.py:Query.add_immediate_loading", "django/db/models/sql/query.py:Query._get_only_select_mask", "django/db/models/sql/query.py:Query.add_select_related", "django/db/models/sql/compiler.py:SQLCompiler.get_select", "django/db/models/sql/compiler.py:SQLCompiler.get_related_selections"], "raw_output_loc": ["```\ndjango/db/models/sql/query.py\nline: 2330\nfunction: Query.add_immediate_loading\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/db/models/sql/query.py:Query._get_only_select_mask\nline: 775\nfunction: Query._get_only_select_mask\n\ndjango/db/models/sql/query.py:Query.add_select_related\nline: 2252\nfunction: Query.add_select_related\n\ndjango/db/models/sql/compiler.py:SQLCompiler.get_select\nfunction: SQLCompiler.get_select\n\ndjango/db/models/sql/compiler.py:SQLCompiler.get_related_selections\nfunction: SQLCompiler.get_related_selections\n\ndjango/db/models/sql/compiler.py:select_related_descend\nfunction: select_related_descend\n```"], "meta_data": {"repo": "django/django", "base_commit": "4142739af1cda53581af4169dbe16d6cd5e26948", "problem_statement": "QuerySet.only() doesn't work with select_related() on a reverse OneToOneField relation.\nDescription\n\t\nOn Django 4.2 calling only() with select_related() on a query using the reverse lookup for a OneToOne relation does not generate the correct query.\nAll the fields from the related model are still included in the generated SQL.\nSample models:\nclass Main(models.Model):\n\tmain_field_1 = models.CharField(blank=True, max_length=45)\n\tmain_field_2 = models.CharField(blank=True, max_length=45)\n\tmain_field_3 = models.CharField(blank=True, max_length=45)\nclass Secondary(models.Model):\n\tmain = models.OneToOneField(Main, primary_key=True, related_name='secondary', on_delete=models.CASCADE)\n\tsecondary_field_1 = models.CharField(blank=True, max_length=45)\n\tsecondary_field_2 = models.CharField(blank=True, max_length=45)\n\tsecondary_field_3 = models.CharField(blank=True, max_length=45)\nSample code:\nMain.objects.select_related('secondary').only('main_field_1', 'secondary__secondary_field_1')\nGenerated query on Django 4.2.1:\nSELECT \"bugtest_main\".\"id\", \"bugtest_main\".\"main_field_1\", \"bugtest_secondary\".\"main_id\", \"bugtest_secondary\".\"secondary_field_1\", \"bugtest_secondary\".\"secondary_field_2\", \"bugtest_secondary\".\"secondary_field_3\" FROM \"bugtest_main\" LEFT OUTER JOIN \"bugtest_secondary\" ON (\"bugtest_main\".\"id\" = \"bugtest_secondary\".\"main_id\")\nGenerated query on Django 4.1.9:\nSELECT \"bugtest_main\".\"id\", \"bugtest_main\".\"main_field_1\", \"bugtest_secondary\".\"main_id\", \"bugtest_secondary\".\"secondary_field_1\" FROM \"bugtest_main\" LEFT OUTER JOIN \"bugtest_secondary\" ON (\"bugtest_main\".\"id\" = \"bugtest_secondary\".\"main_id\")\n", "patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -779,7 +779,13 @@ def _get_only_select_mask(self, opts, mask, select_mask=None):\n         # Only include fields mentioned in the mask.\n         for field_name, field_mask in mask.items():\n             field = opts.get_field(field_name)\n-            field_select_mask = select_mask.setdefault(field, {})\n+            # Retrieve the actual field associated with reverse relationships\n+            # as that's what is expected in the select mask.\n+            if field in opts.related_objects:\n+                field_key = field.field\n+            else:\n+                field_key = field\n+            field_select_mask = select_mask.setdefault(field_key, {})\n             if field_mask:\n                 if not field.is_relation:\n                     raise FieldError(next(iter(field_mask)))\n"}}
{"instance_id": "sympy__sympy-18057", "found_files": ["sympy/core/expr.py", "sympy/core/sympify.py", "sympy/parsing/sympy_parser.py"], "found_modules": ["sympy/core/expr.py:Expr", "sympy/core/sympify.py:sympify", "sympy/parsing/sympy_parser.py:parse_expr", "sympy/parsing/sympy_parser.py:eval_expr", "sympy/parsing/sympy_parser.py:evaluateFalse"], "found_entities": ["sympy/core/expr.py:Expr.__eq__", "sympy/core/sympify.py:sympify", "sympy/parsing/sympy_parser.py:parse_expr", "sympy/parsing/sympy_parser.py:eval_expr", "sympy/parsing/sympy_parser.py:evaluateFalse"], "raw_output_loc": ["```\nsympy/core/expr.py\nline: 124\nfunction: Expr.__eq__\n\nsympy/core/sympify.py\nline: 385\nfunction: sympify\n\nsympy/parsing/sympy_parser.py\nline: 1011\nfunction: parse_expr\n\nsympy/parsing/sympy_parser.py\nline: 906\nfunction: eval_expr\n```", "```\nsympy/core/expr.py\nline: 124\nclass: Expr\nfunction: Expr.__eq__\n\nsympy/core/sympify.py\nline: 365\nfunction: sympify\n\nsympy/parsing/sympy_parser.py\nline: 908\nfunction: parse_expr\n\nsympy/parsing/sympy_parser.py\nline: 896\nfunction: eval_expr\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "62000f37b8821573ba00280524ffb4ac4a380875", "problem_statement": "Sympy incorrectly attempts to eval reprs in its __eq__ method\nPassing strings produced by unknown objects into eval is **very bad**. It is especially surprising for an equality check to trigger that kind of behavior. This should be fixed ASAP.\r\n\r\nRepro code:\r\n\r\n```\r\nimport sympy\r\nclass C:\r\n    def __repr__(self):\r\n        return 'x.y'\r\n_ = sympy.Symbol('x') == C()\r\n```\r\n\r\nResults in:\r\n\r\n```\r\nE   AttributeError: 'Symbol' object has no attribute 'y'\r\n```\r\n\r\nOn the line:\r\n\r\n```\r\n    expr = eval(\r\n        code, global_dict, local_dict)  # take local objects in preference\r\n```\r\n\r\nWhere code is:\r\n\r\n```\r\nSymbol ('x' ).y\r\n```\r\n\r\nFull trace:\r\n\r\n```\r\nFAILED                   [100%]\r\n        class C:\r\n            def __repr__(self):\r\n                return 'x.y'\r\n    \r\n>       _ = sympy.Symbol('x') == C()\r\n\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\nsympy/core/expr.py:124: in __eq__\r\n    other = sympify(other)\r\nsympy/core/sympify.py:385: in sympify\r\n    expr = parse_expr(a, local_dict=locals, transformations=transformations, evaluate=evaluate)\r\nsympy/parsing/sympy_parser.py:1011: in parse_expr\r\n    return eval_expr(code, local_dict, global_dict)\r\nsympy/parsing/sympy_parser.py:906: in eval_expr\r\n    code, global_dict, local_dict)  # take local objects in preference\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n>   ???\r\nE   AttributeError: 'Symbol' object has no attribute 'y'\r\n\r\n<string>:1: AttributeError\r\n```\r\n\r\nRelated issue: an unknown object whose repr is `x` will incorrectly compare as equal to a sympy symbol x:\r\n\r\n```\r\n    class C:\r\n        def __repr__(self):\r\n            return 'x'\r\n\r\n    assert sympy.Symbol('x') != C()  # fails\r\n```\n", "patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -121,7 +121,7 @@ def _hashable_content(self):\n \n     def __eq__(self, other):\n         try:\n-            other = sympify(other)\n+            other = _sympify(other)\n             if not isinstance(other, Expr):\n                 return False\n         except (SympifyError, SyntaxError):\n"}}
{"instance_id": "django__django-11179", "found_files": ["django/db/models/deletion.py"], "found_modules": ["django/db/models/deletion.py:Collector"], "found_entities": ["django/db/models/deletion.py:Collector.delete"], "raw_output_loc": ["```\ndjango/db/models/deletion.py\nline: 280\nclass: Collector\nfunction: Collector.delete\n```", "```\ndjango/db/models/deletion.py\nline: 276\nline: 280\nclass: Collector\nfunction: Collector.delete\n```"], "meta_data": {"repo": "django/django", "base_commit": "19fc6376ce67d01ca37a91ef2f55ef769f50513a", "problem_statement": "delete() on instances of models without any dependencies doesn't clear PKs.\nDescription\n\t\nDeleting any model with no dependencies not updates the PK on the model. It should be set to None after .delete() call.\nSee Django.db.models.deletion:276-281. Should update the model line 280.\n", "patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,7 @@ def delete(self):\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n"}}
{"instance_id": "django__django-13230", "found_files": ["django/contrib/syndication/views.py"], "found_modules": ["django/contrib/syndication/views.py:Feed"], "found_entities": ["django/contrib/syndication/views.py:Feed.get_feed", "django/contrib/syndication/views.py:Feed.item_extra_kwargs"], "raw_output_loc": ["```\ndjango/contrib/syndication/views.py\nline: 202\nclass: Feed\nfunction: Feed.get_feed\n\n```", "```\ndjango/contrib/syndication/views.py\nline: 103\nfunction: Feed.item_extra_kwargs\n```"], "meta_data": {"repo": "django/django", "base_commit": "184a6eebb0ef56d5f1b1315a8e666830e37f3f81", "problem_statement": "Add support for item_comments to syndication framework\nDescription\n\t\nAdd comments argument to feed.add_item() in syndication.views so that item_comments can be defined directly without having to take the detour via item_extra_kwargs .\nAdditionally, comments is already explicitly mentioned in the feedparser, but not implemented in the view.\n", "patch": "diff --git a/django/contrib/syndication/views.py b/django/contrib/syndication/views.py\n--- a/django/contrib/syndication/views.py\n+++ b/django/contrib/syndication/views.py\n@@ -212,6 +212,7 @@ def get_feed(self, obj, request):\n                 author_name=author_name,\n                 author_email=author_email,\n                 author_link=author_link,\n+                comments=self._get_dynamic_attr('item_comments', item),\n                 categories=self._get_dynamic_attr('item_categories', item),\n                 item_copyright=self._get_dynamic_attr('item_copyright', item),\n                 **self.item_extra_kwargs(item)\n"}}
{"instance_id": "pytest-dev__pytest-5692", "found_files": ["src/_pytest/junitxml.py"], "found_modules": ["src/_pytest/junitxml.py:LogXML"], "found_entities": ["src/_pytest/junitxml.py:LogXML.pytest_sessionfinish"], "raw_output_loc": ["```\nsrc/_pytest/junitxml.py\nline: 660\nline: 661\nclass: LogXML\nfunction: LogXML.pytest_sessionfinish\n```", "```\nsrc/_pytest/junitxml.py\nline: 660\nclass: LogXML\nfunction: LogXML.pytest_sessionfinish\n\nsrc/_pytest/junitxml.py\nline: 669\nclass: LogXML\nfunction: LogXML.pytest_sessionfinish\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "29e336bd9bf87eaef8e2683196ee1975f1ad4088", "problem_statement": "Hostname and timestamp properties in generated JUnit XML reports\nPytest enables generating JUnit XML reports of the tests.\r\n\r\nHowever, there are some properties missing, specifically `hostname` and `timestamp` from the `testsuite` XML element. Is there an option to include them?\r\n\r\nExample of a pytest XML report:\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n<testsuite errors=\"0\" failures=\"2\" name=\"check\" skipped=\"0\" tests=\"4\" time=\"0.049\">\r\n\t<testcase classname=\"test_sample.TestClass\" file=\"test_sample.py\" line=\"3\" name=\"test_addOne_normal\" time=\"0.001\"></testcase>\r\n\t<testcase classname=\"test_sample.TestClass\" file=\"test_sample.py\" line=\"6\" name=\"test_addOne_edge\" time=\"0.001\"></testcase>\r\n</testsuite>\r\n```\r\n\r\nExample of a junit XML report:\r\n```xml\r\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<testsuite name=\"location.GeoLocationTest\" tests=\"2\" skipped=\"0\" failures=\"0\" errors=\"0\" timestamp=\"2019-04-22T10:32:27\" hostname=\"Anass-MacBook-Pro.local\" time=\"0.048\">\r\n  <properties/>\r\n  <testcase name=\"testIoException()\" classname=\"location.GeoLocationTest\" time=\"0.044\"/>\r\n  <testcase name=\"testJsonDeserialization()\" classname=\"location.GeoLocationTest\" time=\"0.003\"/>\r\n  <system-out><![CDATA[]]></system-out>\r\n  <system-err><![CDATA[]]></system-err>\r\n</testsuite>\r\n```\n", "patch": "diff --git a/src/_pytest/junitxml.py b/src/_pytest/junitxml.py\n--- a/src/_pytest/junitxml.py\n+++ b/src/_pytest/junitxml.py\n@@ -10,9 +10,11 @@\n \"\"\"\n import functools\n import os\n+import platform\n import re\n import sys\n import time\n+from datetime import datetime\n \n import py\n \n@@ -666,6 +668,8 @@ def pytest_sessionfinish(self):\n             skipped=self.stats[\"skipped\"],\n             tests=numtests,\n             time=\"%.3f\" % suite_time_delta,\n+            timestamp=datetime.fromtimestamp(self.suite_start_time).isoformat(),\n+            hostname=platform.node(),\n         )\n         logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n         logfile.close()\n"}}
{"instance_id": "django__django-13925", "found_files": ["django/apps/config.py", "django/db/models/base.py"], "found_modules": ["django/apps/config.py:AppConfig", "django/db/models/base.py:Model"], "found_entities": ["django/apps/config.py:AppConfig.default_auto_field", "django/db/models/base.py:Model._check_single_primary_key"], "raw_output_loc": ["```\ndjango/apps/config.py:AppConfig.default_auto_field\nfunction: AppConfig.default_auto_field\n\ncore/utils/helper_functions.py\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nfunction: load_app_configuration\n```", "```\ndjango/db/models/base.py\nline: 1556\nfunction: Model._check_single_primary_key\n\ncore/settings.py\nfunction: DEFAULT_AUTO_FIELD\n\naccounts/models.py\nclass: Entity\nfunction: Entity.__init__\n\naccounts/apps.py\nclass: SpeedyCoreAccountsConfig\nfunction: SpeedyCoreAccountsConfig.default_auto_field\n\ncore/models.py\nclass: AbstractBaseModel\nfunction: AbstractBaseModel.save\n```"], "meta_data": {"repo": "django/django", "base_commit": "0c42cdf0d2422f4c080e93594d5d15381d6e955e", "problem_statement": "models.W042 is raised on inherited manually specified primary key.\nDescription\n\t\nI have models which inherit from other models, and they should inherit the primary key. This works fine with Django 3.1. However, if I install Django 3.2 alpha, when I run make_migrations I get the following error messages:\nSystem check identified some issues:\nWARNINGS:\naccounts.ReservedUsername: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the SpeedyCoreAccountsConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\naccounts.User: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the SpeedyCoreAccountsConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nblocks.Block: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\ncontact_by_form.Feedback: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the SpeedyCoreContactByFormConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\ncore_messages.ReadMark: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the SpeedyCoreMessagesConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nfriendship.Block: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nfriendship.Follow: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nfriendship.Friend: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nfriendship.FriendshipRequest: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nlikes.UserLike: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nuploads.Image: (models.W042) Auto-created primary key used when not defining a primary key type, by default 'django.db.models.AutoField'.\n\t\tHINT: Configure the DEFAULT_AUTO_FIELD setting or the AppConfig.default_auto_field attribute to point to a subclass of AutoField, e.g. 'django.db.models.BigAutoField'.\nThese models should not use auto-created primary keys! I already defined the primary key in the ancestor of the model. For example class Entity which class User inherits from. It looks to me like a bug in Django 3.2 alpha.\n", "patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1299,6 +1299,11 @@ def check(cls, **kwargs):\n     def _check_default_pk(cls):\n         if (\n             cls._meta.pk.auto_created and\n+            # Inherited PKs are checked in parents models.\n+            not (\n+                isinstance(cls._meta.pk, OneToOneField) and\n+                cls._meta.pk.remote_field.parent_link\n+            ) and\n             not settings.is_overridden('DEFAULT_AUTO_FIELD') and\n             not cls._meta.app_config._is_default_auto_field_overridden\n         ):\n"}}
{"instance_id": "django__django-11620", "found_files": ["django/urls/resolvers.py", "django/urls/converters.py"], "found_modules": ["django/urls/resolvers.py:URLResolver", "django/urls/resolvers.py:URLPattern", "django/urls/converters.py:IntConverter", "django/urls/converters.py:StringConverter", "django/urls/converters.py:UUIDConverter"], "found_entities": ["django/urls/resolvers.py:URLResolver.resolve", "django/urls/resolvers.py:URLPattern.resolve", "django/urls/converters.py:IntConverter.to_python", "django/urls/converters.py:StringConverter.to_python", "django/urls/converters.py:UUIDConverter.to_python"], "raw_output_loc": ["```\ndjango/urls/resolvers.py\nline: 538\nline: 539\nline: 540\nfunction: URLResolver.resolve\n\ncore/handlers/exception.py\nline: 42\nline: 43\nfunction: get_exception_response\n\ncore/handlers/base.py\nline: 244\nline: 245\nfunction: BaseHandler.handle_uncaught_exception\n\nhttp/response.py\nline: 559\nclass: Http404\n\nurls/converters.py\nline: 8\nline: 9\nfunction: IntConverter.to_python\n```", "```\ndjango/urls/resolvers.py\nline: 534\nclass: URLResolver\nfunction: URLResolver.resolve\n\ndjango/urls/resolvers.py\nline: 348\nclass: URLPattern\nfunction: URLPattern.resolve\n\ndjango/urls/converters.py\nline: 8\nclass: IntConverter\nfunction: IntConverter.to_python\n\ndjango/urls/converters.py\nline: 18\nclass: StringConverter\nfunction: StringConverter.to_python\n\ndjango/urls/converters.py\nline: 28\nclass: UUIDConverter\nfunction: UUIDConverter.to_python\n```"], "meta_data": {"repo": "django/django", "base_commit": "514efa3129792ec2abb2444f3e7aeb3f21a38386", "problem_statement": "When DEBUG is True, raising Http404 in a path converter's to_python method does not result in a technical response\nDescription\n\t\nThis is the response I get (plain text): \nA server error occurred. Please contact the administrator.\nI understand a ValueError should be raised which tells the URL resolver \"this path does not match, try next one\" but Http404 is what came to my mind intuitively and the error message was not very helpful.\nOne could also make a point that raising a Http404 should be valid way to tell the resolver \"this is indeed the right path but the current parameter value does not match anything so stop what you are doing and let the handler return the 404 page (including a helpful error message when DEBUG is True instead of the default 'Django tried these URL patterns')\".\nThis would prove useful for example to implement a path converter that uses get_object_or_404.\n", "patch": "diff --git a/django/views/debug.py b/django/views/debug.py\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -5,10 +5,10 @@\n from pathlib import Path\n \n from django.conf import settings\n-from django.http import HttpResponse, HttpResponseNotFound\n+from django.http import Http404, HttpResponse, HttpResponseNotFound\n from django.template import Context, Engine, TemplateDoesNotExist\n from django.template.defaultfilters import pprint\n-from django.urls import Resolver404, resolve\n+from django.urls import resolve\n from django.utils import timezone\n from django.utils.datastructures import MultiValueDict\n from django.utils.encoding import force_str\n@@ -483,7 +483,7 @@ def technical_404_response(request, exception):\n     caller = ''\n     try:\n         resolver_match = resolve(request.path)\n-    except Resolver404:\n+    except Http404:\n         pass\n     else:\n         obj = resolver_match.func\n"}}
{"instance_id": "django__django-14016", "found_files": ["django/db/models/query_utils.py"], "found_modules": ["django/db/models/query_utils.py:Q"], "found_entities": ["django/db/models/query_utils.py:Q._combine", "django/db/models/query_utils.py:Q.__or__"], "raw_output_loc": ["```\ndjango/db/models/query_utils.py\nline: 43\nline: 49\nline: 52\nclass: Q\nfunction: Q._combine\n```", "```\ndjango/db/models/query_utils.py\nline: 60\nclass: Q\nfunction: Q.__or__\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "1710cdbe79c90665046034fe1700933d038d90ad", "problem_statement": "\"TypeError: cannot pickle\" when applying | operator to a Q object\nDescription\n\t \n\t\t(last modified by Daniel Izquierdo)\n\t \nUsing a reference to a non-pickleable type of object such as dict_keys in a Q object makes the | operator fail:\n>>> from django.db.models import Q\n>>> Q(x__in={}.keys())\n<Q: (AND: ('x__in', dict_keys([])))>\n>>> Q() | Q(x__in={}.keys())\nTraceback (most recent call last):\n...\nTypeError: cannot pickle 'dict_keys' object\nEven though this particular example could be solved by doing Q() | Q(x__in={}) it still feels like using .keys() should work.\nI can work on a patch if there's agreement that this should not crash.\n", "patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -5,7 +5,6 @@\n large and/or so that they can be used by other modules without getting into\n circular import difficulties.\n \"\"\"\n-import copy\n import functools\n import inspect\n from collections import namedtuple\n@@ -46,10 +45,12 @@ def _combine(self, other, conn):\n \n         # If the other Q() is empty, ignore it and just use `self`.\n         if not other:\n-            return copy.deepcopy(self)\n+            _, args, kwargs = self.deconstruct()\n+            return type(self)(*args, **kwargs)\n         # Or if this Q is empty, ignore it and just use `other`.\n         elif not self:\n-            return copy.deepcopy(other)\n+            _, args, kwargs = other.deconstruct()\n+            return type(other)(*args, **kwargs)\n \n         obj = type(self)()\n         obj.connector = conn\n"}}
{"instance_id": "psf__requests-1963", "found_files": ["requests/sessions.py", "requests/models.py"], "found_modules": ["requests/sessions.py:SessionRedirectMixin", "requests/models.py:PreparedRequest"], "found_entities": ["requests/sessions.py:SessionRedirectMixin.resolve_redirects", "requests/models.py:PreparedRequest.copy"], "raw_output_loc": ["```\nrequests/sessions.py\nline: 91\nclass: SessionRedirectMixin\nfunction: SessionRedirectMixin.resolve_redirects\n```", "```\nrequests/sessions.py:SessionRedirectMixin.resolve_redirects\nline: 91\nfunction: SessionRedirectMixin.resolve_redirects\n\nrequests/models.py:PreparedRequest.copy\nline: 310\nfunction: PreparedRequest.copy\n```"], "meta_data": {"repo": "psf/requests", "base_commit": "110048f9837f8441ea536804115e80b69f400277", "problem_statement": "`Session.resolve_redirects` copies the original request for all subsequent requests, can cause incorrect method selection\nConsider the following redirection chain:\n\n```\nPOST /do_something HTTP/1.1\nHost: server.example.com\n...\n\nHTTP/1.1 303 See Other\nLocation: /new_thing_1513\n\nGET /new_thing_1513\nHost: server.example.com\n...\n\nHTTP/1.1 307 Temporary Redirect\nLocation: //failover.example.com/new_thing_1513\n```\n\nThe intermediate 303 See Other has caused the POST to be converted to\na GET.  The subsequent 307 should preserve the GET.  However, because\n`Session.resolve_redirects` starts each iteration by copying the _original_\nrequest object, Requests will issue a POST!\n\n", "patch": "diff --git a/requests/sessions.py b/requests/sessions.py\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -168,8 +168,11 @@ def resolve_redirects(self, resp, req, stream=False, timeout=None,\n             if new_auth is not None:\n                 prepared_request.prepare_auth(new_auth)\n \n+            # Override the original request.\n+            req = prepared_request\n+\n             resp = self.send(\n-                prepared_request,\n+                req,\n                 stream=stream,\n                 timeout=timeout,\n                 verify=verify,\n"}}
{"instance_id": "django__django-12470", "found_files": ["django/db/models/options.py", "django/db/models/base.py", "django/db/models/sql/query.py", "django/db/models/query.py", "django/db/models/sql/compiler.py"], "found_modules": ["django/db/models/base.py:Model", "django/db/models/base.py:ModelBase", "django/db/models/sql/query.py:Query", "django/db/models/query.py:QuerySet", "django/db/models/sql/compiler.py:SQLCompiler", "django/db/models/options.py:Options"], "found_entities": ["django/db/models/base.py:Model._check_ordering", "django/db/models/base.py:ModelBase.__new__", "django/db/models/query.py:QuerySet.ordered", "django/db/models/sql/compiler.py:SQLCompiler.find_ordering_name", "django/db/models/sql/query.py:Query.join_parent_model", "django/db/models/sql/query.py:Query.names_to_path", "django/db/models/sql/query.py:Query.get_meta", "django/db/models/sql/compiler.py:SQLCompiler.get_order_by"], "raw_output_loc": ["```\ndjango/db/models/options.py\nline: 1680\nline: 1683\nline: 1699\nfunction: Model._check_ordering\n\ncore/metadata/options.py\nline: 42\nline: 45\nfunction: Options._prepare\n\ndjango/db/models/base.py\nline: 1666\nline: 1671\nfunction: Model._check_ordering\n\ndjango/db/models/query.py\nline: 1203\nfunction: QuerySet.ordered\n\ndjango/db/models/sql/query.py\nline: 1015\nfunction: Query.get_meta\n```", "```\ndjango/db/models/base.py\nline: 146\nline: 147\nclass: ModelBase\nfunction: ModelBase.__new__\n\ndjango/db/models/options.py\nline: 85\nclass: Options\nfunction: Options.__init__\n\ndjango/db/models/sql/query.py\nline: 1440\nfunction: Query.names_to_path\n\ndjango/db/models/sql/compiler.py\nline: 706\nline: 707\nfunction: SQLCompiler.find_ordering_name\n\ndjango/db/models/sql/compiler.py\nline: 340\nfunction: SQLCompiler.get_order_by\n```"], "meta_data": {"repo": "django/django", "base_commit": "142ab6846ac09d6d401e26fc8b6b988a583ac0f5", "problem_statement": "Inherited model doesn't correctly order by \"-pk\" when specified on Parent.Meta.ordering\nDescription\n\t\nGiven the following model definition:\nfrom django.db import models\nclass Parent(models.Model):\n\tclass Meta:\n\t\tordering = [\"-pk\"]\nclass Child(Parent):\n\tpass\nQuerying the Child class results in the following:\n>>> print(Child.objects.all().query)\nSELECT \"myapp_parent\".\"id\", \"myapp_child\".\"parent_ptr_id\" FROM \"myapp_child\" INNER JOIN \"myapp_parent\" ON (\"myapp_child\".\"parent_ptr_id\" = \"myapp_parent\".\"id\") ORDER BY \"myapp_parent\".\"id\" ASC\nThe query is ordered ASC but I expect the order to be DESC.\n", "patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -709,9 +709,9 @@ def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n \n         # If we get to this point and the field is a relation to another model,\n-        # append the default ordering for that model unless the attribute name\n-        # of the field is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name:\n+        # append the default ordering for that model unless it is the pk\n+        # shortcut or the attribute name of the field that is specified.\n+        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n"}}
{"instance_id": "sympy__sympy-18835", "found_files": ["sympy/utilities/iterables.py"], "found_modules": ["sympy/utilities/iterables.py:uniq"], "found_entities": ["sympy/utilities/iterables.py:uniq"], "raw_output_loc": ["```\nsympy/utilities/iterables.py\nline: 2088\nfunction: uniq\n```", "```\nsympy/utilities/iterables.py\nline: 2112\nfunction: uniq\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "516fa83e69caf1e68306cfc912a13f36c434d51c", "problem_statement": "uniq modifies list argument\nWhen you iterate over a dictionary or set and try to modify it while doing so you get an error from Python:\r\n```python\r\n>>> multiset('THISTLE')\r\n{'T': 2, 'H': 1, 'I': 1, 'S': 1, 'L': 1, 'E': 1}\r\n>>> for i in _:\r\n...   _.pop(i)\r\n...\r\n2\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nRuntimeError: dictionary changed size during iteration\r\n```\r\nIt would be good to do the same thing from within `uniq` because the output will silently be wrong if you modify a passed list:\r\n```python\r\n>>> f=list('THISTLE')\r\n>>> for i in uniq(f):\r\n...   f.remove(i)\r\n...   i\r\n...\r\n'T'\r\n'I'\r\n'L'\r\n```\r\nI think this would entail recording the size at the start and then checking the size and raising a similar RuntimeError if the size changes.\n", "patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -2088,8 +2088,13 @@ def has_variety(seq):\n def uniq(seq, result=None):\n     \"\"\"\n     Yield unique elements from ``seq`` as an iterator. The second\n-    parameter ``result``  is used internally; it is not necessary to pass\n-    anything for this.\n+    parameter ``result``  is used internally; it is not necessary\n+    to pass anything for this.\n+\n+    Note: changing the sequence during iteration will raise a\n+    RuntimeError if the size of the sequence is known; if you pass\n+    an iterator and advance the iterator you will change the\n+    output of this routine but there will be no warning.\n \n     Examples\n     ========\n@@ -2106,15 +2111,27 @@ def uniq(seq, result=None):\n     >>> list(uniq([[1], [2, 1], [1]]))\n     [[1], [2, 1]]\n     \"\"\"\n+    try:\n+        n = len(seq)\n+    except TypeError:\n+        n = None\n+    def check():\n+        # check that size of seq did not change during iteration;\n+        # if n == None the object won't support size changing, e.g.\n+        # an iterator can't be changed\n+        if n is not None and len(seq) != n:\n+            raise RuntimeError('sequence changed size during iteration')\n     try:\n         seen = set()\n         result = result or []\n         for i, s in enumerate(seq):\n             if not (s in seen or seen.add(s)):\n                 yield s\n+                check()\n     except TypeError:\n         if s not in result:\n             yield s\n+            check()\n             result.append(s)\n         if hasattr(seq, '__getitem__'):\n             for s in uniq(seq[i + 1:], result):\n"}}
{"instance_id": "django__django-11630", "found_files": ["django/db/models/base.py", "django/core/checks/model_checks.py"], "found_modules": ["django/db/models/base.py:ModelBase", "django/core/checks/model_checks.py:check_all_models"], "found_entities": ["django/db/models/base.py:ModelBase.__new__", "django/core/checks/model_checks.py:check_all_models"], "raw_output_loc": ["```\ndjango/db/models/base.py:ModelBase\nline: 117\nfunction: ModelBase.__new__\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/core/checks/model_checks.py\nline: 38\nline: 47\nfunction: check_all_models\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "65e86948b80262574058a94ccaae3a9b59c3faea", "problem_statement": "Django throws error when different apps with different models have the same name table name.\nDescription\n\t\nError message:\ntable_name: (models.E028) db_table 'table_name' is used by multiple models: base.ModelName, app2.ModelName.\nWe have a Base app that points to a central database and that has its own tables. We then have multiple Apps that talk to their own databases. Some share the same table names.\nWe have used this setup for a while, but after upgrading to Django 2.2 we're getting an error saying we're not allowed 2 apps, with 2 different models to have the same table names. \nIs this correct behavior? We've had to roll back to Django 2.0 for now.\n", "patch": "diff --git a/django/core/checks/model_checks.py b/django/core/checks/model_checks.py\n--- a/django/core/checks/model_checks.py\n+++ b/django/core/checks/model_checks.py\n@@ -4,7 +4,8 @@\n from itertools import chain\n \n from django.apps import apps\n-from django.core.checks import Error, Tags, register\n+from django.conf import settings\n+from django.core.checks import Error, Tags, Warning, register\n \n \n @register(Tags.models)\n@@ -35,14 +36,25 @@ def check_all_models(app_configs=None, **kwargs):\n             indexes[model_index.name].append(model._meta.label)\n         for model_constraint in model._meta.constraints:\n             constraints[model_constraint.name].append(model._meta.label)\n+    if settings.DATABASE_ROUTERS:\n+        error_class, error_id = Warning, 'models.W035'\n+        error_hint = (\n+            'You have configured settings.DATABASE_ROUTERS. Verify that %s '\n+            'are correctly routed to separate databases.'\n+        )\n+    else:\n+        error_class, error_id = Error, 'models.E028'\n+        error_hint = None\n     for db_table, model_labels in db_table_models.items():\n         if len(model_labels) != 1:\n+            model_labels_str = ', '.join(model_labels)\n             errors.append(\n-                Error(\n+                error_class(\n                     \"db_table '%s' is used by multiple models: %s.\"\n-                    % (db_table, ', '.join(db_table_models[db_table])),\n+                    % (db_table, model_labels_str),\n                     obj=db_table,\n-                    id='models.E028',\n+                    hint=(error_hint % model_labels_str) if error_hint else None,\n+                    id=error_id,\n                 )\n             )\n     for index_name, model_labels in indexes.items():\n"}}
{"instance_id": "sympy__sympy-17139", "found_files": ["sympy/simplify/fu.py", "sympy/simplify/simplify.py", "sympy/simplify/trigsimp.py"], "found_modules": ["sympy/simplify/fu.py:_TR56", "sympy/simplify/fu.py:TR6", "sympy/simplify/simplify.py:bottom_up", "sympy/simplify/trigsimp.py:_futrig", "sympy/simplify/trigsimp.py:futrig", "sympy/simplify/fu.py:TR5"], "found_entities": ["sympy/simplify/fu.py:_TR56._f", "sympy/simplify/fu.py:TR6", "sympy/simplify/simplify.py:bottom_up", "sympy/simplify/trigsimp.py:_futrig", "sympy/simplify/fu.py:_TR56", "sympy/simplify/trigsimp.py:futrig", "sympy/simplify/fu.py:TR5"], "raw_output_loc": ["```\nsympy/simplify/fu.py\nline: 504\nfunction: _TR56._f\n\nsympy/simplify/fu.py\nline: 566\nfunction: TR6\n\nsympy/simplify/fu.py\nline: 470\nfunction: _TR56\n\nsympy/simplify/simplify.py\nline: 1070\nfunction: bottom_up\n\nsympy/simplify/trigsimp.py\nline: 1101\nfunction: _futrig\n```", "```\nsympy/simplify/fu.py\nline: 504\nfunction: _TR56._f\n\nsympy/simplify/fu.py\nline: 566\nfunction: TR6\n\nsympy/simplify/trigsimp.py\nline: 1145\nfunction: _futrig\n\nsympy/simplify/simplify.py\nline: 1081\nfunction: bottom_up\n\nsympy/simplify/fu.py\nline: 545\nfunction: TR5\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "1d3327b8e90a186df6972991963a5ae87053259d", "problem_statement": "simplify(cos(x)**I): Invalid comparison of complex I (fu.py)\n```\r\n>>> from sympy import *\r\n>>> x = Symbol('x')\r\n>>> print(simplify(cos(x)**I))\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/e/se/sympy/simplify/simplify.py\", line 587, in simplify\r\n    expr = trigsimp(expr, deep=True)\r\n  File \"/home/e/se/sympy/simplify/trigsimp.py\", line 508, in trigsimp\r\n    return trigsimpfunc(expr)\r\n  File \"/home/e/se/sympy/simplify/trigsimp.py\", line 501, in <lambda>\r\n    'matching': (lambda x: futrig(x)),\r\n  File \"/home/e/se/sympy/simplify/trigsimp.py\", line 1101, in futrig\r\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\r\n  File \"/home/e/se/sympy/simplify/simplify.py\", line 1081, in bottom_up\r\n    rv = F(rv)\r\n  File \"/home/e/se/sympy/simplify/trigsimp.py\", line 1101, in <lambda>\r\n    e = bottom_up(e, lambda x: _futrig(x, **kwargs))\r\n  File \"/home/e/se/sympy/simplify/trigsimp.py\", line 1169, in _futrig\r\n    e = greedy(tree, objective=Lops)(e)\r\n  File \"/home/e/se/sympy/strategies/core.py\", line 115, in minrule\r\n    return min([rule(expr) for rule in rules], key=objective)\r\n  File \"/home/e/se/sympy/strategies/core.py\", line 115, in <listcomp>\r\n    return min([rule(expr) for rule in rules], key=objective)\r\n  File \"/home/e/se/sympy/strategies/core.py\", line 44, in chain_rl\r\n    expr = rule(expr)\r\n  File \"/home/e/se/sympy/simplify/fu.py\", line 566, in TR6\r\n    return _TR56(rv, cos, sin, lambda x: 1 - x, max=max, pow=pow)\r\n  File \"/home/e/se/sympy/simplify/fu.py\", line 524, in _TR56\r\n    return bottom_up(rv, _f)\r\n  File \"/home/e/se/sympy/simplify/simplify.py\", line 1081, in bottom_up\r\n    rv = F(rv)\r\n  File \"/home/e/se/sympy/simplify/fu.py\", line 504, in _f\r\n    if (rv.exp < 0) == True:\r\n  File \"/home/e/se/sympy/core/expr.py\", line 406, in __lt__\r\n    raise TypeError(\"Invalid comparison of complex %s\" % me)\r\nTypeError: Invalid comparison of complex I\r\n```\n", "patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -500,6 +500,8 @@ def _f(rv):\n         # change is not going to allow a simplification as far as I can tell.\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n+        if not rv.exp.is_real:\n+            return rv\n \n         if (rv.exp < 0) == True:\n             return rv\n"}}
{"instance_id": "matplotlib__matplotlib-22835", "found_files": ["lib/matplotlib/artist.py", "lib/matplotlib/colors.py", "lib/matplotlib/backend_bases.py"], "found_modules": ["lib/matplotlib/artist.py:Artist", "lib/matplotlib/colors.py:BoundaryNorm", "lib/matplotlib/backend_bases.py:NavigationToolbar2"], "found_entities": ["lib/matplotlib/artist.py:Artist.format_cursor_data", "lib/matplotlib/colors.py:BoundaryNorm.inverse", "lib/matplotlib/backend_bases.py:NavigationToolbar2._mouse_event_to_message"], "raw_output_loc": ["```\nlib/matplotlib/artist.py\nline: 1307\nline: 1308\nfunction: Artist.format_cursor_data\n\nlib/matplotlib/colors.py\nline: 1904\nfunction: BoundaryNorm.inverse\n```", "```\nlib/matplotlib/artist.py\nline: 1307\nfunction: Artist.format_cursor_data\n\nlib/matplotlib/colors.py\nline: 1912\nclass: BoundaryNorm\nfunction: BoundaryNorm.inverse\n\nlib/matplotlib/backend_bases.py\nline: 3014\nclass: NavigationToolbar2\nfunction: NavigationToolbar2._mouse_event_to_message\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "c33557d120eefe3148ebfcf2e758ff2357966000", "problem_statement": "[Bug]: scalar mappable format_cursor_data crashes on BoundarNorm\n### Bug summary\r\n\r\nIn 3.5.0 if you do:\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport matplotlib as mpl\r\n\r\nfig, ax = plt.subplots()\r\nnorm = mpl.colors.BoundaryNorm(np.linspace(-4, 4, 5), 256)\r\nX = np.random.randn(10, 10)\r\npc = ax.imshow(X, cmap='RdBu_r', norm=norm)\r\n```\r\n\r\nand mouse over the image, it crashes with\r\n\r\n```\r\nFile \"/Users/jklymak/matplotlib/lib/matplotlib/artist.py\", line 1282, in format_cursor_data\r\n    neighbors = self.norm.inverse(\r\n  File \"/Users/jklymak/matplotlib/lib/matplotlib/colors.py\", line 1829, in inverse\r\n    raise ValueError(\"BoundaryNorm is not invertible\")\r\nValueError: BoundaryNorm is not invertible\r\n```\r\n\r\nand interaction stops.  \r\n\r\nNot sure if we should have a special check here, a try-except, or actually just make BoundaryNorm approximately invertible.  \r\n\r\n\r\n### Matplotlib Version\r\n\r\nmain 3.5.0\r\n\r\n\n[Bug]: scalar mappable format_cursor_data crashes on BoundarNorm\n### Bug summary\r\n\r\nIn 3.5.0 if you do:\r\n\r\n```python\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport matplotlib as mpl\r\n\r\nfig, ax = plt.subplots()\r\nnorm = mpl.colors.BoundaryNorm(np.linspace(-4, 4, 5), 256)\r\nX = np.random.randn(10, 10)\r\npc = ax.imshow(X, cmap='RdBu_r', norm=norm)\r\n```\r\n\r\nand mouse over the image, it crashes with\r\n\r\n```\r\nFile \"/Users/jklymak/matplotlib/lib/matplotlib/artist.py\", line 1282, in format_cursor_data\r\n    neighbors = self.norm.inverse(\r\n  File \"/Users/jklymak/matplotlib/lib/matplotlib/colors.py\", line 1829, in inverse\r\n    raise ValueError(\"BoundaryNorm is not invertible\")\r\nValueError: BoundaryNorm is not invertible\r\n```\r\n\r\nand interaction stops.  \r\n\r\nNot sure if we should have a special check here, a try-except, or actually just make BoundaryNorm approximately invertible.  \r\n\r\n\r\n### Matplotlib Version\r\n\r\nmain 3.5.0\r\n\r\n\n", "patch": "diff --git a/lib/matplotlib/artist.py b/lib/matplotlib/artist.py\n--- a/lib/matplotlib/artist.py\n+++ b/lib/matplotlib/artist.py\n@@ -12,6 +12,7 @@\n \n import matplotlib as mpl\n from . import _api, cbook\n+from .colors import BoundaryNorm\n from .cm import ScalarMappable\n from .path import Path\n from .transforms import (Bbox, IdentityTransform, Transform, TransformedBbox,\n@@ -1303,10 +1304,20 @@ def format_cursor_data(self, data):\n                 return \"[]\"\n             normed = self.norm(data)\n             if np.isfinite(normed):\n-                # Midpoints of neighboring color intervals.\n-                neighbors = self.norm.inverse(\n-                    (int(self.norm(data) * n) + np.array([0, 1])) / n)\n-                delta = abs(neighbors - data).max()\n+                if isinstance(self.norm, BoundaryNorm):\n+                    # not an invertible normalization mapping\n+                    cur_idx = np.argmin(np.abs(self.norm.boundaries - data))\n+                    neigh_idx = max(0, cur_idx - 1)\n+                    # use max diff to prevent delta == 0\n+                    delta = np.diff(\n+                        self.norm.boundaries[neigh_idx:cur_idx + 2]\n+                    ).max()\n+\n+                else:\n+                    # Midpoints of neighboring color intervals.\n+                    neighbors = self.norm.inverse(\n+                        (int(normed * n) + np.array([0, 1])) / n)\n+                    delta = abs(neighbors - data).max()\n                 g_sig_digits = cbook._g_sig_digits(data, delta)\n             else:\n                 g_sig_digits = 3  # Consistent with default below.\n"}}
{"instance_id": "sympy__sympy-14308", "found_files": ["sympy/printing/pretty/pretty.py", "sympy/vector/vector.py", "sympy/vector/coordsysrect.py"], "found_modules": ["sympy/printing/pretty/pretty.py:PrettyPrinter", "sympy/vector/coordsysrect.py:CoordSys3D"], "found_entities": ["sympy/printing/pretty/pretty.py:PrettyPrinter._print_BasisDependent", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Cross", "sympy/vector/coordsysrect.py:CoordSys3D.__str__", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Curl", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Divergence", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Dot", "sympy/printing/pretty/pretty.py:PrettyPrinter._print_Gradient"], "raw_output_loc": ["```\nsympy/printing/pretty/pretty.py\nline: 889\nfunction: PrettyPrinter._print_BasisDependent\n\nsympy/vector/vector.py\nline: 12\nclass: Vector\nfunction: Vector.__str__\n\nsympy/vector/coordsysrect.py\nline: 257\nclass: CoordSys3D\nfunction: CoordSys3D.__str__\n```", "```\nsympy/printing/pretty/pretty.py\nline: 89\nfunction: PrettyPrinter._print_Cross\n\nsympy/printing/pretty/pretty.py\nline: 101\nfunction: PrettyPrinter._print_Curl\n\nsympy/printing/pretty/pretty.py\nline: 110\nfunction: PrettyPrinter._print_Divergence\n\nsympy/printing/pretty/pretty.py\nline: 119\nfunction: PrettyPrinter._print_Dot\n\nsympy/printing/pretty/pretty.py\nline: 131\nfunction: PrettyPrinter._print_Gradient\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "fb536869fb7aa28b2695ad7a3b70949926b291c4", "problem_statement": "vectors break pretty printing\n```py\r\nIn [1]: from sympy.vector import *\r\n\r\nIn [2]: e = CoordSysCartesian('e')\r\n\r\nIn [3]: (x/y)**t*e.j\r\nOut[3]:\r\n\u239b   t\u239e e_j\r\n\u239c\u239bx\u239e e_j \u239f\r\n\u239c\u239c\u2500\u239f \u239f\r\n\u239d\u239dy\u23a0 \u23a0\r\n```\r\n\r\nAlso, when it does print correctly, the baseline is wrong (it should be centered). \n", "patch": "diff --git a/sympy/printing/pretty/pretty.py b/sympy/printing/pretty/pretty.py\n--- a/sympy/printing/pretty/pretty.py\n+++ b/sympy/printing/pretty/pretty.py\n@@ -931,26 +931,49 @@ def _print_BasisDependent(self, expr):\n         #Fixing the newlines\n         lengths = []\n         strs = ['']\n+        flag = []\n         for i, partstr in enumerate(o1):\n+            flag.append(0)\n             # XXX: What is this hack?\n             if '\\n' in partstr:\n                 tempstr = partstr\n                 tempstr = tempstr.replace(vectstrs[i], '')\n-                tempstr = tempstr.replace(u'\\N{RIGHT PARENTHESIS UPPER HOOK}',\n-                                          u'\\N{RIGHT PARENTHESIS UPPER HOOK}'\n-                                          + ' ' + vectstrs[i])\n+                if u'\\N{right parenthesis extension}' in tempstr:   # If scalar is a fraction\n+                    for paren in range(len(tempstr)):\n+                        flag[i] = 1\n+                        if tempstr[paren] == u'\\N{right parenthesis extension}':\n+                            tempstr = tempstr[:paren] + u'\\N{right parenthesis extension}'\\\n+                                         + ' '  + vectstrs[i] + tempstr[paren + 1:]\n+                            break\n+                elif u'\\N{RIGHT PARENTHESIS LOWER HOOK}' in tempstr:\n+                    flag[i] = 1\n+                    tempstr = tempstr.replace(u'\\N{RIGHT PARENTHESIS LOWER HOOK}',\n+                                        u'\\N{RIGHT PARENTHESIS LOWER HOOK}'\n+                                        + ' ' + vectstrs[i])\n+                else:\n+                    tempstr = tempstr.replace(u'\\N{RIGHT PARENTHESIS UPPER HOOK}',\n+                                        u'\\N{RIGHT PARENTHESIS UPPER HOOK}'\n+                                        + ' ' + vectstrs[i])\n                 o1[i] = tempstr\n+\n         o1 = [x.split('\\n') for x in o1]\n-        n_newlines = max([len(x) for x in o1])\n-        for parts in o1:\n-            lengths.append(len(parts[0]))\n+        n_newlines = max([len(x) for x in o1])  # Width of part in its pretty form\n+\n+        if 1 in flag:                           # If there was a fractional scalar\n+            for i, parts in enumerate(o1):\n+                if len(parts) == 1:             # If part has no newline\n+                    parts.insert(0, ' ' * (len(parts[0])))\n+                    flag[i] = 1\n+\n+        for i, parts in enumerate(o1):\n+            lengths.append(len(parts[flag[i]]))\n             for j in range(n_newlines):\n                 if j+1 <= len(parts):\n                     if j >= len(strs):\n                         strs.append(' ' * (sum(lengths[:-1]) +\n                                            3*(len(lengths)-1)))\n-                    if j == 0:\n-                        strs[0] += parts[0] + ' + '\n+                    if j == flag[i]:\n+                        strs[flag[i]] += parts[flag[i]] + ' + '\n                     else:\n                         strs[j] += parts[j] + ' '*(lengths[-1] -\n                                                    len(parts[j])+\n"}}
{"instance_id": "sympy__sympy-21612", "found_files": ["sympy/parsing/latex/_parse_latex_antlr.py", "sympy/parsing/latex/_antlr/latexparser.py"], "found_modules": ["sympy/parsing/latex/_parse_latex_antlr.py:convert_mp", "sympy/parsing/latex/_parse_latex_antlr.py:convert_frac", "sympy/parsing/latex/_antlr/latexparser.py:LaTeXParser", "sympy/parsing/latex/_parse_latex_antlr.py:parse_latex", "sympy/parsing/latex/_parse_latex_antlr.py:convert_relation"], "found_entities": ["sympy/parsing/latex/_parse_latex_antlr.py:convert_mp", "sympy/parsing/latex/_parse_latex_antlr.py:convert_frac", "sympy/parsing/latex/_antlr/latexparser.py:LaTeXParser.frac", "sympy/parsing/latex/_parse_latex_antlr.py:parse_latex", "sympy/parsing/latex/_parse_latex_antlr.py:convert_relation"], "raw_output_loc": ["```\nsympy/parsing/latex/_parse_latex_antlr.py\nline: 141\nline: 143\nfunction: convert_mp\n\nsympy/parsing/latex/_antlr/latexparser.py\nline: 2301\nline: 2318\nfunction: LaTeXParser.frac\n\nsympy/parsing/latex/_parse_latex_antlr.py\nline: 85\nfunction: convert_relation\n```", "```\nsympy/parsing/latex/_parse_latex_antlr.py\nline: 345-390\nfunction: convert_frac\n\nsympy/parsing/latex/_parse_latex_antlr.py\nline: 140-143\nfunction: convert_mp\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "b4777fdcef467b7132c055f8ac2c9a5059e6a145", "problem_statement": "Latex parsing of fractions yields wrong expression due to missing brackets\nProblematic latex expression: `\"\\\\frac{\\\\frac{a^3+b}{c}}{\\\\frac{1}{c^2}}\"`\r\n\r\nis parsed to: `((a**3 + b)/c)/1/(c**2)`.\r\n\r\nExpected is: `((a**3 + b)/c)/(1/(c**2))`. \r\n\r\nThe missing brackets in the denominator result in a wrong expression.\r\n\r\n## Tested on\r\n\r\n- 1.8\r\n- 1.6.2\r\n\r\n## Reproduce:\r\n\r\n```\r\nroot@d31ef1c26093:/# python3\r\nPython 3.6.9 (default, Jan 26 2021, 15:33:00)\r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> from sympy.parsing.latex import parse_latex\r\n>>> parse_latex(\"\\\\frac{\\\\frac{a^3+b}{c}}{\\\\frac{1}{c^2}}\")\r\n((a**3 + b)/c)/1/(c**2)\r\n\r\n\n", "patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -333,7 +333,7 @@ def apow(i):\n                     b.append(apow(item))\n                 else:\n                     if (len(item.args[0].args) != 1 and\n-                            isinstance(item.base, Mul)):\n+                            isinstance(item.base, (Mul, Pow))):\n                         # To avoid situations like #14160\n                         pow_paren.append(item)\n                     b.append(item.base)\n"}}
{"instance_id": "sphinx-doc__sphinx-7686", "found_files": ["sphinx/ext/autosummary/generate.py", "sphinx/ext/autosummary/__init__.py"], "found_modules": ["sphinx/ext/autosummary/generate.py:generate_autosummary_content", "sphinx/ext/autosummary/generate.py:generate_autosummary_docs", "sphinx/ext/autosummary/__init__.py:Autosummary", "sphinx/ext/autosummary/__init__.py:get_documenter"], "found_entities": ["sphinx/ext/autosummary/generate.py:generate_autosummary_content.get_members", "sphinx/ext/autosummary/generate.py:generate_autosummary_docs", "sphinx/ext/autosummary/generate.py:generate_autosummary_content", "sphinx/ext/autosummary/__init__.py:get_documenter"], "raw_output_loc": ["```\nsphinx/ext/autosummary/generate.py:generate_autosummary_content.get_members\nline: 195\nfunction: generate_autosummary_content.get_members\n\nsphinx/ext/autosummary/generate.py:generate_autosummary_content\nline: 251\nline: 253\nline: 255\nfunction: generate_autosummary_content\n\nsphinx/ext/autosummary/generate.py:generate_autosummary_docs\nline: 297\nfunction: generate_autosummary_docs\n```", "```\nsphinx/ext/autosummary/generate.py\nline: 195\nfunction: generate_autosummary_content.get_members\n\nsphinx/ext/autosummary/generate.py\nline: 207\nfunction: generate_autosummary_content.get_members\n\nsphinx/ext/autosummary/generate.py\nline: 361\nfunction: generate_autosummary_docs\n\nsphinx/ext/autosummary/__init__.py\nfunction: Autosummary\n\nsphinx/ext/autosummary/__init__.py\nfunction: get_documenter\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "752d3285d250bbaf673cff25e83f03f247502021", "problem_statement": "autosummary: The members variable for module template contains imported members\n**Describe the bug**\r\nautosummary: The members variable for module template contains imported members even if autosummary_imported_members is False.\r\n\r\n**To Reproduce**\r\n\r\n```\r\n# _templates/autosummary/module.rst\r\n{{ fullname | escape | underline }}\r\n\r\n.. automodule:: {{ fullname }}\r\n\r\n   .. autosummary::\r\n   {% for item in members %}\r\n      {{ item }}\r\n   {%- endfor %}\r\n\r\n```\r\n```\r\n# example.py\r\nimport os\r\n```\r\n```\r\n# index.rst\r\n.. autosummary::\r\n   :toctree: generated\r\n\r\n   example\r\n```\r\n```\r\n# conf.py\r\nautosummary_generate = True\r\nautosummary_imported_members = False\r\n```\r\n\r\nAs a result, I got following output:\r\n```\r\n# generated/example.rst\r\nexample\r\n=======\r\n\r\n.. automodule:: example\r\n\r\n   .. autosummary::\r\n\r\n      __builtins__\r\n      __cached__\r\n      __doc__\r\n      __file__\r\n      __loader__\r\n      __name__\r\n      __package__\r\n      __spec__\r\n      os\r\n```\r\n\r\n**Expected behavior**\r\nThe template variable `members` should not contain imported members when `autosummary_imported_members` is False.\r\n\r\n**Your project**\r\nNo\r\n\r\n**Screenshots**\r\nNo\r\n\r\n**Environment info**\r\n- OS: Mac\r\n- Python version: 3.8.2\r\n- Sphinx version: 3.1.0dev\r\n- Sphinx extensions:  sphinx.ext.autosummary\r\n- Extra tools: No\r\n\r\n**Additional context**\r\nNo\r\n\n", "patch": "diff --git a/sphinx/ext/autosummary/generate.py b/sphinx/ext/autosummary/generate.py\n--- a/sphinx/ext/autosummary/generate.py\n+++ b/sphinx/ext/autosummary/generate.py\n@@ -18,6 +18,7 @@\n \"\"\"\n \n import argparse\n+import inspect\n import locale\n import os\n import pkgutil\n@@ -176,6 +177,56 @@ def render(self, template_name: str, context: Dict) -> str:\n # -- Generating output ---------------------------------------------------------\n \n \n+class ModuleScanner:\n+    def __init__(self, app: Any, obj: Any) -> None:\n+        self.app = app\n+        self.object = obj\n+\n+    def get_object_type(self, name: str, value: Any) -> str:\n+        return get_documenter(self.app, value, self.object).objtype\n+\n+    def is_skipped(self, name: str, value: Any, objtype: str) -> bool:\n+        try:\n+            return self.app.emit_firstresult('autodoc-skip-member', objtype,\n+                                             name, value, False, {})\n+        except Exception as exc:\n+            logger.warning(__('autosummary: failed to determine %r to be documented, '\n+                              'the following exception was raised:\\n%s'),\n+                           name, exc, type='autosummary')\n+            return False\n+\n+    def scan(self, imported_members: bool) -> List[str]:\n+        members = []\n+        for name in dir(self.object):\n+            try:\n+                value = safe_getattr(self.object, name)\n+            except AttributeError:\n+                value = None\n+\n+            objtype = self.get_object_type(name, value)\n+            if self.is_skipped(name, value, objtype):\n+                continue\n+\n+            try:\n+                if inspect.ismodule(value):\n+                    imported = True\n+                elif safe_getattr(value, '__module__') != self.object.__name__:\n+                    imported = True\n+                else:\n+                    imported = False\n+            except AttributeError:\n+                imported = False\n+\n+            if imported_members:\n+                # list all members up\n+                members.append(name)\n+            elif imported is False:\n+                # list not-imported members up\n+                members.append(name)\n+\n+        return members\n+\n+\n def generate_autosummary_content(name: str, obj: Any, parent: Any,\n                                  template: AutosummaryRenderer, template_name: str,\n                                  imported_members: bool, app: Any,\n@@ -246,7 +297,8 @@ def get_modules(obj: Any) -> Tuple[List[str], List[str]]:\n     ns.update(context)\n \n     if doc.objtype == 'module':\n-        ns['members'] = dir(obj)\n+        scanner = ModuleScanner(app, obj)\n+        ns['members'] = scanner.scan(imported_members)\n         ns['functions'], ns['all_functions'] = \\\n             get_members(obj, {'function'}, imported=imported_members)\n         ns['classes'], ns['all_classes'] = \\\n"}}
{"instance_id": "django__django-12700", "found_files": ["django/views/debug.py"], "found_modules": ["django/views/debug.py:SafeExceptionReporterFilter"], "found_entities": ["django/views/debug.py:SafeExceptionReporterFilter.cleanse_setting"], "raw_output_loc": ["```\ndjango/views/debug.py\nline: 83\nclass: SafeExceptionReporterFilter\nfunction: SafeExceptionReporterFilter.cleanse_setting\n```", "```\ndjango/views/debug.py\nline: 83\nclass: SafeExceptionReporterFilter\nfunction: SafeExceptionReporterFilter.cleanse_setting\n```"], "meta_data": {"repo": "django/django", "base_commit": "d51c50d836c5cf8db5566da17963f871be554615", "problem_statement": "Settings are cleaned insufficiently.\nDescription\n\t\nPosting publicly after checking with the rest of the security team.\nI just ran into a case where django.views.debug.SafeExceptionReporterFilter.get_safe_settings() would return several un-cleansed values. Looking at cleanse_setting() I realized that we \u200bonly take care of `dict`s but don't take other types of iterables into account but \u200breturn them as-is.\nExample:\nIn my settings.py I have this:\nMY_SETTING = {\n\t\"foo\": \"value\",\n\t\"secret\": \"value\",\n\t\"token\": \"value\",\n\t\"something\": [\n\t\t{\"foo\": \"value\"},\n\t\t{\"secret\": \"value\"},\n\t\t{\"token\": \"value\"},\n\t],\n\t\"else\": [\n\t\t[\n\t\t\t{\"foo\": \"value\"},\n\t\t\t{\"secret\": \"value\"},\n\t\t\t{\"token\": \"value\"},\n\t\t],\n\t\t[\n\t\t\t{\"foo\": \"value\"},\n\t\t\t{\"secret\": \"value\"},\n\t\t\t{\"token\": \"value\"},\n\t\t],\n\t]\n}\nOn Django 3.0 and below:\n>>> import pprint\n>>> from django.views.debug import get_safe_settings\n>>> pprint.pprint(get_safe_settings()[\"MY_SETTING\"])\n{'else': [[{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}],\n\t\t [{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}]],\n 'foo': 'value',\n 'secret': '********************',\n 'something': [{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}],\n 'token': '********************'}\nOn Django 3.1 and up:\n>>> from django.views.debug import SafeExceptionReporterFilter\n>>> import pprint\n>>> pprint.pprint(SafeExceptionReporterFilter().get_safe_settings()[\"MY_SETTING\"])\n{'else': [[{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}],\n\t\t [{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}]],\n 'foo': 'value',\n 'secret': '********************',\n 'something': [{'foo': 'value'}, {'secret': 'value'}, {'token': 'value'}],\n 'token': '********************'}\n", "patch": "diff --git a/django/views/debug.py b/django/views/debug.py\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -90,6 +90,10 @@ def cleanse_setting(self, key, value):\n                 cleansed = self.cleansed_substitute\n             elif isinstance(value, dict):\n                 cleansed = {k: self.cleanse_setting(k, v) for k, v in value.items()}\n+            elif isinstance(value, list):\n+                cleansed = [self.cleanse_setting('', v) for v in value]\n+            elif isinstance(value, tuple):\n+                cleansed = tuple([self.cleanse_setting('', v) for v in value])\n             else:\n                 cleansed = value\n         except TypeError:\n"}}
{"instance_id": "sphinx-doc__sphinx-8506", "found_files": ["sphinx/domains/std.py", "sphinx/ext/autodoc/__init__.py", "sphinx/directives/__init__.py"], "found_modules": ["sphinx/domains/std.py:Cmdoption", "sphinx/domains/std.py:StandardDomain", "sphinx/directives/__init__.py:ObjectDescription", "sphinx/ext/autodoc/__init__.py:members_option"], "found_entities": ["sphinx/domains/std.py:Cmdoption.handle_signature", "sphinx/domains/std.py:StandardDomain.add_program_option", "sphinx/directives/__init__.py:ObjectDescription.handle_signature", "sphinx/domains/std.py:StandardDomain._resolve_option_xref", "sphinx/ext/autodoc/__init__.py:members_option"], "raw_output_loc": ["```\nsphinx/domains/std.py\nline: 192\nclass: Cmdoption\nfunction: Cmdoption.handle_signature\n\nsphinx/domains/std.py\nline: 194\nclass: Cmdoption\nfunction: Cmdoption.handle_signature\n\nsphinx/domains/std.py\nline: 759\nclass: StandardDomain\nfunction: StandardDomain.add_program_option\n\nsphinx/domains/std.py\nline: 919\nclass: StandardDomain\nfunction: StandardDomain._resolve_option_xref\n\nsphinx/ext/autodoc/__init__.py\nline: 92\nfunction: members_option\n```", "```\nsphinx/domains/std.py\nline: 186\nclass: Cmdoption\nfunction: Cmdoption.handle_signature\n\nsphinx/domains/std.py\nline: 46\nfunction: option_desc_re\n\nsphinx/directives/__init__.py\nline: 50\nclass: ObjectDescription\nfunction: ObjectDescription.handle_signature\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "e4bd3bd3ddd42c6642ff779a4f7381f219655c2c", "problem_statement": "Sphinx 3.2 complains about option:: syntax that earlier versions accepted\nSphinx 3.2 complains about use of the option:: directive that earlier versions accepted without complaint.\r\n\r\nThe QEMU documentation includes this:\r\n```\r\n.. option:: [enable=]PATTERN\r\n\r\n   Immediately enable events matching *PATTERN*\r\n```\r\n\r\nas part of the documentation of the command line options of one of its programs. Earlier versions of Sphinx were fine with this, but Sphinx 3.2 complains:\r\n\r\n```\r\nWarning, treated as error:\r\n../../docs/qemu-option-trace.rst.inc:4:Malformed option description '[enable=]PATTERN', should look like \"opt\", \"-opt args\", \"--opt args\", \"/opt args\" or \"+opt args\"\r\n```\r\n\r\nSphinx ideally shouldn't change in ways that break the building of documentation that worked in older versions, because this makes it unworkably difficult to have documentation that builds with whatever the Linux distro's sphinx-build is.\r\n\r\nThe error message suggests that Sphinx has a very restrictive idea of what option syntax is; it would be better if it just accepted any string, because not all programs and OSes have option syntax that matches the limited list the error message indicates.\r\n\n", "patch": "diff --git a/sphinx/domains/std.py b/sphinx/domains/std.py\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -43,7 +43,7 @@\n \n \n # RE for option descriptions\n-option_desc_re = re.compile(r'((?:/|--|-|\\+)?[^\\s=[]+)(=?\\s*.*)')\n+option_desc_re = re.compile(r'((?:/|--|-|\\+)?[^\\s=]+)(=?\\s*.*)')\n # RE for grammar tokens\n token_re = re.compile(r'`(\\w+)`', re.U)\n \n@@ -197,6 +197,11 @@ def handle_signature(self, sig: str, signode: desc_signature) -> str:\n                                location=signode)\n                 continue\n             optname, args = m.groups()\n+            if optname.endswith('[') and args.endswith(']'):\n+                # optional value surrounded by brackets (ex. foo[=bar])\n+                optname = optname[:-1]\n+                args = '[' + args\n+\n             if count:\n                 signode += addnodes.desc_addname(', ', ', ')\n             signode += addnodes.desc_name(optname, optname)\n"}}
{"instance_id": "django__django-12708", "found_files": ["django/db/backends/base/schema.py"], "found_modules": ["django/db/backends/base/schema.py:BaseDatabaseSchemaEditor"], "found_entities": ["django/db/backends/base/schema.py:BaseDatabaseSchemaEditor.alter_unique_together", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor._delete_composed_index", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor.alter_index_together", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor._constraint_names", "django/db/backends/base/schema.py:BaseDatabaseSchemaEditor._delete_constraint_sql"], "raw_output_loc": ["```\ndjango/db/backends/base/schema.py\nline: 378\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._delete_composed_index\n\ndjango/db/backends/base/schema.py\nline: 380\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor.alter_unique_together\n\ndjango/db/backends/base/schema.py\nline: 396\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor.alter_index_together\n\ndjango/db/backends/base/schema.py\nline: 1142\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._constraint_names\n\ndjango/db/backends/base/schema.py\nline: 1135\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._delete_constraint_sql\n```", "```\ndjango/db/backends/base/schema.py\nline: 378\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._delete_composed_index\n\ndjango/db/backends/base/schema.py\nline: 396\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor.alter_index_together\n\ndjango/db/backends/base/schema.py\nline: 380\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor.alter_unique_together\n\ndjango/db/backends/base/schema.py\nline: 410\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._delete_composed_index\n\ndjango/db/backends/base/schema.py\nline: 415\nclass: BaseDatabaseSchemaEditor\nfunction: BaseDatabaseSchemaEditor._delete_composed_index\n```"], "meta_data": {"repo": "django/django", "base_commit": "447980e72ac01da1594dd3373a03ba40b7ee6f80", "problem_statement": "Migration crashes deleting an index_together if there is a unique_together on the same fields\nDescription\n\t\nHappens with Django 1.11.10\nSteps to reproduce:\n1) Create models with 2 fields, add 2 same fields to unique_together and to index_together\n2) Delete index_together -> Fail\nIt will fail at django/db/backends/base/schema.py, line 378, in _delete_composed_index(), ValueError: Found wrong number (2) of constraints for as this one will find two constraints, the _uniq and the _idx one. No way to get out of this...\nThe worst in my case is that happened as I wanted to refactor my code to use the \"new\" (Dj 1.11) Options.indexes feature. I am actually not deleting the index, just the way it is declared in my code.\nI think there are 2 different points here:\n1) The deletion of index_together should be possible alone or made coherent (migrations side?) with unique_together\n2) Moving the declaration of an index should not result in an index re-creation\n", "patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -393,7 +393,12 @@ def alter_index_together(self, model, old_index_together, new_index_together):\n         news = {tuple(fields) for fields in new_index_together}\n         # Deleted indexes\n         for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n+            self._delete_composed_index(\n+                model,\n+                fields,\n+                {'index': True, 'unique': False},\n+                self.sql_delete_index,\n+            )\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n"}}
{"instance_id": "django__django-15202", "found_files": ["django/forms/fields.py", "django/core/validators.py"], "found_modules": ["django/forms/fields.py:URLField.to_python", "django/forms/fields.py:URLField", "django/core/validators.py:URLValidator"], "found_entities": ["django/forms/fields.py:URLField.to_python.split_url", "django/forms/fields.py:URLField.to_python", "django/core/validators.py:URLValidator.__call__"], "raw_output_loc": ["```\ndjango/forms/fields.py\nline: 688-693\nclass: URLField\nfunction: URLField.to_python.split_url\n\ncore/validators.py\nline: 119\nclass: URLValidator\nfunction: URLValidator.__call__\n\nurllib/parse.py\nline: 440\nfunction: urlsplit\n```", "```\ndjango/forms/fields.py\nline: 688\nline: 689\nline: 690\nline: 691\nline: 693\nclass: URLField\nfunction: URLField.to_python.split_url\n\ndjango/core/validators.py\nline: 117\nline: 118\nline: 119\nclass: URLValidator\nfunction: URLValidator.__call__\n```"], "meta_data": {"repo": "django/django", "base_commit": "4fd3044ca0135da903a70dfb66992293f529ecf1", "problem_statement": "URLField throws ValueError instead of ValidationError on clean\nDescription\n\t\nforms.URLField( ).clean('////]@N.AN')\nresults in:\n\tValueError: Invalid IPv6 URL\n\tTraceback (most recent call last):\n\t File \"basic_fuzzer.py\", line 22, in TestOneInput\n\t File \"fuzzers.py\", line 350, in test_forms_URLField\n\t File \"django/forms/fields.py\", line 151, in clean\n\t File \"django/forms/fields.py\", line 136, in run_validators\n\t File \"django/core/validators.py\", line 130, in __call__\n\t File \"urllib/parse.py\", line 440, in urlsplit\n", "patch": "diff --git a/django/core/validators.py b/django/core/validators.py\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -108,15 +108,16 @@ def __call__(self, value):\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n \n         # Then check full URL\n+        try:\n+            splitted_url = urlsplit(value)\n+        except ValueError:\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n         try:\n             super().__call__(value)\n         except ValidationError as e:\n             # Trivial case failed. Try for possible IDN domain\n             if value:\n-                try:\n-                    scheme, netloc, path, query, fragment = urlsplit(value)\n-                except ValueError:  # for example, \"Invalid IPv6 URL\"\n-                    raise ValidationError(self.message, code=self.code, params={'value': value})\n+                scheme, netloc, path, query, fragment = splitted_url\n                 try:\n                     netloc = punycode(netloc)  # IDN -> ACE\n                 except UnicodeError:  # invalid domain part\n@@ -127,7 +128,7 @@ def __call__(self, value):\n                 raise\n         else:\n             # Now verify IPv6 in the netloc part\n-            host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', urlsplit(value).netloc)\n+            host_match = re.search(r'^\\[(.+)\\](?::\\d{1,5})?$', splitted_url.netloc)\n             if host_match:\n                 potential_ip = host_match[1]\n                 try:\n@@ -139,7 +140,7 @@ def __call__(self, value):\n         # section 3.1. It's defined to be 255 bytes or less, but this includes\n         # one byte for the length of the name and one byte for the trailing dot\n         # that's used to indicate absolute names in DNS.\n-        if len(urlsplit(value).hostname) > 253:\n+        if splitted_url.hostname is None or len(splitted_url.hostname) > 253:\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n \n \n"}}
{"instance_id": "scikit-learn__scikit-learn-14087", "found_files": ["sklearn/linear_model/logistic.py"], "found_modules": ["sklearn/linear_model/logistic.py:LogisticRegressionCV", "sklearn/linear_model/logistic.py:_log_reg_scoring_path", "sklearn/linear_model/logistic.py:_logistic_regression_path"], "found_entities": ["sklearn/linear_model/logistic.py:LogisticRegressionCV.fit", "sklearn/linear_model/logistic.py:_log_reg_scoring_path", "sklearn/linear_model/logistic.py:_logistic_regression_path"], "raw_output_loc": ["```\nsklearn/linear_model/logistic.py\nline: 2192\nline: 2193\nline: 2194\nclass: LogisticRegressionCV\nfunction: LogisticRegressionCV.fit\n\nsklearn/linear_model/logistic.py\nline: 995\nfunction: _log_reg_scoring_path\n\nsklearn/linear_model/logistic.py\nline: 646\nfunction: _logistic_regression_path\n```", "```\nsklearn/linear_model/logistic.py\nline: 2192\nline: 2193\nline: 2194\nclass: LogisticRegressionCV\nfunction: LogisticRegressionCV.fit\n\nsklearn/linear_model/logistic.py\nline: 995\nfunction: _log_reg_scoring_path\n\nsklearn/linear_model/logistic.py\nline: 646\nfunction: _logistic_regression_path\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "a5743ed36fbd3fbc8e351bdab16561fbfca7dfa1", "problem_statement": "IndexError thrown with LogisticRegressionCV and refit=False\n#### Description\r\nThe following error is thrown when trying to estimate a regularization parameter via cross-validation, *without* refitting.\r\n\r\n#### Steps/Code to Reproduce\r\n```python\r\nimport sys\r\nimport sklearn\r\nfrom sklearn.linear_model import LogisticRegressionCV\r\nimport numpy as np\r\n\r\nnp.random.seed(29)\r\nX = np.random.normal(size=(1000, 3))\r\nbeta = np.random.normal(size=3)\r\nintercept = np.random.normal(size=None)\r\ny = np.sign(intercept + X @ beta)\r\n\r\nLogisticRegressionCV(\r\ncv=5,\r\nsolver='saga', # same error with 'liblinear'\r\ntol=1e-2,\r\nrefit=False).fit(X, y)\r\n```\r\n\r\n\r\n#### Expected Results\r\nNo error is thrown. \r\n\r\n#### Actual Results\r\n```\r\n---------------------------------------------------------------------------\r\nIndexError                                Traceback (most recent call last)\r\n<ipython-input-3-81609fd8d2ca> in <module>\r\n----> 1 LogisticRegressionCV(refit=False).fit(X, y)\r\n\r\n~/.pyenv/versions/3.6.7/envs/jupyter/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in fit(self, X, y, sample_weight)\r\n   2192                 else:\r\n   2193                     w = np.mean([coefs_paths[:, i, best_indices[i], :]\r\n-> 2194                                  for i in range(len(folds))], axis=0)\r\n   2195 \r\n   2196                 best_indices_C = best_indices % len(self.Cs_)\r\n\r\n~/.pyenv/versions/3.6.7/envs/jupyter/lib/python3.6/site-packages/sklearn/linear_model/logistic.py in <listcomp>(.0)\r\n   2192                 else:\r\n   2193                     w = np.mean([coefs_paths[:, i, best_indices[i], :]\r\n-> 2194                                  for i in range(len(folds))], axis=0)\r\n   2195 \r\n   2196                 best_indices_C = best_indices % len(self.Cs_)\r\n\r\nIndexError: too many indices for array\r\n```\r\n\r\n#### Versions\r\n```\r\nSystem:\r\n    python: 3.6.7 (default, May 13 2019, 16:14:45)  [GCC 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.46.4)]\r\nexecutable: /Users/tsweetser/.pyenv/versions/3.6.7/envs/jupyter/bin/python\r\n   machine: Darwin-18.6.0-x86_64-i386-64bit\r\n\r\nBLAS:\r\n    macros: NO_ATLAS_INFO=3, HAVE_CBLAS=None\r\n  lib_dirs: \r\ncblas_libs: cblas\r\n\r\nPython deps:\r\n       pip: 19.1.1\r\nsetuptools: 39.0.1\r\n   sklearn: 0.21.2\r\n     numpy: 1.15.1\r\n     scipy: 1.1.0\r\n    Cython: 0.29.6\r\n    pandas: 0.24.2\r\n```\n", "patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2170,7 +2170,7 @@ def fit(self, X, y, sample_weight=None):\n                 # Take the best scores across every fold and the average of\n                 # all coefficients corresponding to the best scores.\n                 best_indices = np.argmax(scores, axis=1)\n-                if self.multi_class == 'ovr':\n+                if multi_class == 'ovr':\n                     w = np.mean([coefs_paths[i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n                 else:\n@@ -2180,8 +2180,11 @@ def fit(self, X, y, sample_weight=None):\n                 best_indices_C = best_indices % len(self.Cs_)\n                 self.C_.append(np.mean(self.Cs_[best_indices_C]))\n \n-                best_indices_l1 = best_indices // len(self.Cs_)\n-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                if self.penalty == 'elasticnet':\n+                    best_indices_l1 = best_indices // len(self.Cs_)\n+                    self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))\n+                else:\n+                    self.l1_ratio_.append(None)\n \n             if multi_class == 'multinomial':\n                 self.C_ = np.tile(self.C_, n_classes)\n"}}
{"instance_id": "django__django-13448", "found_files": ["django/db/backends/base/creation.py", "django/contrib/admin/models.py", "django/core/management/__init__.py"], "found_modules": ["django/db/backends/base/creation.py:BaseDatabaseCreation", "django/contrib/admin/models.py:LogEntry.Meta", "django/core/management/__init__.py:call_command", "django/contrib/admin/models.py:LogEntry"], "found_entities": ["django/db/backends/base/creation.py:BaseDatabaseCreation.create_test_db", "django/db/backends/base/creation.py:BaseDatabaseCreation.serialize_db_to_string", "django/core/management/__init__.py:call_command"], "raw_output_loc": ["```\ndjango/db/backends/base/creation.py\nline: 78\nfunction: BaseDatabaseCreation.create_test_db\n\ncore/utils/helper_functions.py\nline: 121\nfunction: serialize_db_to_string\n\ndjango/test/runner.py\nline: 616\nfunction: DiscoverRunner.setup_databases\n\ndjango/contrib/admin/models.py\nline: 68\nclass: LogEntry\nfunction: LogEntry.Meta\n```", "```\ndjango/db/backends/base/creation.py\nline: 94\nclass: BaseDatabaseCreation\nfunction: BaseDatabaseCreation.serialize_db_to_string\n\ndjango/test/runner.py\nfunction: setup_databases\n\ndjango/core/management/__init__.py\nline: 76\nfunction: call_command\n```"], "meta_data": {"repo": "django/django", "base_commit": "7b9596b974fb0ad1868b10c8c2174e10b72be403", "problem_statement": "Test runner setup_databases crashes with \"TEST\": {\"MIGRATE\": False}.\nDescription\n\t\nI'm trying to upgrade a project from Django 3.0 to Django 3.1 and wanted to try out the new \"TEST\": {\"MIGRATE\": False} database setting.\nSadly I'm running into an issue immediately when running ./manage.py test.\nRemoving the \"TEST\": {\"MIGRATE\": False} line allows the tests to run. So this is not blocking the upgrade for us, but it would be nice if we were able to use the new feature to skip migrations during testing.\nFor reference, this project was recently upgraded from Django 1.4 all the way to 3.0 so there might be some legacy cruft somewhere that triggers this.\nHere's the trackeback. I'll try to debug this some more.\nTraceback (most recent call last):\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\npsycopg2.errors.UndefinedTable: relation \"django_admin_log\" does not exist\nLINE 1: ...n_flag\", \"django_admin_log\".\"change_message\" FROM \"django_ad...\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ^\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n File \"/usr/local/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1156, in execute_sql\n\tcursor.execute(sql, params)\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/utils.py\", line 66, in execute\n\treturn self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/utils.py\", line 75, in _execute_with_wrappers\n\treturn executor(sql, params, many, context)\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\n File \"/usr/local/lib/python3.6/site-packages/django/db/utils.py\", line 90, in __exit__\n\traise dj_exc_value.with_traceback(traceback) from exc_value\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n\treturn self.cursor.execute(sql, params)\ndjango.db.utils.ProgrammingError: relation \"django_admin_log\" does not exist\nLINE 1: ...n_flag\", \"django_admin_log\".\"change_message\" FROM \"django_ad...\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t ^\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n File \"./manage.py\", line 15, in <module>\n\tmain()\n File \"./manage.py\", line 11, in main\n\texecute_from_command_line(sys.argv)\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/__init__.py\", line 401, in execute_from_command_line\n\tutility.execute()\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/__init__.py\", line 395, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/commands/test.py\", line 23, in run_from_argv\n\tsuper().run_from_argv(argv)\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/base.py\", line 330, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/base.py\", line 371, in execute\n\toutput = self.handle(*args, **options)\n File \"/usr/local/lib/python3.6/site-packages/django/core/management/commands/test.py\", line 53, in handle\n\tfailures = test_runner.run_tests(test_labels)\n File \"/usr/local/lib/python3.6/site-packages/django/test/runner.py\", line 695, in run_tests\n\told_config = self.setup_databases(aliases=databases)\n File \"/usr/local/lib/python3.6/site-packages/django/test/runner.py\", line 616, in setup_databases\n\tself.parallel, **kwargs\n File \"/usr/local/lib/python3.6/site-packages/django/test/utils.py\", line 174, in setup_databases\n\tserialize=connection.settings_dict['TEST'].get('SERIALIZE', True),\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/base/creation.py\", line 78, in create_test_db\n\tself.connection._test_serialized_contents = self.serialize_db_to_string()\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/base/creation.py\", line 121, in serialize_db_to_string\n\tserializers.serialize(\"json\", get_objects(), indent=None, stream=out)\n File \"/usr/local/lib/python3.6/site-packages/django/core/serializers/__init__.py\", line 128, in serialize\n\ts.serialize(queryset, **options)\n File \"/usr/local/lib/python3.6/site-packages/django/core/serializers/base.py\", line 90, in serialize\n\tfor count, obj in enumerate(queryset, start=1):\n File \"/usr/local/lib/python3.6/site-packages/django/db/backends/base/creation.py\", line 118, in get_objects\n\tyield from queryset.iterator()\n File \"/usr/local/lib/python3.6/site-packages/django/db/models/query.py\", line 360, in _iterator\n\tyield from self._iterable_class(self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size)\n File \"/usr/local/lib/python3.6/site-packages/django/db/models/query.py\", line 53, in __iter__\n\tresults = compiler.execute_sql(chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size)\n File \"/usr/local/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1159, in execute_sql\n\tcursor.close()\npsycopg2.errors.InvalidCursorName: cursor \"_django_curs_139860821038912_sync_1\" does not exist\n", "patch": "diff --git a/django/db/backends/base/creation.py b/django/db/backends/base/creation.py\n--- a/django/db/backends/base/creation.py\n+++ b/django/db/backends/base/creation.py\n@@ -58,7 +58,14 @@ def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=\n         settings.DATABASES[self.connection.alias][\"NAME\"] = test_database_name\n         self.connection.settings_dict[\"NAME\"] = test_database_name\n \n-        if self.connection.settings_dict['TEST']['MIGRATE']:\n+        try:\n+            if self.connection.settings_dict['TEST']['MIGRATE'] is False:\n+                # Disable migrations for all apps.\n+                old_migration_modules = settings.MIGRATION_MODULES\n+                settings.MIGRATION_MODULES = {\n+                    app.label: None\n+                    for app in apps.get_app_configs()\n+                }\n             # We report migrate messages at one level lower than that\n             # requested. This ensures we don't get flooded with messages during\n             # testing (unless you really ask to be flooded).\n@@ -69,6 +76,9 @@ def create_test_db(self, verbosity=1, autoclobber=False, serialize=True, keepdb=\n                 database=self.connection.alias,\n                 run_syncdb=True,\n             )\n+        finally:\n+            if self.connection.settings_dict['TEST']['MIGRATE'] is False:\n+                settings.MIGRATION_MODULES = old_migration_modules\n \n         # We then serialize the current state of the database into a string\n         # and store it on the connection. This slightly horrific process is so people\n"}}
{"instance_id": "django__django-10924", "found_files": ["django/db/models/fields/__init__.py"], "found_modules": ["django/db/models/fields/__init__.py:FilePathField", "django/db/models/fields/__init__.py:Field"], "found_entities": ["django/db/models/fields/__init__.py:FilePathField.deconstruct", "django/db/models/fields/__init__.py:Field.deconstruct"], "raw_output_loc": ["```\ndjango/db/models/fields/__init__.py\nline: 1688\nline: 1691\nclass: FilePathField\nfunction: FilePathField.deconstruct\n\ndjango/db/models/fields/__init__.py\nline: 398\nline: 485\nclass: Field\nfunction: Field.deconstruct\n```", "```\ndjango/db/models/fields/__init__.py\nline: 1688\nline: 1690\nclass: FilePathField\nfunction: FilePathField.deconstruct\n```"], "meta_data": {"repo": "django/django", "base_commit": "bceadd2788dc2dad53eba0caae172bd8522fd483", "problem_statement": "Allow FilePathField path to accept a callable.\nDescription\n\t\nI have a special case where I want to create a model containing the path to some local files on the server/dev machine. Seeing as the place where these files are stored is different on different machines I have the following:\nimport os\nfrom django.conf import settings\nfrom django.db import models\nclass LocalFiles(models.Model):\n\tname = models.CharField(max_length=255)\n\tfile = models.FilePathField(path=os.path.join(settings.LOCAL_FILE_DIR, 'example_dir'))\nNow when running manage.py makemigrations it will resolve the path based on the machine it is being run on. Eg: /home/<username>/server_files/example_dir\nI had to manually change the migration to include the os.path.join() part to not break this when running the migration on production/other machine.\n", "patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -1709,7 +1709,7 @@ def get_prep_value(self, value):\n \n     def formfield(self, **kwargs):\n         return super().formfield(**{\n-            'path': self.path,\n+            'path': self.path() if callable(self.path) else self.path,\n             'match': self.match,\n             'recursive': self.recursive,\n             'form_class': forms.FilePathField,\n"}}
{"instance_id": "django__django-16816", "found_files": ["django/contrib/admin/utils.py", "django/contrib/admin/checks.py", "django/contrib/admin/templatetags/admin_list.py", "django/contrib/admin/options.py"], "found_modules": ["django/contrib/admin/utils.py:label_for_field", "django/contrib/admin/checks.py:ModelAdminChecks", "django/contrib/admin/templatetags/admin_list.py:result_headers", "django/contrib/admin/options.py:ModelAdmin"], "found_entities": ["django/contrib/admin/utils.py:label_for_field", "django/contrib/admin/checks.py:ModelAdminChecks._check_list_display_item", "django/contrib/admin/templatetags/admin_list.py:result_headers", "django/contrib/admin/options.py:ModelAdmin.get_list_display"], "raw_output_loc": ["```\ndjango/contrib/admin/utils.py\nline: 340\nfunction: label_for_field\n\ndjango/contrib/admin/templatetags/admin_list.py\nline: 90\nfunction: result_headers\n\ndjango/contrib/admin/options.py\nline: 1086\nfunction: ModelAdmin.get_list_display\n```", "```\ndjango/contrib/admin/checks.py\nline: 893\nclass: ModelAdminChecks\nfunction: ModelAdminChecks._check_list_display_item\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "191f6a9a4586b5e5f79f4f42f190e7ad4bbacc84", "problem_statement": "Error E108 does not cover some cases\nDescription\n\t \n\t\t(last modified by Baha Sdtbekov)\n\t \nI have two models, Question and Choice. And if I write list_display = [\"choice\"] in QuestionAdmin, I get no errors.\nBut when I visit /admin/polls/question/, the following trace is returned:\nInternal Server Error: /admin/polls/question/\nTraceback (most recent call last):\n File \"/some/path/django/contrib/admin/utils.py\", line 334, in label_for_field\n\tfield = _get_non_gfk_field(model._meta, name)\n File \"/some/path/django/contrib/admin/utils.py\", line 310, in _get_non_gfk_field\n\traise FieldDoesNotExist()\ndjango.core.exceptions.FieldDoesNotExist\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n File \"/some/path/django/core/handlers/exception.py\", line 55, in inner\n\tresponse = get_response(request)\n File \"/some/path/django/core/handlers/base.py\", line 220, in _get_response\n\tresponse = response.render()\n File \"/some/path/django/template/response.py\", line 111, in render\n\tself.content = self.rendered_content\n File \"/some/path/django/template/response.py\", line 89, in rendered_content\n\treturn template.render(context, self._request)\n File \"/some/path/django/template/backends/django.py\", line 61, in render\n\treturn self.template.render(context)\n File \"/some/path/django/template/base.py\", line 175, in render\n\treturn self._render(context)\n File \"/some/path/django/template/base.py\", line 167, in _render\n\treturn self.nodelist.render(context)\n File \"/some/path/django/template/base.py\", line 1005, in render\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 1005, in <listcomp>\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 966, in render_annotated\n\treturn self.render(context)\n File \"/some/path/django/template/loader_tags.py\", line 157, in render\n\treturn compiled_parent._render(context)\n File \"/some/path/django/template/base.py\", line 167, in _render\n\treturn self.nodelist.render(context)\n File \"/some/path/django/template/base.py\", line 1005, in render\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 1005, in <listcomp>\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 966, in render_annotated\n\treturn self.render(context)\n File \"/some/path/django/template/loader_tags.py\", line 157, in render\n\treturn compiled_parent._render(context)\n File \"/some/path/django/template/base.py\", line 167, in _render\n\treturn self.nodelist.render(context)\n File \"/some/path/django/template/base.py\", line 1005, in render\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 1005, in <listcomp>\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 966, in render_annotated\n\treturn self.render(context)\n File \"/some/path/django/template/loader_tags.py\", line 63, in render\n\tresult = block.nodelist.render(context)\n File \"/some/path/django/template/base.py\", line 1005, in render\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 1005, in <listcomp>\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 966, in render_annotated\n\treturn self.render(context)\n File \"/some/path/django/template/loader_tags.py\", line 63, in render\n\tresult = block.nodelist.render(context)\n File \"/some/path/django/template/base.py\", line 1005, in render\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 1005, in <listcomp>\n\treturn SafeString(\"\".join([node.render_annotated(context) for node in self]))\n File \"/some/path/django/template/base.py\", line 966, in render_annotated\n\treturn self.render(context)\n File \"/some/path/django/contrib/admin/templatetags/base.py\", line 45, in render\n\treturn super().render(context)\n File \"/some/path/django/template/library.py\", line 258, in render\n\t_dict = self.func(*resolved_args, **resolved_kwargs)\n File \"/some/path/django/contrib/admin/templatetags/admin_list.py\", line 326, in result_list\n\theaders = list(result_headers(cl))\n File \"/some/path/django/contrib/admin/templatetags/admin_list.py\", line 90, in result_headers\n\ttext, attr = label_for_field(\n File \"/some/path/django/contrib/admin/utils.py\", line 362, in label_for_field\n\traise AttributeError(message)\nAttributeError: Unable to lookup 'choice' on Question or QuestionAdmin\n[24/Apr/2023 15:43:32] \"GET /admin/polls/question/ HTTP/1.1\" 500 349913\nI suggest that error E108 be updated to cover this case as well\nFor reproduce see \u200bgithub\n", "patch": "diff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -916,9 +916,10 @@ def _check_list_display_item(self, obj, item, label):\n                         id=\"admin.E108\",\n                     )\n                 ]\n-        if isinstance(field, models.ManyToManyField) or (\n-            getattr(field, \"rel\", None) and field.rel.field.many_to_one\n-        ):\n+        if (\n+            getattr(field, \"is_relation\", False)\n+            and (field.many_to_many or field.one_to_many)\n+        ) or (getattr(field, \"rel\", None) and field.rel.field.many_to_one):\n             return [\n                 checks.Error(\n                     f\"The value of '{label}' must not be a many-to-many field or a \"\n"}}
{"instance_id": "scikit-learn__scikit-learn-12471", "found_files": ["sklearn/preprocessing/_encoders.py", "sklearn/preprocessing/label.py"], "found_modules": ["sklearn/preprocessing/_encoders.py:_BaseEncoder", "sklearn/preprocessing/_encoders.py:OneHotEncoder", "sklearn/preprocessing/label.py:_encode_python", "sklearn/preprocessing/label.py:_encode_check_unknown"], "found_entities": ["sklearn/preprocessing/_encoders.py:_BaseEncoder._transform", "sklearn/preprocessing/_encoders.py:OneHotEncoder.transform", "sklearn/preprocessing/label.py:_encode_python", "sklearn/preprocessing/label.py:_encode_check_unknown", "sklearn/preprocessing/_encoders.py:OneHotEncoder._transform_new"], "raw_output_loc": ["```\nsklearn/preprocessing/_encoders.py\nline: 114\nclass: OneHotEncoder\nfunction: OneHotEncoder._transform\n\nsklearn/preprocessing/_encoders.py\nline: 100\nfunction: _encode_check_unknown\n\nsklearn/preprocessing/_encoders.py\nline: 109\nclass: OneHotEncoder\nfunction: OneHotEncoder._transform\n\nsklearn/preprocessing/_encoders.py\nline: 115\nclass: OneHotEncoder\nfunction: OneHotEncoder._transform\n\nsklearn/preprocessing/_encoders.py\nline: 604\nclass: OneHotEncoder\nfunction: OneHotEncoder.transform\n```", "```\nsklearn/preprocessing/_encoders.py:_BaseEncoder._transform\nline: 114\nfunction: _BaseEncoder._transform\n\nsklearn/preprocessing/label.py:_encode_python\nline: 68\nfunction: _encode_python\n\nsklearn/preprocessing/label.py:_encode_check_unknown\nline: 140\nfunction: _encode_check_unknown\n\nsklearn/preprocessing/_encoders.py:OneHotEncoder._transform_new\nline: 565\nfunction: OneHotEncoder._transform_new\n\nsklearn/preprocessing/_encoders.py:OneHotEncoder.transform\nline: 604\nfunction: OneHotEncoder.transform\n```"], "meta_data": {"repo": "scikit-learn/scikit-learn", "base_commit": "02dc9ed680e7f53f1b0d410dcdd37341c7958eb1", "problem_statement": "OneHotEncoder ignore unknown error when categories are strings \n#### Description\r\n\r\nThis bug is very specific, but it happens when you set OneHotEncoder to ignore unknown entries.\r\nand your labels are strings. The memory of the arrays is not handled safely and it can lead to a ValueError\r\n\r\nBasically, when you call the transform method it will sets all the unknown strings on your array to OneHotEncoder.categories_[i][0] which is the first category alphabetically sorted given for fit\r\nIf this OneHotEncoder.categories_[i][0] is a long string, and the array that you want to transform has small strings, then it is impossible to fit the whole  OneHotEncoder.categories_[i][0] into the entries of the array we want to transform. So  OneHotEncoder.categories_[i][0]  is truncated and this raise the ValueError.\r\n\r\n\r\n\r\n#### Steps/Code to Reproduce\r\n```\r\n\r\nimport numpy as np\r\nfrom sklearn.preprocessing import OneHotEncoder\r\n\r\n\r\n# It needs to be numpy arrays, the error does not appear \r\n# is you have lists of lists because it gets treated like an array of objects.\r\ntrain  = np.array([ '22','333','4444','11111111' ]).reshape((-1,1))\r\ntest   = np.array([ '55555',  '22' ]).reshape((-1,1))\r\n\r\nohe = OneHotEncoder(dtype=bool,handle_unknown='ignore')\r\n\r\nohe.fit( train )\r\nenc_test = ohe.transform( test )\r\n\r\n```\r\n\r\n\r\n#### Expected Results\r\nHere we should get an sparse matrix 2x4 false everywhere except at (1,1) the '22' that is known\r\n\r\n#### Actual Results\r\n\r\n> ValueError: y contains previously unseen labels: ['111111']\r\n\r\n\r\n#### Versions\r\nSystem:\r\n    python: 2.7.12 (default, Dec  4 2017, 14:50:18)  [GCC 5.4.0 20160609]\r\n   machine: Linux-4.4.0-138-generic-x86_64-with-Ubuntu-16.04-xenial\r\nexecutable: /usr/bin/python\r\n\r\nBLAS:\r\n    macros: HAVE_CBLAS=None\r\ncblas_libs: openblas, openblas\r\n  lib_dirs: /usr/lib\r\n\r\nPython deps:\r\n    Cython: 0.25.2\r\n     scipy: 0.18.1\r\nsetuptools: 36.7.0\r\n       pip: 9.0.1\r\n     numpy: 1.15.2\r\n    pandas: 0.19.1\r\n   sklearn: 0.21.dev0\r\n\r\n\r\n\r\n#### Comments\r\n\r\nI already implemented a fix for this issue, where I check the size of the elements in the array before, and I cast them into objects if necessary.\n", "patch": "diff --git a/sklearn/preprocessing/_encoders.py b/sklearn/preprocessing/_encoders.py\n--- a/sklearn/preprocessing/_encoders.py\n+++ b/sklearn/preprocessing/_encoders.py\n@@ -110,7 +110,14 @@ def _transform(self, X, handle_unknown='error'):\n                     # continue `The rows are marked `X_mask` and will be\n                     # removed later.\n                     X_mask[:, i] = valid_mask\n-                    Xi = Xi.copy()\n+                    # cast Xi into the largest string type necessary\n+                    # to handle different lengths of numpy strings\n+                    if (self.categories_[i].dtype.kind in ('U', 'S')\n+                            and self.categories_[i].itemsize > Xi.itemsize):\n+                        Xi = Xi.astype(self.categories_[i].dtype)\n+                    else:\n+                        Xi = Xi.copy()\n+\n                     Xi[~valid_mask] = self.categories_[i][0]\n             _, encoded = _encode(Xi, self.categories_[i], encode=True)\n             X_int[:, i] = encoded\n"}}
{"instance_id": "psf__requests-2317", "found_files": ["requests/sessions.py", "requests/compat.py", "requests/models.py", "requests/api.py"], "found_modules": ["requests/sessions.py:Session", "requests/models.py:PreparedRequest", "requests/api.py:request"], "found_entities": ["requests/sessions.py:Session.request", "requests/models.py:PreparedRequest.prepare_method", "requests/api.py:request"], "raw_output_loc": ["```\nrequests/sessions.py\nline: 428\nfunction: Session.request\n\nrequests/models.py\nline: 328\nfunction: PreparedRequest.prepare_method\n\nrequests/compat.py\nline: 111\nfunction: builtin_str\n```", "```\nrequests/sessions.py\nline: 428\nfunction: Session.request\n\nrequests/compat.py\nline: 96\nline: 111\nfunction: builtin_str\n\nrequests/api.py\nline: 17\nfunction: request\n```"], "meta_data": {"repo": "psf/requests", "base_commit": "091991be0da19de9108dbe5e3752917fea3d7fdc", "problem_statement": "method = builtin_str(method) problem\nIn requests/sessions.py is a command:\n\nmethod = builtin_str(method)\nConverts method from\nb\u2019GET\u2019\nto\n\"b'GET\u2019\"\n\nWhich is the literal string, no longer a binary string.  When requests tries to use the method \"b'GET\u2019\u201d, it gets a 404 Not Found response.\n\nI am using python3.4 and python-neutronclient (2.3.9) with requests (2.4.3).  neutronclient is broken because it uses this \"args = utils.safe_encode_list(args)\" command which converts all the values to binary string, including method.\n\nI'm not sure if this is a bug with neutronclient or a bug with requests, but I'm starting here.  Seems if requests handled the method value being a binary string, we wouldn't have any problem.\n\nAlso, I tried in python2.6 and this bug doesn't exist there. Some difference between 2.6 and 3.4 makes this not work right.\n\n", "patch": "diff --git a/requests/sessions.py b/requests/sessions.py\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -13,7 +13,7 @@\n from datetime import datetime\n \n from .auth import _basic_auth_str\n-from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str\n+from .compat import cookielib, OrderedDict, urljoin, urlparse\n from .cookies import (\n     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n@@ -425,7 +425,7 @@ def request(self, method, url,\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n-        method = builtin_str(method)\n+        method = to_native_string(method)\n \n         # Create the Request.\n         req = Request(\n"}}
{"instance_id": "sympy__sympy-22005", "found_files": ["sympy/solvers/polysys.py"], "found_modules": ["sympy/solvers/polysys.py:solve_generic", "sympy/solvers/polysys.py:solve_poly_system"], "found_entities": ["sympy/solvers/polysys.py:solve_generic._solve_reduced_system", "sympy/solvers/polysys.py:solve_poly_system"], "raw_output_loc": ["```\nsympy/solvers/polysys.py\nline: 240\nline: 243\nfunction: solve_generic._solve_reduced_system\n\nsympy/solvers/polysys.py\nline: 63\nfunction: solve_poly_system\n\nsympy/solvers/tests/test_polysys.py\nline: 48\nfunction: test_solve_poly_system\n```", "```\nsympy/solvers/polysys.py\nline: 243\nfunction: solve_generic._solve_reduced_system\n```"], "meta_data": {"repo": "sympy/sympy", "base_commit": "2c83657ff1c62fc2761b639469fdac7f7561a72a", "problem_statement": "detection of infinite solution request\n```python\r\n>>> solve_poly_system((x - 1,), x, y)\r\nTraceback (most recent call last):\r\n...\r\nNotImplementedError:\r\nonly zero-dimensional systems supported (finite number of solutions)\r\n>>> solve_poly_system((y - 1,), x, y)  <--- this is not handled correctly\r\n[(1,)]\r\n```\r\n```diff\r\ndiff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\r\nindex b9809fd4e9..674322d4eb 100644\r\n--- a/sympy/solvers/polysys.py\r\n+++ b/sympy/solvers/polysys.py\r\n@@ -240,7 +240,7 @@ def _solve_reduced_system(system, gens, entry=False):\r\n \r\n         univariate = list(filter(_is_univariate, basis))\r\n \r\n-        if len(univariate) == 1:\r\n+        if len(univariate) == 1 and len(gens) == 1:\r\n             f = univariate.pop()\r\n         else:\r\n             raise NotImplementedError(filldedent('''\r\ndiff --git a/sympy/solvers/tests/test_polysys.py b/sympy/solvers/tests/test_polysys.py\r\nindex 58419f8762..9e674a6fe6 100644\r\n--- a/sympy/solvers/tests/test_polysys.py\r\n+++ b/sympy/solvers/tests/test_polysys.py\r\n@@ -48,6 +48,10 @@ def test_solve_poly_system():\r\n     raises(NotImplementedError, lambda: solve_poly_system(\r\n         [z, -2*x*y**2 + x + y**2*z, y**2*(-z - 4) + 2]))\r\n     raises(PolynomialError, lambda: solve_poly_system([1/x], x))\r\n+    raises(NotImplementedError, lambda: solve_poly_system(\r\n+        Poly(x - 1, x, y), (x, y)))\r\n+    raises(NotImplementedError, lambda: solve_poly_system(\r\n+        Poly(y - 1, x, y), (x, y)))\r\n \r\n \r\n def test_solve_biquadratic():\r\n```\n", "patch": "diff --git a/sympy/solvers/polysys.py b/sympy/solvers/polysys.py\n--- a/sympy/solvers/polysys.py\n+++ b/sympy/solvers/polysys.py\n@@ -240,6 +240,12 @@ def _solve_reduced_system(system, gens, entry=False):\n \n         univariate = list(filter(_is_univariate, basis))\n \n+        if len(basis) < len(gens):\n+            raise NotImplementedError(filldedent('''\n+                only zero-dimensional systems supported\n+                (finite number of solutions)\n+                '''))\n+\n         if len(univariate) == 1:\n             f = univariate.pop()\n         else:\n"}}
{"instance_id": "django__django-13033", "found_files": ["django/db/models/sql/query.py", "django/db/models/fields/related.py", "django/db/models/options.py"], "found_modules": ["django/db/models/sql/query.py:Query", "django/db/models/fields/related.py:ForeignObject", "django/db/models/options.py:Options"], "found_entities": ["django/db/models/sql/query.py:Query.add_ordering", "django/db/models/sql/query.py:Query.names_to_path", "django/db/models/fields/related.py:ForeignObject.get_path_info", "django/db/models/sql/query.py:Query.join", "django/db/models/options.py:Options.get_field"], "raw_output_loc": ["```\ndjango/db/models/sql/query.py:Query.add_ordering\nline: 1889\nfunction: Query.add_ordering\n\ncore/utils/helper_functions.py\nline: 101\nfunction: calculate_metrics\n\ntests/unit/test_alpha_processor.py\nline: 30\nclass: TestAlphaProcessor\nfunction: TestAlphaProcessor.test_data_processing_logic\n\nsrc/module_beta/file2.py\nline: 77\nfunction: BetaService.handle_request\n\nconfigs/config_loader.py\nline: 15\nfunction: load_app_configuration\n```", "```\ndjango/db/models/sql/query.py:Query.add_ordering\nline: 1890\nline: 1920\nfunction: Query.add_ordering\n\ndjango/db/models/sql/query.py:Query.names_to_path\nline: 1425\nline: 1495\nfunction: Query.names_to_path\n\ndjango/db/models/fields/related.py:ForeignObject.get_path_info\nline: 706\nline: 718\nfunction: ForeignObject.get_path_info\n\ndjango/db/models/sql/query.py:Query.join\nline: 1425\nline: 1495\nfunction: Query.join\n\ndjango/db/models/options.py:Options.get_field\nline: 1448\nfunction: Options.get_field\n```"], "meta_data": {"repo": "django/django", "base_commit": "a59de6e89e8dc1f3e71c9a5a5bbceb373ea5247e", "problem_statement": "Self referencing foreign key doesn't correctly order by a relation \"_id\" field.\nDescription\n\t\nInitially discovered on 2.2.10 but verified still happens on 3.0.6. Given the following models:\nclass OneModel(models.Model):\n\tclass Meta:\n\t\tordering = (\"-id\",)\n\tid = models.BigAutoField(primary_key=True)\n\troot = models.ForeignKey(\"OneModel\", on_delete=models.CASCADE, null=True)\n\toneval = models.BigIntegerField(null=True)\nclass TwoModel(models.Model):\n\tid = models.BigAutoField(primary_key=True)\n\trecord = models.ForeignKey(OneModel, on_delete=models.CASCADE)\n\ttwoval = models.BigIntegerField(null=True)\nThe following queryset gives unexpected results and appears to be an incorrect SQL query:\nqs = TwoModel.objects.filter(record__oneval__in=[1,2,3])\nqs = qs.order_by(\"record__root_id\")\nprint(qs.query)\nSELECT \"orion_twomodel\".\"id\", \"orion_twomodel\".\"record_id\", \"orion_twomodel\".\"twoval\" FROM \"orion_twomodel\" INNER JOIN \"orion_onemodel\" ON (\"orion_twomodel\".\"record_id\" = \"orion_onemodel\".\"id\") LEFT OUTER JOIN \"orion_onemodel\" T3 ON (\"orion_onemodel\".\"root_id\" = T3.\"id\") WHERE \"orion_onemodel\".\"oneval\" IN (1, 2, 3) ORDER BY T3.\"id\" DESC\nThe query has an unexpected DESCENDING sort. That appears to come from the default sort order on the OneModel class, but I would expect the order_by() to take prececence. The the query has two JOINS, which is unnecessary. It appears that, since OneModel.root is a foreign key to itself, that is causing it to do the unnecessary extra join. In fact, testing a model where root is a foreign key to a third model doesn't show the problem behavior.\nNote also that the queryset with order_by(\"record__root\") gives the exact same SQL.\nThis queryset gives correct results and what looks like a pretty optimal SQL:\nqs = TwoModel.objects.filter(record__oneval__in=[1,2,3])\nqs = qs.order_by(\"record__root__id\")\nprint(qs.query)\nSELECT \"orion_twomodel\".\"id\", \"orion_twomodel\".\"record_id\", \"orion_twomodel\".\"twoval\" FROM \"orion_twomodel\" INNER JOIN \"orion_onemodel\" ON (\"orion_twomodel\".\"record_id\" = \"orion_onemodel\".\"id\") WHERE \"orion_onemodel\".\"oneval\" IN (1, 2, 3) ORDER BY \"orion_onemodel\".\"root_id\" ASC\nSo is this a potential bug or a misunderstanding on my part?\nAnother queryset that works around the issue and gives a reasonable SQL query and expected results:\nqs = TwoModel.objects.filter(record__oneval__in=[1,2,3])\nqs = qs.annotate(root_id=F(\"record__root_id\"))\nqs = qs.order_by(\"root_id\")\nprint(qs.query)\nSELECT \"orion_twomodel\".\"id\", \"orion_twomodel\".\"record_id\", \"orion_twomodel\".\"twoval\" FROM \"orion_twomodel\" INNER JOIN \"orion_onemodel\" ON (\"orion_twomodel\".\"record_id\" = \"orion_onemodel\".\"id\") WHERE \"orion_onemodel\".\"oneval\" IN (1, 2, 3) ORDER BY \"orion_onemodel\".\"zero_id\" ASC\nASCENDING sort, and a single INNER JOIN, as I'd expect. That actually works for my use because I need that output column anyway.\nOne final oddity; with the original queryset but the inverted sort order_by():\nqs = TwoModel.objects.filter(record__oneval__in=[1,2,3])\nqs = qs.order_by(\"-record__root_id\")\nprint(qs.query)\nSELECT \"orion_twomodel\".\"id\", \"orion_twomodel\".\"record_id\", \"orion_twomodel\".\"twoval\" FROM \"orion_twomodel\" INNER JOIN \"orion_onemodel\" ON (\"orion_twomodel\".\"record_id\" = \"orion_onemodel\".\"id\") LEFT OUTER JOIN \"orion_onemodel\" T3 ON (\"orion_onemodel\".\"root_id\" = T3.\"id\") WHERE \"orion_onemodel\".\"oneval\" IN (1, 2, 3) ORDER BY T3.\"id\" ASC\nOne gets the query with the two JOINs but an ASCENDING sort order. I was not under the impression that sort orders are somehow relative to the class level sort order, eg: does specifing order_by(\"-record__root_id\") invert the class sort order? Testing that on a simple case doesn't show that behavior at all.\nThanks for any assistance and clarification.\n", "patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -727,7 +727,12 @@ def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n         # If we get to this point and the field is a relation to another model,\n         # append the default ordering for that model unless it is the pk\n         # shortcut or the attribute name of the field that is specified.\n-        if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':\n+        if (\n+            field.is_relation and\n+            opts.ordering and\n+            getattr(field, 'attname', None) != pieces[-1] and\n+            name != 'pk'\n+        ):\n             # Firstly, avoid infinite loops.\n             already_seen = already_seen or set()\n             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n"}}
{"instance_id": "django__django-11910", "found_files": ["django/db/migrations/operations/fields.py"], "found_modules": ["django/db/migrations/operations/fields.py:AlterField", "django/db/migrations/operations/fields.py:RenameField"], "found_entities": ["django/db/migrations/operations/fields.py:AlterField.database_forwards", "django/db/migrations/operations/fields.py:RenameField.state_forwards"], "raw_output_loc": ["```\ndjango/db/migrations/operations/fields.py:AlterField\nline: 241\nline: 246\nfunction: AlterField.database_forwards\n\n```", "```\ndjango/db/migrations/operations/fields.py:RenameField\nline: 337\nline: 349\nfunction: RenameField.state_forwards\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "d232fd76a85870daf345fd8f8d617fe7802ae194", "problem_statement": "ForeignKey's to_field parameter gets the old field's name when renaming a PrimaryKey.\nDescription\n\t\nHaving these two models \nclass ModelA(models.Model):\n\tfield_wrong = models.CharField('field1', max_length=50, primary_key=True) # I'm a Primary key.\nclass ModelB(models.Model):\n\tfield_fk = models.ForeignKey(ModelA, blank=True, null=True, on_delete=models.CASCADE) \n... migrations applyed ...\nthe ModelA.field_wrong field has been renamed ... and Django recognizes the \"renaming\"\n# Primary key renamed\nclass ModelA(models.Model):\n\tfield_fixed = models.CharField('field1', max_length=50, primary_key=True) # I'm a Primary key.\nAttempts to to_field parameter. \nThe to_field points to the old_name (field_typo) and not to the new one (\"field_fixed\")\nclass Migration(migrations.Migration):\n\tdependencies = [\n\t\t('app1', '0001_initial'),\n\t]\n\toperations = [\n\t\tmigrations.RenameField(\n\t\t\tmodel_name='modela',\n\t\t\told_name='field_wrong',\n\t\t\tnew_name='field_fixed',\n\t\t),\n\t\tmigrations.AlterField(\n\t\t\tmodel_name='modelb',\n\t\t\tname='modela',\n\t\t\tfield=models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.CASCADE, to='app1.ModelB', to_field='field_wrong'),\n\t\t),\n\t]\n", "patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -927,6 +927,10 @@ def generate_altered_fields(self):\n                 if remote_field_name:\n                     to_field_rename_key = rename_key + (remote_field_name,)\n                     if to_field_rename_key in self.renamed_fields:\n+                        # Repoint both model and field name because to_field\n+                        # inclusion in ForeignKey.deconstruct() is based on\n+                        # both.\n+                        new_field.remote_field.model = old_field.remote_field.model\n                         new_field.remote_field.field_name = old_field.remote_field.field_name\n                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n                 from_fields = getattr(new_field, 'from_fields', None)\n"}}
{"instance_id": "pytest-dev__pytest-7220", "found_files": ["src/_pytest/_code/code.py", "src/_pytest/fixtures.py", "src/_pytest/monkeypatch.py"], "found_modules": ["src/_pytest/_code/code.py:Code", "src/_pytest/_code/code.py:TracebackEntry", "src/_pytest/fixtures.py:FixtureDef", "src/_pytest/_code/code.py:ExceptionInfo", "src/_pytest/monkeypatch.py:MonkeyPatch"], "found_entities": ["src/_pytest/_code/code.py:Code.path", "src/_pytest/_code/code.py:TracebackEntry.path", "src/_pytest/_code/code.py:TracebackEntry.frame", "src/_pytest/fixtures.py:FixtureDef.execute", "src/_pytest/_code/code.py:ExceptionInfo._getreprcrash", "src/_pytest/monkeypatch.py:MonkeyPatch.chdir"], "raw_output_loc": ["```\nsrc/_pytest/_code/code.py:Code.path\nline: 75\nfunction: Code.path\n\nsrc/_pytest/_code/code.py:TracebackEntry.path\nline: 215\nfunction: TracebackEntry.path\n\nsrc/_pytest/fixtures.py:FixtureDef.execute\nline: 901\nfunction: FixtureDef.execute\n```", "```\nsrc/_pytest/_code/code.py\nline: 75\nclass: Code\nfunction: Code.path\n\nsrc/_pytest/_code/code.py\nline: 197\nclass: TracebackEntry\nfunction: TracebackEntry.frame\n\nsrc/_pytest/_code/code.py\nline: 215\nclass: TracebackEntry\nfunction: TracebackEntry.path\n\nsrc/_pytest/_code/code.py\nline: 563\nclass: ExceptionInfo\nfunction: ExceptionInfo._getreprcrash\n\nsrc/_pytest/monkeypatch.py\nline: 275\nclass: MonkeyPatch\nfunction: MonkeyPatch.chdir\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "56bf819c2f4eaf8b36bd8c42c06bb59d5a3bfc0f", "problem_statement": "Wrong path to test file when directory changed in fixture\nFiles are shown as relative to new directory when working directory is changed in a fixture. This makes it impossible to jump to the error as the editor is unaware of the directory change. The displayed directory should stay relative to the original directory.\r\n\r\ntest_path_error.py:\r\n```python\r\nimport os\r\nimport errno\r\nimport shutil\r\n\r\nimport pytest\r\n\r\n\r\n@pytest.fixture\r\ndef private_dir():  # or (monkeypatch)\r\n    out_dir = 'ddd'\r\n\r\n    try:\r\n        shutil.rmtree(out_dir)\r\n    except OSError as ex:\r\n        if ex.errno != errno.ENOENT:\r\n            raise\r\n    os.mkdir(out_dir)\r\n\r\n    old_dir = os.getcwd()\r\n    os.chdir(out_dir)\r\n    yield out_dir\r\n    os.chdir(old_dir)\r\n\r\n    # Same issue if using:\r\n    # monkeypatch.chdir(out_dir)\r\n\r\n\r\ndef test_show_wrong_path(private_dir):\r\n    assert False\r\n```\r\n\r\n```diff\r\n+ Expected: test_path_error.py:29: AssertionError\r\n- Displayed: ../test_path_error.py:29: AssertionError\r\n```\r\n\r\nThe full output is:\r\n```\r\n-*- mode: compilation; default-directory: \"~/src/pytest_path_error/\" -*-\r\nCompilation started at Fri Jan 10 00:05:52\r\n\r\nnox\r\nnox > Running session test\r\nnox > Creating virtual environment (virtualenv) using python3.7 in .nox/test\r\nnox > pip install pytest>=5.3\r\nnox > pip freeze\r\nattrs==19.3.0\r\nimportlib-metadata==1.3.0\r\nmore-itertools==8.0.2\r\npackaging==20.0\r\npluggy==0.13.1\r\npy==1.8.1\r\npyparsing==2.4.6\r\npytest==5.3.2\r\nsix==1.13.0\r\nwcwidth==0.1.8\r\nzipp==0.6.0\r\nnox > pytest \r\n================================= test session starts =================================\r\nplatform linux -- Python 3.7.5, pytest-5.3.2, py-1.8.1, pluggy-0.13.1\r\nrootdir: /home/lhn/src/pytest_path_error\r\ncollected 1 item                                                                      \r\n\r\ntest_path_error.py F                                                            [100%]\r\n\r\n====================================== FAILURES =======================================\r\n________________________________ test_show_wrong_path _________________________________\r\n\r\nprivate_dir = 'ddd'\r\n\r\n    def test_show_wrong_path(private_dir):\r\n>       assert False\r\nE       assert False\r\n\r\n../test_path_error.py:29: AssertionError\r\n================================== 1 failed in 0.03s ==================================\r\nnox > Command pytest  failed with exit code 1\r\nnox > Session test failed.\r\n\r\nCompilation exited abnormally with code 1 at Fri Jan 10 00:06:01\r\n```\r\n\r\nnoxfile.py:\r\n```python\r\nimport nox\r\n\r\n@nox.session(python='3.7')\r\ndef test(session):\r\n    session.install('pytest>=5.3')\r\n    session.run('pip', 'freeze')\r\n    session.run('pytest')\r\n```\n", "patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -29,6 +29,7 @@\n from _pytest.mark.structures import MarkDecorator\n from _pytest.mark.structures import NodeKeywords\n from _pytest.outcomes import fail\n+from _pytest.pathlib import Path\n from _pytest.store import Store\n \n if TYPE_CHECKING:\n@@ -361,9 +362,14 @@ def _repr_failure_py(\n         else:\n             truncate_locals = True\n \n+        # excinfo.getrepr() formats paths relative to the CWD if `abspath` is False.\n+        # It is possible for a fixture/test to change the CWD while this code runs, which\n+        # would then result in the user seeing confusing paths in the failure message.\n+        # To fix this, if the CWD changed, always display the full absolute path.\n+        # It will be better to just always display paths relative to invocation_dir, but\n+        # this requires a lot of plumbing (#6428).\n         try:\n-            os.getcwd()\n-            abspath = False\n+            abspath = Path(os.getcwd()) != Path(self.config.invocation_dir)\n         except OSError:\n             abspath = True\n \n"}}
{"instance_id": "matplotlib__matplotlib-23476", "found_files": ["lib/matplotlib/figure.py", "lib/matplotlib/backends/backend_macosx.py", "lib/matplotlib/backend_bases.py"], "found_modules": ["lib/matplotlib/figure.py:Figure", "lib/matplotlib/backends/backend_macosx.py:FigureCanvasMac", "lib/matplotlib/backend_bases.py:_Backend"], "found_entities": ["lib/matplotlib/figure.py:Figure.__setstate__", "lib/matplotlib/backend_bases.py:_Backend.new_figure_manager_given_figure", "lib/matplotlib/backends/backend_macosx.py:FigureCanvasMac.resize"], "raw_output_loc": ["```\nlib/matplotlib/figure.py\nline: 3047\nfunction: Figure.__setstate__\n\nlib/matplotlib/backends/backend_macosx.py\nline: 38\nclass: FigureCanvasMac\nfunction: FigureCanvasMac.__init__\n\nlib/matplotlib/backend_bases.py\nline: 3510\nfunction: _Backend.new_figure_manager_given_figure\n```", "```\nlib/matplotlib/figure.py\nline: 3035\nclass: Figure\nfunction: Figure.__setstate__\n\nlib/matplotlib/backends/backend_macosx.py\nline: 38\nclass: FigureCanvasMac\nfunction: FigureCanvasMac.__init__\n\nlib/matplotlib/backend_bases.py\nline: 3499\nfunction: new_figure_manager_given_figure\n\nlib/matplotlib/backends/backend_macosx.py\nline: 96\nfunction: FigureCanvasMac.resize\n\nlib/matplotlib/figure.py\nline: 3047\nfunction: FigureCanvasBase\n```"], "meta_data": {"repo": "matplotlib/matplotlib", "base_commit": "33a0599711d26dc2b79f851c6daed4947df7c167", "problem_statement": "[Bug]: DPI of a figure is doubled after unpickling on M1 Mac\n### Bug summary\r\n\r\nWhen a figure is unpickled, it's dpi is doubled. This behaviour happens every time and if done in a loop it can cause an `OverflowError`.\r\n\r\n### Code for reproduction\r\n\r\n```python\r\nimport numpy as np\r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\nimport pickle\r\nimport platform\r\n\r\nprint(matplotlib.get_backend())\r\nprint('Matplotlib ver:', matplotlib.__version__)\r\nprint('Platform:', platform.platform())\r\nprint('System:', platform.system())\r\nprint('Release:', platform.release())\r\nprint('Python ver:', platform.python_version())\r\n\r\n\r\ndef dump_load_get_dpi(fig):\r\n    with open('sinus.pickle','wb') as file:\r\n        pickle.dump(fig, file)\r\n\r\n    with open('sinus.pickle', 'rb') as blob:\r\n        fig2 = pickle.load(blob)\r\n    return fig2, fig2.dpi\r\n\r\n\r\ndef run():\r\n    fig = plt.figure()\r\n    x = np.linspace(0,2*np.pi)\r\n    y = np.sin(x)\r\n\r\n    for i in range(32):\r\n        print(f'{i}: {fig.dpi}')\r\n        fig, dpi = dump_load_get_dpi(fig)\r\n\r\n\r\nif __name__ == '__main__':\r\n    run()\r\n```\r\n\r\n\r\n### Actual outcome\r\n\r\n```\r\nMacOSX\r\nMatplotlib ver: 3.5.2\r\nPlatform: macOS-12.4-arm64-arm-64bit\r\nSystem: Darwin\r\nRelease: 21.5.0\r\nPython ver: 3.9.12\r\n0: 200.0\r\n1: 400.0\r\n2: 800.0\r\n3: 1600.0\r\n4: 3200.0\r\n5: 6400.0\r\n6: 12800.0\r\n7: 25600.0\r\n8: 51200.0\r\n9: 102400.0\r\n10: 204800.0\r\n11: 409600.0\r\n12: 819200.0\r\n13: 1638400.0\r\n14: 3276800.0\r\n15: 6553600.0\r\n16: 13107200.0\r\n17: 26214400.0\r\n18: 52428800.0\r\n19: 104857600.0\r\n20: 209715200.0\r\n21: 419430400.0\r\nTraceback (most recent call last):\r\n  File \"/Users/wsykala/projects/matplotlib/example.py\", line 34, in <module>\r\n    run()\r\n  File \"/Users/wsykala/projects/matplotlib/example.py\", line 30, in run\r\n    fig, dpi = dump_load_get_dpi(fig)\r\n  File \"/Users/wsykala/projects/matplotlib/example.py\", line 20, in dump_load_get_dpi\r\n    fig2 = pickle.load(blob)\r\n  File \"/Users/wsykala/miniconda3/envs/playground/lib/python3.9/site-packages/matplotlib/figure.py\", line 2911, in __setstate__\r\n    mgr = plt._backend_mod.new_figure_manager_given_figure(num, self)\r\n  File \"/Users/wsykala/miniconda3/envs/playground/lib/python3.9/site-packages/matplotlib/backend_bases.py\", line 3499, in new_figure_manager_given_figure\r\n    canvas = cls.FigureCanvas(figure)\r\n  File \"/Users/wsykala/miniconda3/envs/playground/lib/python3.9/site-packages/matplotlib/backends/backend_macosx.py\", line 32, in __init__\r\n    _macosx.FigureCanvas.__init__(self, width, height)\r\nOverflowError: signed integer is greater than maximum\r\n```\r\n\r\n### Expected outcome\r\n\r\n```\r\nMacOSX\r\nMatplotlib ver: 3.5.2\r\nPlatform: macOS-12.4-arm64-arm-64bit\r\nSystem: Darwin\r\nRelease: 21.5.0\r\nPython ver: 3.9.12\r\n0: 200.0\r\n1: 200.0\r\n2: 200.0\r\n3: 200.0\r\n4: 200.0\r\n5: 200.0\r\n6: 200.0\r\n7: 200.0\r\n8: 200.0\r\n9: 200.0\r\n10: 200.0\r\n11: 200.0\r\n12: 200.0\r\n13: 200.0\r\n14: 200.0\r\n15: 200.0\r\n16: 200.0\r\n17: 200.0\r\n18: 200.0\r\n19: 200.0\r\n20: 200.0\r\n21: 200.0\r\n22: 200.0\r\n```\r\n\r\n### Additional information\r\n\r\nThis seems to happen only on M1 MacBooks and the version of python doesn't matter.\r\n\r\n### Operating system\r\n\r\nOS/X\r\n\r\n### Matplotlib Version\r\n\r\n3.5.2\r\n\r\n### Matplotlib Backend\r\n\r\nMacOSX\r\n\r\n### Python version\r\n\r\n3.9.12\r\n\r\n### Jupyter version\r\n\r\n_No response_\r\n\r\n### Installation\r\n\r\npip\n", "patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -3023,6 +3023,9 @@ def __getstate__(self):\n         # Set cached renderer to None -- it can't be pickled.\n         state[\"_cachedRenderer\"] = None\n \n+        # discard any changes to the dpi due to pixel ratio changes\n+        state[\"_dpi\"] = state.get('_original_dpi', state['_dpi'])\n+\n         # add version information to the state\n         state['__mpl_version__'] = mpl.__version__\n \n"}}
{"instance_id": "django__django-11583", "found_files": ["django/utils/autoreload.py"], "found_modules": ["django/utils/autoreload.py:iter_modules_and_files", "django/utils/autoreload.py:iter_all_python_module_files", "django/utils/autoreload.py:BaseReloader"], "found_entities": ["django/utils/autoreload.py:iter_modules_and_files", "django/utils/autoreload.py:iter_all_python_module_files", "django/utils/autoreload.py:BaseReloader.watch_dir", "django/utils/autoreload.py:BaseReloader.watched_files"], "raw_output_loc": ["```\ndjango/utils/autoreload.py\nline: 139\nfunction: iter_modules_and_files\n\npathlib.py\nline: 330\nfunction: _resolve\n\npathlib.py\nline: 441\nfunction: readlink\n\ndjango/utils/autoreload.py\nline: 241\nfunction: BaseReloader.watched_files\n\ndjango/utils/autoreload.py\nline: 105\nfunction: iter_all_python_module_files\n```", "```\ndjango/utils/autoreload.py\nline: 141\nfunction: iter_modules_and_files\n\n```"], "meta_data": {"repo": "django/django", "base_commit": "60dc957a825232fdda9138e2f8878b2ca407a7c9", "problem_statement": "Auto-reloading with StatReloader very intermittently throws \"ValueError: embedded null byte\".\nDescription\n\t\nRaising this mainly so that it's tracked, as I have no idea how to reproduce it, nor why it's happening. It ultimately looks like a problem with Pathlib, which wasn't used prior to 2.2.\nStacktrace:\nTraceback (most recent call last):\n File \"manage.py\" ...\n\texecute_from_command_line(sys.argv)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/__init__.py\", line 381, in execute_from_command_line\n\tutility.execute()\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/__init__.py\", line 375, in execute\n\tself.fetch_command(subcommand).run_from_argv(self.argv)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/base.py\", line 323, in run_from_argv\n\tself.execute(*args, **cmd_options)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 60, in execute\n\tsuper().execute(*args, **options)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/base.py\", line 364, in execute\n\toutput = self.handle(*args, **options)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 95, in handle\n\tself.run(**options)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/core/management/commands/runserver.py\", line 102, in run\n\tautoreload.run_with_reloader(self.inner_run, **options)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 577, in run_with_reloader\n\tstart_django(reloader, main_func, *args, **kwargs)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 562, in start_django\n\treloader.run(django_main_thread)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 280, in run\n\tself.run_loop()\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 286, in run_loop\n\tnext(ticker)\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 326, in tick\n\tfor filepath, mtime in self.snapshot_files():\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 342, in snapshot_files\n\tfor file in self.watched_files():\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 241, in watched_files\n\tyield from iter_all_python_module_files()\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 103, in iter_all_python_module_files\n\treturn iter_modules_and_files(modules, frozenset(_error_files))\n File \"/Userz/kez/path/to/venv/lib/python3.6/site-packages/django/utils/autoreload.py\", line 132, in iter_modules_and_files\n\tresults.add(path.resolve().absolute())\n File \"/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/pathlib.py\", line 1120, in resolve\n\ts = self._flavour.resolve(self, strict=strict)\n File \"/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/pathlib.py\", line 346, in resolve\n\treturn _resolve(base, str(path)) or sep\n File \"/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/pathlib.py\", line 330, in _resolve\n\ttarget = accessor.readlink(newpath)\n File \"/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/pathlib.py\", line 441, in readlink\n\treturn os.readlink(path)\nValueError: embedded null byte\nI did print(path) before os.readlink(path) in pathlib and ended up with:\n/Users/kez\n/Users/kez/.pyenv\n/Users/kez/.pyenv/versions\n/Users/kez/.pyenv/versions/3.6.2\n/Users/kez/.pyenv/versions/3.6.2/lib\n/Users/kez/.pyenv/versions/3.6.2/lib/python3.6\n/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/asyncio\n/Users/kez/.pyenv/versions/3.6.2/lib/python3.6/asyncio/selector_events.py\n/Users\nIt always seems to be /Users which is last\nIt may have already printed /Users as part of another .resolve() multiple times (that is, the order is not deterministic, and it may have traversed beyond /Users successfully many times during startup.\nI don't know where to begin looking for the rogue null byte, nor why it only exists sometimes.\nBest guess I have is that there's a mountpoint in /Users to a samba share which may not have been connected to yet? I dunno.\nI have no idea if it's fixable without removing the use of pathlib (which tbh I think should happen anyway, because it's slow) and reverting to using os.path.join and friends. \nI have no idea if it's fixed in a later Python version, but with no easy way to reproduce ... dunno how I'd check.\nI have no idea if it's something specific to my system (pyenv, OSX 10.11, etc)\n", "patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -143,6 +143,10 @@ def iter_modules_and_files(modules, extra_files):\n             # The module could have been removed, don't fail loudly if this\n             # is the case.\n             continue\n+        except ValueError as e:\n+            # Network filesystems may return null bytes in file paths.\n+            logger.debug('\"%s\" raised when resolving path: \"%s\"' % (str(e), path))\n+            continue\n         results.add(resolved_path)\n     return frozenset(results)\n \n"}}
{"instance_id": "psf__requests-3362", "found_files": ["requests/models.py", "requests/utils.py"], "found_modules": ["requests/models.py:Response", "requests/utils.py:stream_decode_response_unicode"], "found_entities": ["requests/models.py:Response.iter_content", "requests/utils.py:stream_decode_response_unicode", "requests/models.py:Response.text"], "raw_output_loc": ["```\nrequests/models.py:Response.iter_content\nline: 653\nfunction: Response.iter_content\n\nrequests/utils.py:stream_decode_response_unicode\nline: 359\nfunction: stream_decode_response_unicode\n\nrequests/models.py:Response.text\nline: 758\nfunction: Response.text\n```", "```\nrequests/models.py:Response.iter_content\nline: 653\nline: 697-699\nfunction: Response.iter_content\n\nrequests/models.py:Response\nfunction: Response.__init__\n\nrequests/utils.py:stream_decode_response_unicode\nline: 359-374\nfunction: stream_decode_response_unicode\n```"], "meta_data": {"repo": "psf/requests", "base_commit": "36453b95b13079296776d11b09cab2567ea3e703", "problem_statement": "Uncertain about content/text vs iter_content(decode_unicode=True/False)\nWhen requesting an application/json document, I'm seeing `next(r.iter_content(16*1024, decode_unicode=True))` returning bytes, whereas `r.text` returns unicode. My understanding was that both should return a unicode object. In essence, I thought \"iter_content\" was equivalent to \"iter_text\" when decode_unicode was True. Have I misunderstood something? I can provide an example if needed.\n\nFor reference, I'm using python 3.5.1 and requests 2.10.0.\n\nThanks!\n\n", "patch": "diff --git a/requests/utils.py b/requests/utils.py\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -358,13 +358,20 @@ def get_encoding_from_headers(headers):\n \n def stream_decode_response_unicode(iterator, r):\n     \"\"\"Stream decodes a iterator.\"\"\"\n+    encoding = r.encoding\n \n-    if r.encoding is None:\n-        for item in iterator:\n-            yield item\n-        return\n+    if encoding is None:\n+        encoding = r.apparent_encoding\n+\n+    try:\n+        decoder = codecs.getincrementaldecoder(encoding)(errors='replace')\n+    except (LookupError, TypeError):\n+        # A LookupError is raised if the encoding was not found which could\n+        # indicate a misspelling or similar mistake.\n+        #\n+        # A TypeError can be raised if encoding is None\n+        raise UnicodeError(\"Unable to decode contents with encoding %s.\" % encoding)\n \n-    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n     for chunk in iterator:\n         rv = decoder.decode(chunk)\n         if rv:\n"}}
{"instance_id": "sphinx-doc__sphinx-11445", "found_files": ["sphinx/util/rst.py", "sphinx/environment/collectors/toctree.py", "sphinx/domains/python.py", "sphinx/transforms/__init__.py", "sphinx/parsers.py", "sphinx/environment/adapters/toctree.py"], "found_modules": ["sphinx/util/rst.py:prepend_prolog", "sphinx/environment/collectors/toctree.py:TocTreeCollector.process_doc", "sphinx/domains/python.py:PythonDomain", "sphinx/environment/collectors/toctree.py:TocTreeCollector", "sphinx/parsers.py:RSTParser", "sphinx/environment/adapters/toctree.py:TocTree.resolve", "sphinx/environment/adapters/toctree.py:TocTree"], "found_entities": ["sphinx/util/rst.py:prepend_prolog", "sphinx/environment/collectors/toctree.py:TocTreeCollector.process_doc.build_toc", "sphinx/environment/collectors/toctree.py:TocTreeCollector.process_doc", "sphinx/parsers.py:RSTParser.decorate", "sphinx/domains/python.py:PythonDomain.note_module", "sphinx/domains/python.py:PythonDomain.modules", "sphinx/environment/adapters/toctree.py:TocTree.resolve._entries_from_toctree", "sphinx/environment/adapters/toctree.py:TocTree.resolve"], "raw_output_loc": ["```\nsphinx/environment/collectors/toctree.py:TocTreeCollector.process_doc\nline: 71-89\nfunction: TocTreeCollector.process_doc.build_toc\n\nsphinx/transforms/__init__.py:SphinxContentsFilter\nline: 288-296\nfunction: SphinxContentsFilter.visit_pending_xref\n\nsphinx/domains/python.py:PythonDomain.note_module\nline: 1292-1299\nfunction: PythonDomain.note_module\n\nsphinx/util/rst.py:prepend_prolog\nline: 78-97\nfunction: prepend_prolog\n```", "```\nsphinx/util/rst.py\nline: 78\nfunction: prepend_prolog\n\nsphinx/parsers.py\nline: 83\nfunction: RSTParser.decorate\n\nsphinx/environment/adapters/toctree.py\nline: 113\nfunction: TocTree.resolve._entries_from_toctree\n\nsphinx/domains/python.py\nline: 1289\nfunction: PythonDomain.modules\n\nsphinx/environment/collectors/toctree.py\nline: 24\nclass: TocTreeCollector\n```"], "meta_data": {"repo": "sphinx-doc/sphinx", "base_commit": "71db08c05197545944949d5aa76cd340e7143627", "problem_statement": "Using rst_prolog removes top level headings containing a domain directive\n### Describe the bug\r\n\r\nIf `rst_prolog` is set, then any documents that contain a domain directive as the first heading (eg `:mod:`) do not render the heading correctly or include the heading in the toctree.\r\n\r\nIn the example below, if the heading of `docs/mypackage.rst` were `mypackage2` instead of `:mod:mypackage2` then the heading displays correctly.\r\nSimilarly, if you do not set `rst_prolog` then the heading will display correctly.\r\n\r\nThis appears to have been broken for some time because I can reproduce it in v4.0.0 of Sphinx\r\n\r\n### How to Reproduce\r\n\r\n```bash\r\n$ sphinx-quickstart --no-sep --project mypackage --author me -v 0.1.0 --release 0.1.0 --language en docs\r\n$ echo -e 'Welcome\\n=======\\n\\n.. toctree::\\n\\n   mypackage\\n' > docs/index.rst\r\n$ echo -e ':mod:`mypackage2`\\n=================\\n\\nContent\\n\\nSubheading\\n----------\\n' > docs/mypackage.rst\r\n$ echo -e 'rst_prolog = \"\"\"\\n.. |psf| replace:: Python Software Foundation\\n\"\"\"\\n' >> docs/conf.py\r\n$ sphinx-build -b html . _build\r\n$ grep 'mypackage2' docs/_build/index.html\r\n```\r\n\r\n`docs/index.rst`:\r\n\r\n```rst\r\nWelcome\r\n=======\r\n\r\n.. toctree::\r\n\r\n   mypackage\r\n```\r\n\r\n`docs/mypackage.rst`:\r\n\r\n```rst\r\n:mod:`mypackage2`\r\n=================\r\n\r\nContent\r\n\r\nSubheading\r\n----------\r\n```\r\n\r\n### Environment Information\r\n\r\n```text\r\nPlatform:              linux; (Linux-6.3.2-arch1-1-x86_64-with-glibc2.37)\r\nPython version:        3.11.3 (main, Apr  5 2023, 15:52:25) [GCC 12.2.1 20230201])\r\nPython implementation: CPython\r\nSphinx version:        7.1.0+/d3c91f951\r\nDocutils version:      0.20.1\r\nJinja2 version:        3.1.2\r\nPygments version:      2.15.1\r\n```\r\n\r\n\r\n### Sphinx extensions\r\n\r\n```python\r\n[]\r\n```\r\n\r\n\r\n### Additional context\r\n\r\n_No response_\n", "patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -10,22 +10,17 @@\n \n from docutils.parsers.rst import roles\n from docutils.parsers.rst.languages import en as english\n+from docutils.parsers.rst.states import Body\n from docutils.statemachine import StringList\n from docutils.utils import Reporter\n-from jinja2 import Environment\n+from jinja2 import Environment, pass_environment\n \n from sphinx.locale import __\n from sphinx.util import docutils, logging\n \n-try:\n-    from jinja2.utils import pass_environment\n-except ImportError:\n-    from jinja2 import environmentfilter as pass_environment\n-\n-\n logger = logging.getLogger(__name__)\n \n-docinfo_re = re.compile(':\\\\w+:.*?')\n+FIELD_NAME_RE = re.compile(Body.patterns['field_marker'])\n symbols_re = re.compile(r'([!-\\-/:-@\\[-`{-~])')  # symbols without dot(0x2e)\n SECTIONING_CHARS = ['=', '-', '~']\n \n@@ -80,7 +75,7 @@ def prepend_prolog(content: StringList, prolog: str) -> None:\n     if prolog:\n         pos = 0\n         for line in content:\n-            if docinfo_re.match(line):\n+            if FIELD_NAME_RE.match(line):\n                 pos += 1\n             else:\n                 break\n@@ -91,6 +86,7 @@ def prepend_prolog(content: StringList, prolog: str) -> None:\n             pos += 1\n \n         # insert prolog (after docinfo if exists)\n+        lineno = 0\n         for lineno, line in enumerate(prolog.splitlines()):\n             content.insert(pos + lineno, line, '<rst_prolog>', lineno)\n \n"}}
{"instance_id": "django__django-12747", "found_files": ["django/db/models/deletion.py", "django/db/models/query.py"], "found_modules": ["django/db/models/deletion.py:Collector", "django/db/models/query.py:QuerySet"], "found_entities": ["django/db/models/deletion.py:Collector.delete", "django/db/models/query.py:QuerySet.delete", "django/db/models/deletion.py:Collector.collect"], "raw_output_loc": ["```\ndjango/db/models/deletion.py\nline: 425-429\nfunction: Collector.delete\n```", "```\ndjango/db/models/query.py\nline: 713\nfunction: QuerySet.delete\n\ndjango/db/models/deletion.py\nline: 379\nfunction: Collector.delete\n\ndjango/db/models/deletion.py\nline: 214\nfunction: Collector.collect\n\ndjango/db/models/deletion.py\nline: 389\nline: 445\nfunction: Collector.delete\n```"], "meta_data": {"repo": "django/django", "base_commit": "c86201b6ed4f8256b0a0520c08aa674f623d4127", "problem_statement": "QuerySet.Delete - inconsistent result when zero objects deleted\nDescription\n\t\nThe result format of the QuerySet.Delete method is a tuple: (X, Y) \nX - is the total amount of deleted objects (including foreign key deleted objects)\nY - is a dictionary specifying counters of deleted objects for each specific model (the key is the _meta.label of the model and the value is counter of deleted objects of this model).\nExample: <class 'tuple'>: (2, {'my_app.FileAccess': 1, 'my_app.File': 1})\nWhen there are zero objects to delete in total - the result is inconsistent:\nFor models with foreign keys - the result will be: <class 'tuple'>: (0, {})\nFor \"simple\" models without foreign key - the result will be: <class 'tuple'>: (0, {'my_app.BlockLibrary': 0})\nI would expect there will be no difference between the two cases: Either both will have the empty dictionary OR both will have dictionary with model-label keys and zero value.\n", "patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -408,7 +408,8 @@ def delete(self):\n             # fast deletes\n             for qs in self.fast_deletes:\n                 count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                if count:\n+                    deleted_counter[qs.model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n@@ -426,7 +427,8 @@ def delete(self):\n                 query = sql.DeleteQuery(model)\n                 pk_list = [obj.pk for obj in instances]\n                 count = query.delete_batch(pk_list, self.using)\n-                deleted_counter[model._meta.label] += count\n+                if count:\n+                    deleted_counter[model._meta.label] += count\n \n                 if not model._meta.auto_created:\n                     for obj in instances:\n"}}
{"instance_id": "pallets__flask-5063", "found_files": ["src/flask/cli.py", "src/flask/app.py", "src/flask/blueprints.py", "src/flask/wrappers.py"], "found_modules": ["src/flask/cli.py:routes_command", "src/flask/blueprints.py:Blueprint", "src/flask/app.py:Flask", "src/flask/blueprints.py:BlueprintSetupState"], "found_entities": ["src/flask/cli.py:routes_command", "src/flask/blueprints.py:Blueprint.register", "src/flask/app.py:Flask.add_url_rule", "src/flask/app.py:Flask.create_url_adapter", "src/flask/blueprints.py:BlueprintSetupState.add_url_rule"], "raw_output_loc": ["```\nsrc/flask/cli.py\nline: 988\nfunction: routes_command\n\nsrc/flask/app.py\nline: 1065\nclass: Flask\nfunction: add_url_rule\n\nsrc/flask/blueprints.py\nline: 271\nfunction: Blueprint.register\n\nsrc/flask/app.py\nline: 1874\nfunction: Flask.create_url_adapter\n\nsrc/flask/wrappers.py\nline: 29\nclass: Request\nproperty: url_rule\n```", "```\nsrc/flask/cli.py\nline: 1001\nfunction: routes_command\n\nsrc/flask/blueprints.py\nline: 271\nfunction: Blueprint.register\n\nsrc/flask/blueprints.py\nline: 85\nfunction: BlueprintSetupState.add_url_rule\n\nsrc/flask/app.py\nline: 1020\nfunction: Flask.add_url_rule\n\nsrc/flask/app.py\nline: 1874\nfunction: Flask.create_url_adapter\n```"], "meta_data": {"repo": "pallets/flask", "base_commit": "182ce3dd15dfa3537391c3efaf9c3ff407d134d4", "problem_statement": "Flask routes to return domain/sub-domains information\nCurrently when checking **flask routes** it provides all routes but **it is no way to see which routes are assigned to which subdomain**.\r\n\r\n**Default server name:**\r\nSERVER_NAME: 'test.local'\r\n\r\n**Domains (sub-domains):**\r\ntest.test.local\r\nadmin.test.local\r\ntest.local\r\n\r\n**Adding blueprints:**\r\napp.register_blueprint(admin_blueprint,url_prefix='',subdomain='admin')\r\napp.register_blueprint(test_subdomain_blueprint,url_prefix='',subdomain='test')\r\n\r\n\r\n```\r\n$ flask routes\r\n * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\r\nEndpoint                                                 Methods    Rule\r\n-------------------------------------------------------  ---------  ------------------------------------------------\r\nadmin_blueprint.home                                      GET        /home\r\ntest_subdomain_blueprint.home                             GET        /home\r\nstatic                                                    GET        /static/<path:filename>\r\n...\r\n```\r\n\r\n\r\n**Feature request**\r\nIt will be good to see something like below (that will make more clear which route for which subdomain, because now need to go and check configuration).\r\n**If it is not possible to fix routes**, can you add or tell which method(s) should be used to get below information from flask? \r\n\r\n```\r\n$ flask routes\r\n * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\r\nDomain                Endpoint                                             Methods    Rule\r\n-----------------   ----------------------------------------------------  ----------  ------------------------------------------------\r\nadmin.test.local     admin_blueprint.home                                  GET        /home\r\ntest.test.local      test_subdomain_blueprint.home                         GET        /home\r\ntest.local           static                                                GET        /static/<path:filename>\r\n...\r\n```\r\n\n", "patch": "diff --git a/src/flask/cli.py b/src/flask/cli.py\n--- a/src/flask/cli.py\n+++ b/src/flask/cli.py\n@@ -9,7 +9,7 @@\n import traceback\n import typing as t\n from functools import update_wrapper\n-from operator import attrgetter\n+from operator import itemgetter\n \n import click\n from click.core import ParameterSource\n@@ -989,49 +989,62 @@ def shell_command() -> None:\n @click.option(\n     \"--sort\",\n     \"-s\",\n-    type=click.Choice((\"endpoint\", \"methods\", \"rule\", \"match\")),\n+    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n     default=\"endpoint\",\n     help=(\n-        'Method to sort routes by. \"match\" is the order that Flask will match '\n-        \"routes when dispatching a request.\"\n+        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n+        \" when dispatching a request.\"\n     ),\n )\n @click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n @with_appcontext\n def routes_command(sort: str, all_methods: bool) -> None:\n     \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n-\n     rules = list(current_app.url_map.iter_rules())\n+\n     if not rules:\n         click.echo(\"No routes were registered.\")\n         return\n \n-    ignored_methods = set(() if all_methods else (\"HEAD\", \"OPTIONS\"))\n+    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n+    host_matching = current_app.url_map.host_matching\n+    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n+    rows = []\n \n-    if sort in (\"endpoint\", \"rule\"):\n-        rules = sorted(rules, key=attrgetter(sort))\n-    elif sort == \"methods\":\n-        rules = sorted(rules, key=lambda rule: sorted(rule.methods))  # type: ignore\n+    for rule in rules:\n+        row = [\n+            rule.endpoint,\n+            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n+        ]\n \n-    rule_methods = [\n-        \", \".join(sorted(rule.methods - ignored_methods))  # type: ignore\n-        for rule in rules\n-    ]\n+        if has_domain:\n+            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n \n-    headers = (\"Endpoint\", \"Methods\", \"Rule\")\n-    widths = (\n-        max(len(rule.endpoint) for rule in rules),\n-        max(len(methods) for methods in rule_methods),\n-        max(len(rule.rule) for rule in rules),\n-    )\n-    widths = [max(len(h), w) for h, w in zip(headers, widths)]\n-    row = \"{{0:<{0}}}  {{1:<{1}}}  {{2:<{2}}}\".format(*widths)\n+        row.append(rule.rule)\n+        rows.append(row)\n+\n+    headers = [\"Endpoint\", \"Methods\"]\n+    sorts = [\"endpoint\", \"methods\"]\n+\n+    if has_domain:\n+        headers.append(\"Host\" if host_matching else \"Subdomain\")\n+        sorts.append(\"domain\")\n+\n+    headers.append(\"Rule\")\n+    sorts.append(\"rule\")\n+\n+    try:\n+        rows.sort(key=itemgetter(sorts.index(sort)))\n+    except ValueError:\n+        pass\n \n-    click.echo(row.format(*headers).strip())\n-    click.echo(row.format(*(\"-\" * width for width in widths)))\n+    rows.insert(0, headers)\n+    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n+    rows.insert(1, [\"-\" * w for w in widths])\n+    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n \n-    for rule, methods in zip(rules, rule_methods):\n-        click.echo(row.format(rule.endpoint, methods, rule.rule).rstrip())\n+    for row in rows:\n+        click.echo(template.format(*row))\n \n \n cli = FlaskGroup(\n"}}
{"instance_id": "django__django-15738", "found_files": ["django/db/migrations/operations/models.py", "django/db/migrations/state.py", "django/db/migrations/executor.py", "django/db/migrations/migration.py"], "found_modules": ["django/db/migrations/operations/models.py:AlterUniqueTogether", "django/db/migrations/state.py:ProjectState", "django/db/migrations/executor.py:MigrationExecutor", "django/db/migrations/migration.py:Migration"], "found_entities": ["django/db/migrations/state.py:ProjectState.add_constraint", "django/db/migrations/state.py:ProjectState.remove_constraint", "django/db/migrations/executor.py:MigrationExecutor.migrate", "django/db/migrations/migration.py:Migration.apply"], "raw_output_loc": ["```\napp_authors/models.py\nline: 5\nclass: Authors\nfunction: Authors.Meta\n\napp_authors/models.py\nline: 15\nclass: ProjectDataSet\nfunction: ProjectDataSet.Meta\n\napp_authors/models.py\nline: 25\nclass: DataSet\nfunction: DataSet.__init__\n\napp_authors/models.py\nline: 35\nclass: Project\nfunction: Project.__init__\n\napp_authors/migrations/0001_initial.py\nline: 10\nfunction: Migration.initial\n```", "```\ndjango/db/migrations/operations/models.py\nline: 598\nclass: AlterUniqueTogether\nfunction: AlterUniqueTogether.__init__\n\ndjango/db/migrations/state.py\nline: 234\nfunction: ProjectState.add_constraint\nline: 237\nfunction: ProjectState.remove_constraint\n\ndjango/db/migrations/executor.py\nline: 94\nfunction: MigrationExecutor.migrate\n\ndjango/db/migrations/migration.py\nline: 92\nfunction: Migration.apply\n```"], "meta_data": {"repo": "django/django", "base_commit": "6f73eb9d90cfec684529aab48d517e3d6449ba8c", "problem_statement": "Models migration with change field foreign to many and deleting unique together.\nDescription\n\t \n\t\t(last modified by Simon Charette)\n\t \nI have models like\nclass Authors(models.Model):\n\tproject_data_set = models.ForeignKey(\n\t\tProjectDataSet,\n\t\ton_delete=models.PROTECT\n\t)\n\tstate = models.IntegerField()\n\tstart_date = models.DateField()\n\tclass Meta:\n\t\t unique_together = (('project_data_set', 'state', 'start_date'),)\nand\nclass DataSet(models.Model):\n\tname = models.TextField(max_length=50)\nclass Project(models.Model):\n\tdata_sets = models.ManyToManyField(\n\t\tDataSet,\n\t\tthrough='ProjectDataSet',\n\t)\n\tname = models.TextField(max_length=50)\nclass ProjectDataSet(models.Model):\n\t\"\"\"\n\tCross table of data set and project\n\t\"\"\"\n\tdata_set = models.ForeignKey(DataSet, on_delete=models.PROTECT)\n\tproject = models.ForeignKey(Project, on_delete=models.PROTECT)\n\tclass Meta:\n\t\tunique_together = (('data_set', 'project'),)\nwhen i want to change field project_data_set in Authors model from foreign key field to many to many field I must delete a unique_together, cause it can't be on many to many field.\nThen my model should be like:\nclass Authors(models.Model):\n\tproject_data_set = models.ManyToManyField(\n\t\tProjectDataSet,\n\t)\n\tstate = models.IntegerField()\n\tstart_date = models.DateField()\nBut when I want to do a migrations.\npython3 manage.py makemigrations\npython3 manage.py migrate\nI have error:\nValueError: Found wrong number (0) of constraints for app_authors(project_data_set, state, start_date)\nThe database is on production, so I can't delete previous initial migrations, and this error isn't depending on database, cause I delete it and error is still the same.\nMy solve is to first delete unique_together, then do a makemigrations and then migrate. After that change the field from foreign key to many to many field, then do a makemigrations and then migrate.\nBut in this way I have 2 migrations instead of one.\nI added attachment with this project, download it and then do makemigrations and then migrate to see this error.\n", "patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -1022,8 +1022,9 @@ def generate_added_fields(self):\n \n     def _generate_added_field(self, app_label, model_name, field_name):\n         field = self.to_state.models[app_label, model_name].get_field(field_name)\n-        # Fields that are foreignkeys/m2ms depend on stuff\n-        dependencies = []\n+        # Adding a field always depends at least on its removal.\n+        dependencies = [(app_label, model_name, field_name, False)]\n+        # Fields that are foreignkeys/m2ms depend on stuff.\n         if field.remote_field and field.remote_field.model:\n             dependencies.extend(\n                 self._get_dependencies_for_foreign_key(\n"}}
{"instance_id": "django__django-12184", "found_files": ["django/urls/resolvers.py"], "found_modules": ["django/urls/resolvers.py:ResolverMatch", "django/urls/resolvers.py:_route_to_regex"], "found_entities": ["django/urls/resolvers.py:_route_to_regex"], "raw_output_loc": ["```\ndjango/urls/resolvers.py\nline: 32\nclass: ResolverMatch\nfunction: ResolverMatch.__init__\n\ncore/handlers/base.py\nline: 85\nclass: BaseHandler\nfunction: BaseHandler._get_response\n\ncore/handlers/base.py\nline: 111\nclass: BaseHandler\nfunction: BaseHandler._get_response\n\ncore/handlers/base.py\nline: 101\nclass: BaseHandler\nfunction: BaseHandler._get_response\n\ncore/handlers/base.py\nline: 100\nclass: BaseHandler\nfunction: BaseHandler._get_response\n```", "```\ndjango/urls/resolvers.py\nline: 203\nfunction: _route_to_regex\n\ncore/handlers/base.py\nline: 113\nfunction: _get_response\n\ncore/handlers/exception.py\nline: 34\nfunction: inner\n\nurls/conf.py\nline: 57\nfunction: _path\n\nurls/base.py\nline: 147\nfunction: is_valid_path\n```"], "meta_data": {"repo": "django/django", "base_commit": "5d674eac871a306405b0fbbaeb17bbeba9c68bf3", "problem_statement": "Optional URL params crash some view functions.\nDescription\n\t\nMy use case, running fine with Django until 2.2:\nURLConf:\nurlpatterns += [\n\t...\n\tre_path(r'^module/(?P<format>(html|json|xml))?/?$', views.modules, name='modules'),\n]\nView:\ndef modules(request, format='html'):\n\t...\n\treturn render(...)\nWith Django 3.0, this is now producing an error:\nTraceback (most recent call last):\n File \"/l10n/venv/lib/python3.6/site-packages/django/core/handlers/exception.py\", line 34, in inner\n\tresponse = get_response(request)\n File \"/l10n/venv/lib/python3.6/site-packages/django/core/handlers/base.py\", line 115, in _get_response\n\tresponse = self.process_exception_by_middleware(e, request)\n File \"/l10n/venv/lib/python3.6/site-packages/django/core/handlers/base.py\", line 113, in _get_response\n\tresponse = wrapped_callback(request, *callback_args, **callback_kwargs)\nException Type: TypeError at /module/\nException Value: modules() takes from 1 to 2 positional arguments but 3 were given\n", "patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -158,8 +158,9 @@ def match(self, path):\n             # If there are any named groups, use those as kwargs, ignoring\n             # non-named groups. Otherwise, pass all non-named arguments as\n             # positional arguments.\n-            kwargs = {k: v for k, v in match.groupdict().items() if v is not None}\n+            kwargs = match.groupdict()\n             args = () if kwargs else match.groups()\n+            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n             return path[match.end():], args, kwargs\n         return None\n \n"}}
{"instance_id": "django__django-17087", "found_files": ["django/contrib/postgres/fields/array.py", "django/db/migrations/serializer.py", "django/db/migrations/operations/fields.py", "django/db/models/fields/__init__.py"], "found_modules": ["django/contrib/postgres/fields/array.py:ArrayField", "django/db/migrations/serializer.py:DeconstructableSerializer", "django/db/migrations/operations/fields.py:AddField", "django/db/migrations/serializer.py:ModelFieldSerializer", "django/db/models/fields/__init__.py:Field"], "found_entities": ["django/contrib/postgres/fields/array.py:ArrayField.deconstruct", "django/db/migrations/serializer.py:DeconstructableSerializer._serialize_path", "django/db/migrations/operations/fields.py:AddField.database_forwards", "django/db/migrations/serializer.py:ModelFieldSerializer.serialize", "django/db/models/fields/__init__.py:Field._check_db_index"], "raw_output_loc": ["```\ndjango/contrib/postgres/fields/array.py\nclass: ArrayField\nfunction: ArrayField.__init__\n\nappname/models.py\nclass: Profile\nclass: Capability\nfunction: Capability.default\n\nappname/migrations/0001_initial.py\nline: 10\nfunction: migrations.AddField\n```", "```\ndjango/contrib/postgres/fields/array.py\nline: 134\nline: 140\nclass: ArrayField\nfunction: ArrayField.deconstruct\n\ndjango/db/migrations/serializer.py\nline: 101\nline: 103\nclass: DeconstructableSerializer\nfunction: DeconstructableSerializer._serialize_path\n\ndjango/db/migrations/serializer.py\nline: 228\nclass: ModelFieldSerializer\nfunction: ModelFieldSerializer.serialize\n\ndjango/db/migrations/operations/fields.py\nline: 101\nline: 107\nclass: AddField\nfunction: AddField.database_forwards\n\ndjango/db/models/fields/__init__.py\nline: 426\nfunction: _effective_default\n```"], "meta_data": {"repo": "django/django", "base_commit": "4a72da71001f154ea60906a2f74898d32b7322a7", "problem_statement": "Class methods from nested classes cannot be used as Field.default.\nDescription\n\t \n\t\t(last modified by Mariusz Felisiak)\n\t \nGiven the following model:\n \nclass Profile(models.Model):\n\tclass Capability(models.TextChoices):\n\t\tBASIC = (\"BASIC\", \"Basic\")\n\t\tPROFESSIONAL = (\"PROFESSIONAL\", \"Professional\")\n\t\t\n\t\t@classmethod\n\t\tdef default(cls) -> list[str]:\n\t\t\treturn [cls.BASIC]\n\tcapabilities = ArrayField(\n\t\tmodels.CharField(choices=Capability.choices, max_length=30, blank=True),\n\t\tnull=True,\n\t\tdefault=Capability.default\n\t)\nThe resulting migration contained the following:\n # ...\n\t migrations.AddField(\n\t\t model_name='profile',\n\t\t name='capabilities',\n\t\t field=django.contrib.postgres.fields.ArrayField(base_field=models.CharField(blank=True, choices=[('BASIC', 'Basic'), ('PROFESSIONAL', 'Professional')], max_length=30), default=appname.models.Capability.default, null=True, size=None),\n\t ),\n # ...\nAs you can see, migrations.AddField is passed as argument \"default\" a wrong value \"appname.models.Capability.default\", which leads to an error when trying to migrate. The right value should be \"appname.models.Profile.Capability.default\".\n", "patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -168,7 +168,7 @@ def serialize(self):\n         ):\n             klass = self.value.__self__\n             module = klass.__module__\n-            return \"%s.%s.%s\" % (module, klass.__name__, self.value.__name__), {\n+            return \"%s.%s.%s\" % (module, klass.__qualname__, self.value.__name__), {\n                 \"import %s\" % module\n             }\n         # Further error checking\n"}}
{"instance_id": "pytest-dev__pytest-11148", "found_files": ["src/_pytest/pathlib.py", "src/_pytest/logging.py"], "found_modules": ["src/_pytest/pathlib.py:import_path", "src/_pytest/logging.py:LogCaptureFixture"], "found_entities": ["src/_pytest/pathlib.py:import_path", "src/_pytest/logging.py:LogCaptureFixture.set_level"], "raw_output_loc": ["```\npmxbot/logging.py\nclass: Logger\nfunction: Logger.store\n\npmxbot/core.py\nfunction: core.initialize\n\ntests/unit/test_commands.py\nclass: TestCommands\nfunction: TestCommands.setup_class\n\nsrc/_pytest/pathlib.py\nfunction: import_path\n```", "```\nsetup.py\nline: 1\nfunction: setup\n\nsrc/_pytest/logging.py\nline: 335\nclass: catching_logs\n\nsrc/_pytest/logging.py\nline: 517\nfunction: LogCaptureFixture.set_level\n\nsrc/_pytest/logging.py\nline: 840\nclass: _FileHandler\n\nsrc/_pytest/logging.py\nline: 848\nclass: _LiveLoggingStreamHandler\n```"], "meta_data": {"repo": "pytest-dev/pytest", "base_commit": "2f7415cfbc4b6ca62f9013f1abd27136f46b9653", "problem_statement": "Module imported twice under import-mode=importlib\nIn pmxbot/pmxbot@7f189ad, I'm attempting to switch pmxbot off of pkg_resources style namespace packaging to PEP 420 namespace packages. To do so, I've needed to switch to `importlib` for the `import-mode` and re-organize the tests to avoid import errors on the tests.\r\n\r\nYet even after working around these issues, the tests are failing when the effect of `core.initialize()` doesn't seem to have had any effect.\r\n\r\nInvestigating deeper, I see that initializer is executed and performs its actions (setting a class variable `pmxbot.logging.Logger.store`), but when that happens, there are two different versions of `pmxbot.logging` present, one in `sys.modules` and another found in `tests.unit.test_commands.logging`:\r\n\r\n```\r\n=========================================================================== test session starts ===========================================================================\r\nplatform darwin -- Python 3.11.1, pytest-7.2.0, pluggy-1.0.0\r\ncachedir: .tox/python/.pytest_cache\r\nrootdir: /Users/jaraco/code/pmxbot/pmxbot, configfile: pytest.ini\r\nplugins: black-0.3.12, mypy-0.10.3, jaraco.test-5.3.0, checkdocs-2.9.0, flake8-1.1.1, enabler-2.0.0, jaraco.mongodb-11.2.1, pmxbot-1122.14.3.dev13+g7f189ad\r\ncollected 421 items / 180 deselected / 241 selected                                                                                                                       \r\nrun-last-failure: rerun previous 240 failures (skipped 14 files)\r\n\r\ntests/unit/test_commands.py E\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> traceback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n\r\ncls = <class 'tests.unit.test_commands.TestCommands'>\r\n\r\n    @classmethod\r\n    def setup_class(cls):\r\n        path = os.path.dirname(os.path.abspath(__file__))\r\n        configfile = os.path.join(path, 'testconf.yaml')\r\n        config = pmxbot.dictlib.ConfigDict.from_yaml(configfile)\r\n        cls.bot = core.initialize(config)\r\n>       logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\r\nE       AttributeError: type object 'Logger' has no attribute 'store'\r\n\r\ntests/unit/test_commands.py:37: AttributeError\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> entering PDB >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n\r\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PDB post_mortem (IO-capturing turned off) >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\r\n> /Users/jaraco/code/pmxbot/pmxbot/tests/unit/test_commands.py(37)setup_class()\r\n-> logging.Logger.store.message(\"logged\", \"testrunner\", \"some text\")\r\n(Pdb) logging.Logger\r\n<class 'pmxbot.logging.Logger'>\r\n(Pdb) logging\r\n<module 'pmxbot.logging' from '/Users/jaraco/code/pmxbot/pmxbot/pmxbot/logging.py'>\r\n(Pdb) import sys\r\n(Pdb) sys.modules['pmxbot.logging']\r\n<module 'pmxbot.logging' from '/Users/jaraco/code/pmxbot/pmxbot/pmxbot/logging.py'>\r\n(Pdb) sys.modules['pmxbot.logging'] is logging\r\nFalse\r\n```\r\n\r\nI haven't yet made a minimal reproducer, but I wanted to first capture this condition.\r\n\n", "patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -523,6 +523,8 @@ def import_path(\n \n     if mode is ImportMode.importlib:\n         module_name = module_name_from_path(path, root)\n+        with contextlib.suppress(KeyError):\n+            return sys.modules[module_name]\n \n         for meta_importer in sys.meta_path:\n             spec = meta_importer.find_spec(module_name, [str(path.parent)])\n"}}
{"instance_id": "psf__requests-2674", "found_files": ["requests/exceptions.py", "requests/adapters.py", "requests/packages/urllib3/exceptions.py", "requests/models.py", "requests/sessions.py"], "found_modules": ["requests/adapters.py:HTTPAdapter", "requests/exceptions.py:HTTPError", "requests/exceptions.py:Timeout", "requests/packages/urllib3/exceptions.py:DecodeError", "requests/models.py:RequestEncodingMixin", "requests/packages/urllib3/exceptions.py:TimeoutError", "requests/models.py:Response", "requests/exceptions.py:ContentDecodingError", "requests/sessions.py:SessionRedirectMixin"], "found_entities": ["requests/adapters.py:HTTPAdapter.send", "requests/models.py:RequestEncodingMixin.path_url", "requests/models.py:Response.iter_content", "requests/sessions.py:SessionRedirectMixin.rebuild_proxies", "requests/sessions.py:SessionRedirectMixin.resolve_redirects"], "raw_output_loc": ["```\nrequests/adapters.py\nline: 324\nclass: HTTPAdapter\nfunction: HTTPAdapter.send\n\nrequests/exceptions.py\nline: 46\nfunction: Timeout\n\nrequests/packages/urllib3/exceptions.py\nline: 95\nclass: TimeoutError\n\nrequests/models.py\nline: 62\nfunction: Response.iter_content.generate\n\nrequests/sessions.py\nline: 234\nfunction: SessionRedirectMixin.resolve_redirects\n```", "```\nrequests/exceptions.py\nline: 10\nfunction: HTTPError\n\nrequests/packages/urllib3/exceptions.py\nline: 46\nclass: DecodeError\nfunction: DecodeError\n\nrequests/packages/urllib3/exceptions.py\nline: 95\nclass: TimeoutError\nfunction: TimeoutError\n\nrequests/exceptions.py\nline: 90\nclass: ContentDecodingError\nfunction: ContentDecodingError\n\nrequests/exceptions.py\nline: 46\nclass: Timeout\nfunction: Timeout\n```"], "meta_data": {"repo": "psf/requests", "base_commit": "0be38a0c37c59c4b66ce908731da15b401655113", "problem_statement": "urllib3 exceptions passing through requests API\nI don't know if it's a design goal of requests to hide urllib3's exceptions and wrap them around requests.exceptions types.\n\n(If it's not IMHO it should be, but that's another discussion)\n\nIf it is, I have at least two of them passing through that I have to catch in addition to requests' exceptions. They are requests.packages.urllib3.exceptions.DecodeError and requests.packages.urllib3.exceptions.TimeoutError (this one I get when a proxy timeouts)\n\nThanks!\n\n", "patch": "diff --git a/requests/adapters.py b/requests/adapters.py\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -19,6 +19,7 @@\n from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth)\n from .structures import CaseInsensitiveDict\n+from .packages.urllib3.exceptions import ClosedPoolError\n from .packages.urllib3.exceptions import ConnectTimeoutError\n from .packages.urllib3.exceptions import HTTPError as _HTTPError\n from .packages.urllib3.exceptions import MaxRetryError\n@@ -421,6 +422,9 @@ def send(self, request, stream=False, timeout=None, verify=True, cert=None, prox\n \n             raise ConnectionError(e, request=request)\n \n+        except ClosedPoolError as e:\n+            raise ConnectionError(e, request=request)\n+\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n"}}
